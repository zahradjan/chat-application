{"ast":null,"code":"const PQueue = require('p-queue').default;\n\nconst Log = require('ipfs-log');\n\nconst getNextAndRefsUnion = e => [...new Set([...e.next, ...e.refs])];\n\nconst flatMap = (res, val) => res.concat(val);\n\nconst defaultConcurrency = 32;\n\nclass Replicator {\n  constructor(store, concurrency) {\n    this._store = store;\n    this._concurrency = concurrency || defaultConcurrency; // Tasks processing queue where each log sync request is\n    // added as a task that fetches the log\n\n    this._q = new PQueue({\n      concurrency: this._concurrency\n    });\n    /* Internal caches */\n    // For storing fetched logs before \"load is complete\".\n    // Cleared when processing is complete.\n\n    this._logs = []; // Index of hashes (CIDs) for checking which entries are currently being fetched.\n    // Hashes are added to this cache before fetching a log starts and removed after\n    // the log was fetched.\n\n    this._fetching = {}; // Index of hashes (CIDs) for checking which entries have been fetched.\n    // Cleared when processing is complete.\n\n    this._fetched = {}; // Listen for an event when the task queue has emptied\n    // and all tasks have been processed. We call the\n    // onReplicationComplete callback which then updates the Store's\n    // state (eg. index, replication state, etc)\n\n    this._q.on('idle', async () => {\n      const logs = this._logs.slice();\n\n      this._logs = [];\n\n      if (this.onReplicationComplete && logs.length > 0 && this._store._oplog) {\n        try {\n          await this.onReplicationComplete(logs); // Remove from internal cache\n\n          logs.forEach(log => log.values.forEach(e => delete this._fetched[e.hash]));\n        } catch (e) {\n          console.error(e);\n        }\n      }\n    });\n  }\n  /**\n   * Returns the number of replication tasks running currently\n   * @return {[Integer]} [Number of replication tasks running]\n   */\n\n\n  get tasksRunning() {\n    return this._q.pending;\n  }\n  /**\n   * Returns the number of replication tasks currently queued\n   * @return {[Integer]} [Number of replication tasks queued]\n   */\n\n\n  get tasksQueued() {\n    return this._q.size;\n  }\n  /**\n   * Returns the hashes currently queued or being processed\n   * @return {[Array]} [Strings of hashes of entries currently queued or being processed]\n   */\n\n\n  get unfinished() {\n    return Object.keys(this._fetching);\n  }\n  /*\n    Process new heads.\n    Param 'entries' is an Array of Entry instances or strings (of CIDs).\n   */\n\n\n  async load(entries) {\n    try {\n      // Add entries to the replication queue\n      this._addToQueue(entries);\n    } catch (e) {\n      console.error(e);\n    }\n  }\n\n  async _addToQueue(entries) {\n    // Function to determine if an entry should be fetched (ie. do we have it somewhere already?)\n    const shouldExclude = h => h && this._store._oplog && (this._store._oplog.has(h) || this._fetching[h] !== undefined || this._fetched[h]); // A task to process a given entries\n\n\n    const createReplicationTask = e => {\n      // Add to internal \"currently fetching\" cache\n      this._fetching[e.hash || e] = true; // The returned function is the processing function / task\n      // to run concurrently\n\n      return async () => {\n        // Call onReplicationProgress only for entries that have .hash field,\n        // if it is a string don't call it (added internally from .next)\n        if (e.hash && this.onReplicationQueued) {\n          this.onReplicationQueued(e);\n        }\n\n        try {\n          // Replicate the log starting from the entry's hash (CID)\n          const log = await this._replicateLog(e); // Add the fetched log to the internal cache to wait\n          // for \"onReplicationComplete\"\n\n          this._logs.push(log);\n        } catch (e) {\n          console.error(e);\n          throw e;\n        } // Remove from internal cache\n\n\n        delete this._fetching[e.hash || e];\n      };\n    };\n\n    if (entries.length > 0) {\n      // Create a processing tasks from each entry/hash that we\n      // should include based on the exclusion filter function\n      const tasks = entries.filter(e => !shouldExclude(e.hash || e)).map(e => createReplicationTask(e)); // Add the tasks to the processing queue\n\n      if (tasks.length > 0) {\n        this._q.addAll(tasks);\n      }\n    }\n  }\n\n  async stop() {\n    // Clear the task queue\n    this._q.pause();\n\n    this._q.clear();\n\n    await this._q.onIdle(); // Reset internal caches\n\n    this._logs = [];\n    this._fetching = {};\n    this._fetched = {};\n  }\n\n  async _replicateLog(entry) {\n    const hash = entry.hash || entry; // Notify the Store that we made progress\n\n    const onProgressCallback = entry => {\n      this._fetched[entry.hash] = true;\n\n      if (this.onReplicationProgress) {\n        this.onReplicationProgress(entry);\n      }\n    };\n\n    const shouldExclude = h => h && h !== hash && this._store._oplog && (this._store._oplog.has(h) || this._fetching[h] !== undefined || this._fetched[h] !== undefined); // Fetch and load a log from the entry hash\n\n\n    const log = await Log.fromEntryHash(this._store._ipfs, this._store.identity, hash, {\n      logId: this._store.id,\n      access: this._store.access,\n      length: -1,\n      exclude: [],\n      shouldExclude,\n      concurrency: this._concurrency,\n      onProgressCallback\n    }); // Return all next pointers\n\n    const nexts = log.values.map(getNextAndRefsUnion).reduce(flatMap, []);\n\n    try {\n      // Add the next (hashes) to the processing queue\n      this._addToQueue(nexts);\n    } catch (e) {\n      console.error(e);\n      throw e;\n    } // Return the log\n\n\n    return log;\n  }\n\n}\n\nmodule.exports = Replicator;","map":{"version":3,"names":["PQueue","require","default","Log","getNextAndRefsUnion","e","Set","next","refs","flatMap","res","val","concat","defaultConcurrency","Replicator","constructor","store","concurrency","_store","_concurrency","_q","_logs","_fetching","_fetched","on","logs","slice","onReplicationComplete","length","_oplog","forEach","log","values","hash","console","error","tasksRunning","pending","tasksQueued","size","unfinished","Object","keys","load","entries","_addToQueue","shouldExclude","h","has","undefined","createReplicationTask","onReplicationQueued","_replicateLog","push","tasks","filter","map","addAll","stop","pause","clear","onIdle","entry","onProgressCallback","onReplicationProgress","fromEntryHash","_ipfs","identity","logId","id","access","exclude","nexts","reduce","module","exports"],"sources":["C:/Users/zajan/GitHub/chatApplication/node_modules/orbit-db-store/src/Replicator.js"],"sourcesContent":["const PQueue = require('p-queue').default\nconst Log = require('ipfs-log')\n\nconst getNextAndRefsUnion = e => [...new Set([...e.next, ...e.refs])]\nconst flatMap = (res, val) => res.concat(val)\n\nconst defaultConcurrency = 32\n\nclass Replicator {\n  constructor (store, concurrency) {\n    this._store = store\n    this._concurrency = concurrency || defaultConcurrency\n\n    // Tasks processing queue where each log sync request is\n    // added as a task that fetches the log\n    this._q = new PQueue({ concurrency: this._concurrency })\n\n    /* Internal caches */\n\n    // For storing fetched logs before \"load is complete\".\n    // Cleared when processing is complete.\n    this._logs = []\n    // Index of hashes (CIDs) for checking which entries are currently being fetched.\n    // Hashes are added to this cache before fetching a log starts and removed after\n    // the log was fetched.\n    this._fetching = {}\n    // Index of hashes (CIDs) for checking which entries have been fetched.\n    // Cleared when processing is complete.\n    this._fetched = {}\n\n    // Listen for an event when the task queue has emptied\n    // and all tasks have been processed. We call the\n    // onReplicationComplete callback which then updates the Store's\n    // state (eg. index, replication state, etc)\n    this._q.on('idle', async () => {\n      const logs = this._logs.slice()\n      this._logs = []\n      if (this.onReplicationComplete && logs.length > 0 && this._store._oplog) {\n        try {\n          await this.onReplicationComplete(logs)\n          // Remove from internal cache\n          logs.forEach(log => log.values.forEach(e => delete this._fetched[e.hash]))\n        } catch (e) {\n          console.error(e)\n        }\n      }\n    })\n  }\n\n  /**\n   * Returns the number of replication tasks running currently\n   * @return {[Integer]} [Number of replication tasks running]\n   */\n  get tasksRunning () {\n    return this._q.pending\n  }\n\n  /**\n   * Returns the number of replication tasks currently queued\n   * @return {[Integer]} [Number of replication tasks queued]\n   */\n  get tasksQueued () {\n    return this._q.size\n  }\n\n  /**\n   * Returns the hashes currently queued or being processed\n   * @return {[Array]} [Strings of hashes of entries currently queued or being processed]\n   */\n  get unfinished () {\n    return Object.keys(this._fetching)\n  }\n\n  /*\n    Process new heads.\n    Param 'entries' is an Array of Entry instances or strings (of CIDs).\n   */\n  async load (entries) {\n    try {\n      // Add entries to the replication queue\n      this._addToQueue(entries)\n    } catch (e) {\n      console.error(e)\n    }\n  }\n\n  async _addToQueue (entries) {\n    // Function to determine if an entry should be fetched (ie. do we have it somewhere already?)\n    const shouldExclude = (h) => h && this._store._oplog && (this._store._oplog.has(h) || this._fetching[h] !== undefined || this._fetched[h])\n\n    // A task to process a given entries\n    const createReplicationTask = (e) => {\n      // Add to internal \"currently fetching\" cache\n      this._fetching[e.hash || e] = true\n      // The returned function is the processing function / task\n      // to run concurrently\n      return async () => {\n        // Call onReplicationProgress only for entries that have .hash field,\n        // if it is a string don't call it (added internally from .next)\n        if (e.hash && this.onReplicationQueued) {\n          this.onReplicationQueued(e)\n        }\n        try {\n          // Replicate the log starting from the entry's hash (CID)\n          const log = await this._replicateLog(e)\n          // Add the fetched log to the internal cache to wait\n          // for \"onReplicationComplete\"\n          this._logs.push(log)\n        } catch (e) {\n          console.error(e)\n          throw e\n        }\n        // Remove from internal cache\n        delete this._fetching[e.hash || e]\n      }\n    }\n\n    if (entries.length > 0) {\n      // Create a processing tasks from each entry/hash that we\n      // should include based on the exclusion filter function\n      const tasks = entries\n        .filter((e) => !shouldExclude(e.hash || e))\n        .map((e) => createReplicationTask(e))\n      // Add the tasks to the processing queue\n      if (tasks.length > 0) {\n        this._q.addAll(tasks)\n      }\n    }\n  }\n\n  async stop () {\n    // Clear the task queue\n    this._q.pause()\n    this._q.clear()\n    await this._q.onIdle()\n    // Reset internal caches\n    this._logs = []\n    this._fetching = {}\n    this._fetched = {}\n  }\n\n  async _replicateLog (entry) {\n    const hash = entry.hash || entry\n\n    // Notify the Store that we made progress\n    const onProgressCallback = (entry) => {\n      this._fetched[entry.hash] = true\n      if (this.onReplicationProgress) {\n        this.onReplicationProgress(entry)\n      }\n    }\n\n    const shouldExclude = (h) => h && h !== hash && this._store._oplog && (this._store._oplog.has(h) || this._fetching[h] !== undefined || this._fetched[h] !== undefined)\n\n    // Fetch and load a log from the entry hash\n    const log = await Log.fromEntryHash(\n      this._store._ipfs,\n      this._store.identity,\n      hash,\n      {\n        logId: this._store.id,\n        access: this._store.access,\n        length: -1,\n        exclude: [],\n        shouldExclude,\n        concurrency: this._concurrency,\n        onProgressCallback\n      }\n    )\n\n    // Return all next pointers\n    const nexts = log.values.map(getNextAndRefsUnion).reduce(flatMap, [])\n    try {\n      // Add the next (hashes) to the processing queue\n      this._addToQueue(nexts)\n    } catch (e) {\n      console.error(e)\n      throw e\n    }\n    // Return the log\n    return log\n  }\n}\n\nmodule.exports = Replicator\n"],"mappings":"AAAA,MAAMA,MAAM,GAAGC,OAAO,CAAC,SAAD,CAAP,CAAmBC,OAAlC;;AACA,MAAMC,GAAG,GAAGF,OAAO,CAAC,UAAD,CAAnB;;AAEA,MAAMG,mBAAmB,GAAGC,CAAC,IAAI,CAAC,GAAG,IAAIC,GAAJ,CAAQ,CAAC,GAAGD,CAAC,CAACE,IAAN,EAAY,GAAGF,CAAC,CAACG,IAAjB,CAAR,CAAJ,CAAjC;;AACA,MAAMC,OAAO,GAAG,CAACC,GAAD,EAAMC,GAAN,KAAcD,GAAG,CAACE,MAAJ,CAAWD,GAAX,CAA9B;;AAEA,MAAME,kBAAkB,GAAG,EAA3B;;AAEA,MAAMC,UAAN,CAAiB;EACfC,WAAW,CAAEC,KAAF,EAASC,WAAT,EAAsB;IAC/B,KAAKC,MAAL,GAAcF,KAAd;IACA,KAAKG,YAAL,GAAoBF,WAAW,IAAIJ,kBAAnC,CAF+B,CAI/B;IACA;;IACA,KAAKO,EAAL,GAAU,IAAIpB,MAAJ,CAAW;MAAEiB,WAAW,EAAE,KAAKE;IAApB,CAAX,CAAV;IAEA;IAEA;IACA;;IACA,KAAKE,KAAL,GAAa,EAAb,CAZ+B,CAa/B;IACA;IACA;;IACA,KAAKC,SAAL,GAAiB,EAAjB,CAhB+B,CAiB/B;IACA;;IACA,KAAKC,QAAL,GAAgB,EAAhB,CAnB+B,CAqB/B;IACA;IACA;IACA;;IACA,KAAKH,EAAL,CAAQI,EAAR,CAAW,MAAX,EAAmB,YAAY;MAC7B,MAAMC,IAAI,GAAG,KAAKJ,KAAL,CAAWK,KAAX,EAAb;;MACA,KAAKL,KAAL,GAAa,EAAb;;MACA,IAAI,KAAKM,qBAAL,IAA8BF,IAAI,CAACG,MAAL,GAAc,CAA5C,IAAiD,KAAKV,MAAL,CAAYW,MAAjE,EAAyE;QACvE,IAAI;UACF,MAAM,KAAKF,qBAAL,CAA2BF,IAA3B,CAAN,CADE,CAEF;;UACAA,IAAI,CAACK,OAAL,CAAaC,GAAG,IAAIA,GAAG,CAACC,MAAJ,CAAWF,OAAX,CAAmBzB,CAAC,IAAI,OAAO,KAAKkB,QAAL,CAAclB,CAAC,CAAC4B,IAAhB,CAA/B,CAApB;QACD,CAJD,CAIE,OAAO5B,CAAP,EAAU;UACV6B,OAAO,CAACC,KAAR,CAAc9B,CAAd;QACD;MACF;IACF,CAZD;EAaD;EAED;AACF;AACA;AACA;;;EACkB,IAAZ+B,YAAY,GAAI;IAClB,OAAO,KAAKhB,EAAL,CAAQiB,OAAf;EACD;EAED;AACF;AACA;AACA;;;EACiB,IAAXC,WAAW,GAAI;IACjB,OAAO,KAAKlB,EAAL,CAAQmB,IAAf;EACD;EAED;AACF;AACA;AACA;;;EACgB,IAAVC,UAAU,GAAI;IAChB,OAAOC,MAAM,CAACC,IAAP,CAAY,KAAKpB,SAAjB,CAAP;EACD;EAED;AACF;AACA;AACA;;;EACY,MAAJqB,IAAI,CAAEC,OAAF,EAAW;IACnB,IAAI;MACF;MACA,KAAKC,WAAL,CAAiBD,OAAjB;IACD,CAHD,CAGE,OAAOvC,CAAP,EAAU;MACV6B,OAAO,CAACC,KAAR,CAAc9B,CAAd;IACD;EACF;;EAEgB,MAAXwC,WAAW,CAAED,OAAF,EAAW;IAC1B;IACA,MAAME,aAAa,GAAIC,CAAD,IAAOA,CAAC,IAAI,KAAK7B,MAAL,CAAYW,MAAjB,KAA4B,KAAKX,MAAL,CAAYW,MAAZ,CAAmBmB,GAAnB,CAAuBD,CAAvB,KAA6B,KAAKzB,SAAL,CAAeyB,CAAf,MAAsBE,SAAnD,IAAgE,KAAK1B,QAAL,CAAcwB,CAAd,CAA5F,CAA7B,CAF0B,CAI1B;;;IACA,MAAMG,qBAAqB,GAAI7C,CAAD,IAAO;MACnC;MACA,KAAKiB,SAAL,CAAejB,CAAC,CAAC4B,IAAF,IAAU5B,CAAzB,IAA8B,IAA9B,CAFmC,CAGnC;MACA;;MACA,OAAO,YAAY;QACjB;QACA;QACA,IAAIA,CAAC,CAAC4B,IAAF,IAAU,KAAKkB,mBAAnB,EAAwC;UACtC,KAAKA,mBAAL,CAAyB9C,CAAzB;QACD;;QACD,IAAI;UACF;UACA,MAAM0B,GAAG,GAAG,MAAM,KAAKqB,aAAL,CAAmB/C,CAAnB,CAAlB,CAFE,CAGF;UACA;;UACA,KAAKgB,KAAL,CAAWgC,IAAX,CAAgBtB,GAAhB;QACD,CAND,CAME,OAAO1B,CAAP,EAAU;UACV6B,OAAO,CAACC,KAAR,CAAc9B,CAAd;UACA,MAAMA,CAAN;QACD,CAfgB,CAgBjB;;;QACA,OAAO,KAAKiB,SAAL,CAAejB,CAAC,CAAC4B,IAAF,IAAU5B,CAAzB,CAAP;MACD,CAlBD;IAmBD,CAxBD;;IA0BA,IAAIuC,OAAO,CAAChB,MAAR,GAAiB,CAArB,EAAwB;MACtB;MACA;MACA,MAAM0B,KAAK,GAAGV,OAAO,CAClBW,MADW,CACHlD,CAAD,IAAO,CAACyC,aAAa,CAACzC,CAAC,CAAC4B,IAAF,IAAU5B,CAAX,CADjB,EAEXmD,GAFW,CAENnD,CAAD,IAAO6C,qBAAqB,CAAC7C,CAAD,CAFrB,CAAd,CAHsB,CAMtB;;MACA,IAAIiD,KAAK,CAAC1B,MAAN,GAAe,CAAnB,EAAsB;QACpB,KAAKR,EAAL,CAAQqC,MAAR,CAAeH,KAAf;MACD;IACF;EACF;;EAES,MAAJI,IAAI,GAAI;IACZ;IACA,KAAKtC,EAAL,CAAQuC,KAAR;;IACA,KAAKvC,EAAL,CAAQwC,KAAR;;IACA,MAAM,KAAKxC,EAAL,CAAQyC,MAAR,EAAN,CAJY,CAKZ;;IACA,KAAKxC,KAAL,GAAa,EAAb;IACA,KAAKC,SAAL,GAAiB,EAAjB;IACA,KAAKC,QAAL,GAAgB,EAAhB;EACD;;EAEkB,MAAb6B,aAAa,CAAEU,KAAF,EAAS;IAC1B,MAAM7B,IAAI,GAAG6B,KAAK,CAAC7B,IAAN,IAAc6B,KAA3B,CAD0B,CAG1B;;IACA,MAAMC,kBAAkB,GAAID,KAAD,IAAW;MACpC,KAAKvC,QAAL,CAAcuC,KAAK,CAAC7B,IAApB,IAA4B,IAA5B;;MACA,IAAI,KAAK+B,qBAAT,EAAgC;QAC9B,KAAKA,qBAAL,CAA2BF,KAA3B;MACD;IACF,CALD;;IAOA,MAAMhB,aAAa,GAAIC,CAAD,IAAOA,CAAC,IAAIA,CAAC,KAAKd,IAAX,IAAmB,KAAKf,MAAL,CAAYW,MAA/B,KAA0C,KAAKX,MAAL,CAAYW,MAAZ,CAAmBmB,GAAnB,CAAuBD,CAAvB,KAA6B,KAAKzB,SAAL,CAAeyB,CAAf,MAAsBE,SAAnD,IAAgE,KAAK1B,QAAL,CAAcwB,CAAd,MAAqBE,SAA/H,CAA7B,CAX0B,CAa1B;;;IACA,MAAMlB,GAAG,GAAG,MAAM5B,GAAG,CAAC8D,aAAJ,CAChB,KAAK/C,MAAL,CAAYgD,KADI,EAEhB,KAAKhD,MAAL,CAAYiD,QAFI,EAGhBlC,IAHgB,EAIhB;MACEmC,KAAK,EAAE,KAAKlD,MAAL,CAAYmD,EADrB;MAEEC,MAAM,EAAE,KAAKpD,MAAL,CAAYoD,MAFtB;MAGE1C,MAAM,EAAE,CAAC,CAHX;MAIE2C,OAAO,EAAE,EAJX;MAKEzB,aALF;MAME7B,WAAW,EAAE,KAAKE,YANpB;MAOE4C;IAPF,CAJgB,CAAlB,CAd0B,CA6B1B;;IACA,MAAMS,KAAK,GAAGzC,GAAG,CAACC,MAAJ,CAAWwB,GAAX,CAAepD,mBAAf,EAAoCqE,MAApC,CAA2ChE,OAA3C,EAAoD,EAApD,CAAd;;IACA,IAAI;MACF;MACA,KAAKoC,WAAL,CAAiB2B,KAAjB;IACD,CAHD,CAGE,OAAOnE,CAAP,EAAU;MACV6B,OAAO,CAACC,KAAR,CAAc9B,CAAd;MACA,MAAMA,CAAN;IACD,CArCyB,CAsC1B;;;IACA,OAAO0B,GAAP;EACD;;AA7Kc;;AAgLjB2C,MAAM,CAACC,OAAP,GAAiB7D,UAAjB"},"metadata":{},"sourceType":"script"}