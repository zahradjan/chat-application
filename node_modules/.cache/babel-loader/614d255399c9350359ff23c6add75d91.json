{"ast":null,"code":"'use strict';\n\nconst Entry = require('./entry');\n\nconst EntryIO = require('./entry-io');\n\nconst Sorting = require('./log-sorting');\n\nconst {\n  LastWriteWins,\n  NoZeroes\n} = Sorting;\n\nconst LogError = require('./log-errors');\n\nconst {\n  isDefined,\n  findUniques,\n  difference,\n  io\n} = require('./utils');\n\nconst IPLD_LINKS = ['heads'];\n\nconst last = (arr, n) => arr.slice(arr.length - Math.min(arr.length, n), arr.length);\n\nclass LogIO {\n  //\n\n  /**\n   * Get the multihash of a Log.\n   * @param {IPFS} ipfs An IPFS instance\n   * @param {Log} log Log to get a multihash for\n   * @returns {Promise<string>}\n   * @deprecated\n   */\n  static async toMultihash(ipfs, log) {\n    let {\n      format\n    } = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n    if (!isDefined(ipfs)) throw LogError.IPFSNotDefinedError();\n    if (!isDefined(log)) throw LogError.LogNotDefinedError();\n    if (!isDefined(format)) format = 'dag-cbor';\n    if (log.values.length < 1) throw new Error('Can\\'t serialize an empty log');\n    return io.write(ipfs, format, log.toJSON(), {\n      links: IPLD_LINKS\n    });\n  }\n  /**\n   * Create a log from a hashes.\n   * @param {IPFS} ipfs An IPFS instance\n   * @param {string} hash The hash of the log\n   * @param {Object} options\n   * @param {number} options.length How many items to include in the log\n   * @param {Array<Entry>} options.exclude Entries to not fetch (cached)\n   * @param {function(hash, entry, parent, depth)} options.onProgressCallback\n   */\n\n\n  static async fromMultihash(ipfs, hash, _ref) {\n    let {\n      length = -1,\n      exclude = [],\n      shouldExclude,\n      timeout,\n      concurrency,\n      sortFn,\n      onProgressCallback\n    } = _ref;\n    if (!isDefined(ipfs)) throw LogError.IPFSNotDefinedError();\n    if (!isDefined(hash)) throw new Error(`Invalid hash: ${hash}`);\n    const logData = await io.read(ipfs, hash, {\n      links: IPLD_LINKS\n    });\n    if (!logData.heads || !logData.id) throw LogError.NotALogError(); // Use user provided sorting function or the default one\n\n    sortFn = sortFn || NoZeroes(LastWriteWins);\n\n    const isHead = e => logData.heads.includes(e.hash);\n\n    const all = await EntryIO.fetchAll(ipfs, logData.heads, {\n      length,\n      exclude,\n      shouldExclude,\n      timeout,\n      concurrency,\n      onProgressCallback\n    });\n    const logId = logData.id;\n    const entries = length > -1 ? last(all.sort(sortFn), length) : all;\n    const heads = entries.filter(isHead);\n    return {\n      logId,\n      entries,\n      heads\n    };\n  }\n  /**\n   * Create a log from an entry hash.\n   * @param {IPFS} ipfs An IPFS instance\n   * @param {string} hash The hash of the entry\n   * @param {Object} options\n   * @param {number} options.length How many items to include in the log\n   * @param {Array<Entry>} options.exclude Entries to not fetch (cached)\n   * @param {function(hash, entry, parent, depth)} options.onProgressCallback\n   */\n\n\n  static async fromEntryHash(ipfs, hash, _ref2) {\n    let {\n      length = -1,\n      exclude = [],\n      shouldExclude,\n      timeout,\n      concurrency,\n      sortFn,\n      onProgressCallback\n    } = _ref2;\n    if (!isDefined(ipfs)) throw LogError.IpfsNotDefinedError();\n    if (!isDefined(hash)) throw new Error(\"'hash' must be defined\"); // Convert input hash(s) to an array\n\n    const hashes = Array.isArray(hash) ? hash : [hash]; // Fetch given length, return size at least the given input entries\n\n    length = length > -1 ? Math.max(length, 1) : length;\n    const all = await EntryIO.fetchParallel(ipfs, hashes, {\n      length,\n      exclude,\n      shouldExclude,\n      timeout,\n      concurrency,\n      onProgressCallback\n    }); // Cap the result at the right size by taking the last n entries,\n    // or if given length is -1, then take all\n\n    sortFn = sortFn || NoZeroes(LastWriteWins);\n    const entries = length > -1 ? last(all.sort(sortFn), length) : all;\n    return {\n      entries\n    };\n  }\n  /**\n   * Creates a log data from a JSON object, to be passed to a Log constructor\n   *\n   * @param {IPFS} ipfs An IPFS instance\n   * @param {json} json A json object containing valid log data\n   * @param {Object} options\n   * @param {number} options.length How many entries to include\n   * @param {function(hash, entry, parent, depth)} options.onProgressCallback\n   **/\n\n\n  static async fromJSON(ipfs, json, _ref3) {\n    let {\n      length = -1,\n      timeout,\n      concurrency,\n      onProgressCallback\n    } = _ref3;\n    if (!isDefined(ipfs)) throw LogError.IPFSNotDefinedError();\n    const {\n      id,\n      heads\n    } = json;\n    const headHashes = heads.map(e => e.hash);\n    const all = await EntryIO.fetchParallel(ipfs, headHashes, {\n      length,\n      timeout,\n      concurrency,\n      onProgressCallback\n    });\n    const entries = all.sort(Entry.compare);\n    return {\n      logId: id,\n      entries,\n      heads\n    };\n  }\n  /**\n   * Create a new log starting from an entry.\n   * @param {IPFS} ipfs An IPFS instance\n   * @param {Entry|Array<Entry>} sourceEntries An entry or an array of entries to fetch a log from\n   * @param {Object} options\n   * @param {number} options.length How many entries to include\n   * @param {Array<Entry>} options.exclude Entries to not fetch (cached)\n   * @param {function(hash, entry, parent, depth)} options.onProgressCallback\n   */\n\n\n  static async fromEntry(ipfs, sourceEntries, _ref4) {\n    let {\n      length = -1,\n      exclude = [],\n      shouldExclude,\n      timeout,\n      concurrency,\n      onProgressCallback\n    } = _ref4;\n    if (!isDefined(ipfs)) throw LogError.IPFSNotDefinedError();\n    if (!isDefined(sourceEntries)) throw new Error(\"'sourceEntries' must be defined\"); // Make sure we only have Entry objects as input\n\n    if (!Array.isArray(sourceEntries) && !Entry.isEntry(sourceEntries)) {\n      throw new Error('\\'sourceEntries\\' argument must be an array of Entry instances or a single Entry');\n    }\n\n    if (!Array.isArray(sourceEntries)) {\n      sourceEntries = [sourceEntries];\n    } // Fetch given length, return size at least the given input entries\n\n\n    length = length > -1 ? Math.max(length, sourceEntries.length) : length; // Make sure we pass hashes instead of objects to the fetcher function\n\n    const hashes = sourceEntries.map(e => e.hash); // Fetch the entries\n\n    const all = await EntryIO.fetchParallel(ipfs, hashes, {\n      length,\n      exclude,\n      shouldExclude,\n      timeout,\n      concurrency,\n      onProgressCallback\n    }); // Combine the fetches with the source entries and take only uniques\n\n    const combined = sourceEntries.concat(all).concat(exclude);\n    const uniques = findUniques(combined, 'hash').sort(Entry.compare); // Cap the result at the right size by taking the last n entries\n\n    const sliced = uniques.slice(length > -1 ? -length : -uniques.length); // Make sure that the given input entries are present in the result\n    // in order to not lose references\n\n    const missingSourceEntries = difference(sliced, sourceEntries, 'hash');\n\n    const replaceInFront = (a, withEntries) => {\n      const sliced = a.slice(withEntries.length, a.length);\n      return withEntries.concat(sliced);\n    }; // Add the input entries at the beginning of the array and remove\n    // as many elements from the array before inserting the original entries\n\n\n    const entries = replaceInFront(sliced, missingSourceEntries);\n    const logId = entries[entries.length - 1].id;\n    return {\n      logId,\n      entries\n    };\n  }\n\n}\n\nmodule.exports = LogIO;","map":{"version":3,"names":["Entry","require","EntryIO","Sorting","LastWriteWins","NoZeroes","LogError","isDefined","findUniques","difference","io","IPLD_LINKS","last","arr","n","slice","length","Math","min","LogIO","toMultihash","ipfs","log","format","IPFSNotDefinedError","LogNotDefinedError","values","Error","write","toJSON","links","fromMultihash","hash","exclude","shouldExclude","timeout","concurrency","sortFn","onProgressCallback","logData","read","heads","id","NotALogError","isHead","e","includes","all","fetchAll","logId","entries","sort","filter","fromEntryHash","IpfsNotDefinedError","hashes","Array","isArray","max","fetchParallel","fromJSON","json","headHashes","map","compare","fromEntry","sourceEntries","isEntry","combined","concat","uniques","sliced","missingSourceEntries","replaceInFront","a","withEntries","module","exports"],"sources":["C:/Users/zajan/GitHub/chatApplication/node_modules/ipfs-log/src/log-io.js"],"sourcesContent":["'use strict'\n\nconst Entry = require('./entry')\nconst EntryIO = require('./entry-io')\nconst Sorting = require('./log-sorting')\nconst { LastWriteWins, NoZeroes } = Sorting\nconst LogError = require('./log-errors')\nconst { isDefined, findUniques, difference, io } = require('./utils')\n\nconst IPLD_LINKS = ['heads']\nconst last = (arr, n) => arr.slice(arr.length - Math.min(arr.length, n), arr.length)\n\nclass LogIO {\n  //\n  /**\n   * Get the multihash of a Log.\n   * @param {IPFS} ipfs An IPFS instance\n   * @param {Log} log Log to get a multihash for\n   * @returns {Promise<string>}\n   * @deprecated\n   */\n  static async toMultihash (ipfs, log, { format } = {}) {\n    if (!isDefined(ipfs)) throw LogError.IPFSNotDefinedError()\n    if (!isDefined(log)) throw LogError.LogNotDefinedError()\n    if (!isDefined(format)) format = 'dag-cbor'\n    if (log.values.length < 1) throw new Error('Can\\'t serialize an empty log')\n\n    return io.write(ipfs, format, log.toJSON(), { links: IPLD_LINKS })\n  }\n\n  /**\n   * Create a log from a hashes.\n   * @param {IPFS} ipfs An IPFS instance\n   * @param {string} hash The hash of the log\n   * @param {Object} options\n   * @param {number} options.length How many items to include in the log\n   * @param {Array<Entry>} options.exclude Entries to not fetch (cached)\n   * @param {function(hash, entry, parent, depth)} options.onProgressCallback\n   */\n  static async fromMultihash (ipfs, hash,\n    { length = -1, exclude = [], shouldExclude, timeout, concurrency, sortFn, onProgressCallback }) {\n    if (!isDefined(ipfs)) throw LogError.IPFSNotDefinedError()\n    if (!isDefined(hash)) throw new Error(`Invalid hash: ${hash}`)\n\n    const logData = await io.read(ipfs, hash, { links: IPLD_LINKS })\n\n    if (!logData.heads || !logData.id) throw LogError.NotALogError()\n\n    // Use user provided sorting function or the default one\n    sortFn = sortFn || NoZeroes(LastWriteWins)\n    const isHead = e => logData.heads.includes(e.hash)\n\n    const all = await EntryIO.fetchAll(ipfs, logData.heads,\n      { length, exclude, shouldExclude, timeout, concurrency, onProgressCallback })\n\n    const logId = logData.id\n    const entries = length > -1 ? last(all.sort(sortFn), length) : all\n    const heads = entries.filter(isHead)\n    return { logId, entries, heads }\n  }\n\n  /**\n   * Create a log from an entry hash.\n   * @param {IPFS} ipfs An IPFS instance\n   * @param {string} hash The hash of the entry\n   * @param {Object} options\n   * @param {number} options.length How many items to include in the log\n   * @param {Array<Entry>} options.exclude Entries to not fetch (cached)\n   * @param {function(hash, entry, parent, depth)} options.onProgressCallback\n   */\n  static async fromEntryHash (ipfs, hash,\n    { length = -1, exclude = [], shouldExclude, timeout, concurrency, sortFn, onProgressCallback }) {\n    if (!isDefined(ipfs)) throw LogError.IpfsNotDefinedError()\n    if (!isDefined(hash)) throw new Error(\"'hash' must be defined\")\n    // Convert input hash(s) to an array\n    const hashes = Array.isArray(hash) ? hash : [hash]\n    // Fetch given length, return size at least the given input entries\n    length = length > -1 ? Math.max(length, 1) : length\n    const all = await EntryIO.fetchParallel(ipfs, hashes,\n      { length, exclude, shouldExclude, timeout, concurrency, onProgressCallback })\n    // Cap the result at the right size by taking the last n entries,\n    // or if given length is -1, then take all\n    sortFn = sortFn || NoZeroes(LastWriteWins)\n    const entries = length > -1 ? last(all.sort(sortFn), length) : all\n    return { entries }\n  }\n\n  /**\n   * Creates a log data from a JSON object, to be passed to a Log constructor\n   *\n   * @param {IPFS} ipfs An IPFS instance\n   * @param {json} json A json object containing valid log data\n   * @param {Object} options\n   * @param {number} options.length How many entries to include\n   * @param {function(hash, entry, parent, depth)} options.onProgressCallback\n   **/\n  static async fromJSON (ipfs, json, { length = -1, timeout, concurrency, onProgressCallback }) {\n    if (!isDefined(ipfs)) throw LogError.IPFSNotDefinedError()\n    const { id, heads } = json\n    const headHashes = heads.map(e => e.hash)\n    const all = await EntryIO.fetchParallel(ipfs, headHashes,\n      { length, timeout, concurrency, onProgressCallback })\n    const entries = all.sort(Entry.compare)\n    return { logId: id, entries, heads }\n  }\n\n  /**\n   * Create a new log starting from an entry.\n   * @param {IPFS} ipfs An IPFS instance\n   * @param {Entry|Array<Entry>} sourceEntries An entry or an array of entries to fetch a log from\n   * @param {Object} options\n   * @param {number} options.length How many entries to include\n   * @param {Array<Entry>} options.exclude Entries to not fetch (cached)\n   * @param {function(hash, entry, parent, depth)} options.onProgressCallback\n   */\n  static async fromEntry (ipfs, sourceEntries,\n    { length = -1, exclude = [], shouldExclude, timeout, concurrency, onProgressCallback }) {\n    if (!isDefined(ipfs)) throw LogError.IPFSNotDefinedError()\n    if (!isDefined(sourceEntries)) throw new Error(\"'sourceEntries' must be defined\")\n\n    // Make sure we only have Entry objects as input\n    if (!Array.isArray(sourceEntries) && !Entry.isEntry(sourceEntries)) {\n      throw new Error('\\'sourceEntries\\' argument must be an array of Entry instances or a single Entry')\n    }\n\n    if (!Array.isArray(sourceEntries)) {\n      sourceEntries = [sourceEntries]\n    }\n\n    // Fetch given length, return size at least the given input entries\n    length = length > -1 ? Math.max(length, sourceEntries.length) : length\n\n    // Make sure we pass hashes instead of objects to the fetcher function\n    const hashes = sourceEntries.map(e => e.hash)\n\n    // Fetch the entries\n    const all = await EntryIO.fetchParallel(ipfs, hashes,\n      { length, exclude, shouldExclude, timeout, concurrency, onProgressCallback })\n\n    // Combine the fetches with the source entries and take only uniques\n    const combined = sourceEntries.concat(all).concat(exclude)\n    const uniques = findUniques(combined, 'hash').sort(Entry.compare)\n\n    // Cap the result at the right size by taking the last n entries\n    const sliced = uniques.slice(length > -1 ? -length : -uniques.length)\n\n    // Make sure that the given input entries are present in the result\n    // in order to not lose references\n    const missingSourceEntries = difference(sliced, sourceEntries, 'hash')\n\n    const replaceInFront = (a, withEntries) => {\n      const sliced = a.slice(withEntries.length, a.length)\n      return withEntries.concat(sliced)\n    }\n\n    // Add the input entries at the beginning of the array and remove\n    // as many elements from the array before inserting the original entries\n    const entries = replaceInFront(sliced, missingSourceEntries)\n    const logId = entries[entries.length - 1].id\n    return { logId, entries }\n  }\n}\n\nmodule.exports = LogIO\n"],"mappings":"AAAA;;AAEA,MAAMA,KAAK,GAAGC,OAAO,CAAC,SAAD,CAArB;;AACA,MAAMC,OAAO,GAAGD,OAAO,CAAC,YAAD,CAAvB;;AACA,MAAME,OAAO,GAAGF,OAAO,CAAC,eAAD,CAAvB;;AACA,MAAM;EAAEG,aAAF;EAAiBC;AAAjB,IAA8BF,OAApC;;AACA,MAAMG,QAAQ,GAAGL,OAAO,CAAC,cAAD,CAAxB;;AACA,MAAM;EAAEM,SAAF;EAAaC,WAAb;EAA0BC,UAA1B;EAAsCC;AAAtC,IAA6CT,OAAO,CAAC,SAAD,CAA1D;;AAEA,MAAMU,UAAU,GAAG,CAAC,OAAD,CAAnB;;AACA,MAAMC,IAAI,GAAG,CAACC,GAAD,EAAMC,CAAN,KAAYD,GAAG,CAACE,KAAJ,CAAUF,GAAG,CAACG,MAAJ,GAAaC,IAAI,CAACC,GAAL,CAASL,GAAG,CAACG,MAAb,EAAqBF,CAArB,CAAvB,EAAgDD,GAAG,CAACG,MAApD,CAAzB;;AAEA,MAAMG,KAAN,CAAY;EACV;;EACA;AACF;AACA;AACA;AACA;AACA;AACA;EAC0B,aAAXC,WAAW,CAAEC,IAAF,EAAQC,GAAR,EAA8B;IAAA,IAAjB;MAAEC;IAAF,CAAiB,uEAAJ,EAAI;IACpD,IAAI,CAAChB,SAAS,CAACc,IAAD,CAAd,EAAsB,MAAMf,QAAQ,CAACkB,mBAAT,EAAN;IACtB,IAAI,CAACjB,SAAS,CAACe,GAAD,CAAd,EAAqB,MAAMhB,QAAQ,CAACmB,kBAAT,EAAN;IACrB,IAAI,CAAClB,SAAS,CAACgB,MAAD,CAAd,EAAwBA,MAAM,GAAG,UAAT;IACxB,IAAID,GAAG,CAACI,MAAJ,CAAWV,MAAX,GAAoB,CAAxB,EAA2B,MAAM,IAAIW,KAAJ,CAAU,+BAAV,CAAN;IAE3B,OAAOjB,EAAE,CAACkB,KAAH,CAASP,IAAT,EAAeE,MAAf,EAAuBD,GAAG,CAACO,MAAJ,EAAvB,EAAqC;MAAEC,KAAK,EAAEnB;IAAT,CAArC,CAAP;EACD;EAED;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;EAC4B,aAAboB,aAAa,CAAEV,IAAF,EAAQW,IAAR,QACwE;IAAA,IAAhG;MAAEhB,MAAM,GAAG,CAAC,CAAZ;MAAeiB,OAAO,GAAG,EAAzB;MAA6BC,aAA7B;MAA4CC,OAA5C;MAAqDC,WAArD;MAAkEC,MAAlE;MAA0EC;IAA1E,CAAgG;IAChG,IAAI,CAAC/B,SAAS,CAACc,IAAD,CAAd,EAAsB,MAAMf,QAAQ,CAACkB,mBAAT,EAAN;IACtB,IAAI,CAACjB,SAAS,CAACyB,IAAD,CAAd,EAAsB,MAAM,IAAIL,KAAJ,CAAW,iBAAgBK,IAAK,EAAhC,CAAN;IAEtB,MAAMO,OAAO,GAAG,MAAM7B,EAAE,CAAC8B,IAAH,CAAQnB,IAAR,EAAcW,IAAd,EAAoB;MAAEF,KAAK,EAAEnB;IAAT,CAApB,CAAtB;IAEA,IAAI,CAAC4B,OAAO,CAACE,KAAT,IAAkB,CAACF,OAAO,CAACG,EAA/B,EAAmC,MAAMpC,QAAQ,CAACqC,YAAT,EAAN,CAN6D,CAQhG;;IACAN,MAAM,GAAGA,MAAM,IAAIhC,QAAQ,CAACD,aAAD,CAA3B;;IACA,MAAMwC,MAAM,GAAGC,CAAC,IAAIN,OAAO,CAACE,KAAR,CAAcK,QAAd,CAAuBD,CAAC,CAACb,IAAzB,CAApB;;IAEA,MAAMe,GAAG,GAAG,MAAM7C,OAAO,CAAC8C,QAAR,CAAiB3B,IAAjB,EAAuBkB,OAAO,CAACE,KAA/B,EAChB;MAAEzB,MAAF;MAAUiB,OAAV;MAAmBC,aAAnB;MAAkCC,OAAlC;MAA2CC,WAA3C;MAAwDE;IAAxD,CADgB,CAAlB;IAGA,MAAMW,KAAK,GAAGV,OAAO,CAACG,EAAtB;IACA,MAAMQ,OAAO,GAAGlC,MAAM,GAAG,CAAC,CAAV,GAAcJ,IAAI,CAACmC,GAAG,CAACI,IAAJ,CAASd,MAAT,CAAD,EAAmBrB,MAAnB,CAAlB,GAA+C+B,GAA/D;IACA,MAAMN,KAAK,GAAGS,OAAO,CAACE,MAAR,CAAeR,MAAf,CAAd;IACA,OAAO;MAAEK,KAAF;MAASC,OAAT;MAAkBT;IAAlB,CAAP;EACD;EAED;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;EAC4B,aAAbY,aAAa,CAAEhC,IAAF,EAAQW,IAAR,SACwE;IAAA,IAAhG;MAAEhB,MAAM,GAAG,CAAC,CAAZ;MAAeiB,OAAO,GAAG,EAAzB;MAA6BC,aAA7B;MAA4CC,OAA5C;MAAqDC,WAArD;MAAkEC,MAAlE;MAA0EC;IAA1E,CAAgG;IAChG,IAAI,CAAC/B,SAAS,CAACc,IAAD,CAAd,EAAsB,MAAMf,QAAQ,CAACgD,mBAAT,EAAN;IACtB,IAAI,CAAC/C,SAAS,CAACyB,IAAD,CAAd,EAAsB,MAAM,IAAIL,KAAJ,CAAU,wBAAV,CAAN,CAF0E,CAGhG;;IACA,MAAM4B,MAAM,GAAGC,KAAK,CAACC,OAAN,CAAczB,IAAd,IAAsBA,IAAtB,GAA6B,CAACA,IAAD,CAA5C,CAJgG,CAKhG;;IACAhB,MAAM,GAAGA,MAAM,GAAG,CAAC,CAAV,GAAcC,IAAI,CAACyC,GAAL,CAAS1C,MAAT,EAAiB,CAAjB,CAAd,GAAoCA,MAA7C;IACA,MAAM+B,GAAG,GAAG,MAAM7C,OAAO,CAACyD,aAAR,CAAsBtC,IAAtB,EAA4BkC,MAA5B,EAChB;MAAEvC,MAAF;MAAUiB,OAAV;MAAmBC,aAAnB;MAAkCC,OAAlC;MAA2CC,WAA3C;MAAwDE;IAAxD,CADgB,CAAlB,CAPgG,CAShG;IACA;;IACAD,MAAM,GAAGA,MAAM,IAAIhC,QAAQ,CAACD,aAAD,CAA3B;IACA,MAAM8C,OAAO,GAAGlC,MAAM,GAAG,CAAC,CAAV,GAAcJ,IAAI,CAACmC,GAAG,CAACI,IAAJ,CAASd,MAAT,CAAD,EAAmBrB,MAAnB,CAAlB,GAA+C+B,GAA/D;IACA,OAAO;MAAEG;IAAF,CAAP;EACD;EAED;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;EACuB,aAARU,QAAQ,CAAEvC,IAAF,EAAQwC,IAAR,SAAyE;IAAA,IAA3D;MAAE7C,MAAM,GAAG,CAAC,CAAZ;MAAemB,OAAf;MAAwBC,WAAxB;MAAqCE;IAArC,CAA2D;IAC5F,IAAI,CAAC/B,SAAS,CAACc,IAAD,CAAd,EAAsB,MAAMf,QAAQ,CAACkB,mBAAT,EAAN;IACtB,MAAM;MAAEkB,EAAF;MAAMD;IAAN,IAAgBoB,IAAtB;IACA,MAAMC,UAAU,GAAGrB,KAAK,CAACsB,GAAN,CAAUlB,CAAC,IAAIA,CAAC,CAACb,IAAjB,CAAnB;IACA,MAAMe,GAAG,GAAG,MAAM7C,OAAO,CAACyD,aAAR,CAAsBtC,IAAtB,EAA4ByC,UAA5B,EAChB;MAAE9C,MAAF;MAAUmB,OAAV;MAAmBC,WAAnB;MAAgCE;IAAhC,CADgB,CAAlB;IAEA,MAAMY,OAAO,GAAGH,GAAG,CAACI,IAAJ,CAASnD,KAAK,CAACgE,OAAf,CAAhB;IACA,OAAO;MAAEf,KAAK,EAAEP,EAAT;MAAaQ,OAAb;MAAsBT;IAAtB,CAAP;EACD;EAED;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;EACwB,aAATwB,SAAS,CAAE5C,IAAF,EAAQ6C,aAAR,SACoE;IAAA,IAAxF;MAAElD,MAAM,GAAG,CAAC,CAAZ;MAAeiB,OAAO,GAAG,EAAzB;MAA6BC,aAA7B;MAA4CC,OAA5C;MAAqDC,WAArD;MAAkEE;IAAlE,CAAwF;IACxF,IAAI,CAAC/B,SAAS,CAACc,IAAD,CAAd,EAAsB,MAAMf,QAAQ,CAACkB,mBAAT,EAAN;IACtB,IAAI,CAACjB,SAAS,CAAC2D,aAAD,CAAd,EAA+B,MAAM,IAAIvC,KAAJ,CAAU,iCAAV,CAAN,CAFyD,CAIxF;;IACA,IAAI,CAAC6B,KAAK,CAACC,OAAN,CAAcS,aAAd,CAAD,IAAiC,CAAClE,KAAK,CAACmE,OAAN,CAAcD,aAAd,CAAtC,EAAoE;MAClE,MAAM,IAAIvC,KAAJ,CAAU,kFAAV,CAAN;IACD;;IAED,IAAI,CAAC6B,KAAK,CAACC,OAAN,CAAcS,aAAd,CAAL,EAAmC;MACjCA,aAAa,GAAG,CAACA,aAAD,CAAhB;IACD,CAXuF,CAaxF;;;IACAlD,MAAM,GAAGA,MAAM,GAAG,CAAC,CAAV,GAAcC,IAAI,CAACyC,GAAL,CAAS1C,MAAT,EAAiBkD,aAAa,CAAClD,MAA/B,CAAd,GAAuDA,MAAhE,CAdwF,CAgBxF;;IACA,MAAMuC,MAAM,GAAGW,aAAa,CAACH,GAAd,CAAkBlB,CAAC,IAAIA,CAAC,CAACb,IAAzB,CAAf,CAjBwF,CAmBxF;;IACA,MAAMe,GAAG,GAAG,MAAM7C,OAAO,CAACyD,aAAR,CAAsBtC,IAAtB,EAA4BkC,MAA5B,EAChB;MAAEvC,MAAF;MAAUiB,OAAV;MAAmBC,aAAnB;MAAkCC,OAAlC;MAA2CC,WAA3C;MAAwDE;IAAxD,CADgB,CAAlB,CApBwF,CAuBxF;;IACA,MAAM8B,QAAQ,GAAGF,aAAa,CAACG,MAAd,CAAqBtB,GAArB,EAA0BsB,MAA1B,CAAiCpC,OAAjC,CAAjB;IACA,MAAMqC,OAAO,GAAG9D,WAAW,CAAC4D,QAAD,EAAW,MAAX,CAAX,CAA8BjB,IAA9B,CAAmCnD,KAAK,CAACgE,OAAzC,CAAhB,CAzBwF,CA2BxF;;IACA,MAAMO,MAAM,GAAGD,OAAO,CAACvD,KAAR,CAAcC,MAAM,GAAG,CAAC,CAAV,GAAc,CAACA,MAAf,GAAwB,CAACsD,OAAO,CAACtD,MAA/C,CAAf,CA5BwF,CA8BxF;IACA;;IACA,MAAMwD,oBAAoB,GAAG/D,UAAU,CAAC8D,MAAD,EAASL,aAAT,EAAwB,MAAxB,CAAvC;;IAEA,MAAMO,cAAc,GAAG,CAACC,CAAD,EAAIC,WAAJ,KAAoB;MACzC,MAAMJ,MAAM,GAAGG,CAAC,CAAC3D,KAAF,CAAQ4D,WAAW,CAAC3D,MAApB,EAA4B0D,CAAC,CAAC1D,MAA9B,CAAf;MACA,OAAO2D,WAAW,CAACN,MAAZ,CAAmBE,MAAnB,CAAP;IACD,CAHD,CAlCwF,CAuCxF;IACA;;;IACA,MAAMrB,OAAO,GAAGuB,cAAc,CAACF,MAAD,EAASC,oBAAT,CAA9B;IACA,MAAMvB,KAAK,GAAGC,OAAO,CAACA,OAAO,CAAClC,MAAR,GAAiB,CAAlB,CAAP,CAA4B0B,EAA1C;IACA,OAAO;MAAEO,KAAF;MAASC;IAAT,CAAP;EACD;;AApJS;;AAuJZ0B,MAAM,CAACC,OAAP,GAAiB1D,KAAjB"},"metadata":{},"sourceType":"script"}