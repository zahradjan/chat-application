{"ast":null,"code":"'use strict';\n\nconst dagPb = require('@ipld/dag-pb');\n\nconst {\n  CID\n} = require('multiformats/cid');\n\nconst log = require('debug')('ipfs:mfs:core:utils:add-link');\n\nconst {\n  UnixFS\n} = require('ipfs-unixfs');\n\nconst DirSharded = require('./dir-sharded');\n\nconst {\n  updateHamtDirectory,\n  recreateHamtLevel,\n  recreateInitialHamtLevel,\n  createShard,\n  toPrefix,\n  addLinksToHamtBucket\n} = require('./hamt-utils');\n\nconst errCode = require('err-code');\n\nconst last = require('it-last');\n/**\n * @typedef {import('ipfs-unixfs').Mtime} Mtime\n * @typedef {import('multiformats/cid').CIDVersion} CIDVersion\n * @typedef {import('hamt-sharding').Bucket<any>} Bucket\n * @typedef {import('../').MfsContext} MfsContext\n * @typedef {import('@ipld/dag-pb').PBNode} PBNode\n * @typedef {import('@ipld/dag-pb').PBLink} PBLink\n */\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {number} options.shardSplitThreshold\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n * @param {CID} [options.parentCid]\n * @param {PBNode} [options.parent]\n */\n\n\nconst addLink = async (context, options) => {\n  let parent = options.parent;\n\n  if (options.parentCid) {\n    const parentCid = CID.asCID(options.parentCid);\n\n    if (parentCid === null) {\n      throw errCode(new Error('Invalid CID passed to addLink'), 'EINVALIDPARENTCID');\n    }\n\n    if (parentCid.code !== dagPb.code) {\n      throw errCode(new Error('Unsupported codec. Only DAG-PB is supported'), 'EINVALIDPARENTCID');\n    }\n\n    log(`Loading parent node ${parentCid}`);\n    const block = await context.repo.blocks.get(parentCid);\n    parent = dagPb.decode(block);\n  }\n\n  if (!parent) {\n    throw errCode(new Error('No parent node or CID passed to addLink'), 'EINVALIDPARENT');\n  }\n\n  if (!options.cid) {\n    throw errCode(new Error('No child cid passed to addLink'), 'EINVALIDCHILDCID');\n  }\n\n  if (!options.name) {\n    throw errCode(new Error('No child name passed to addLink'), 'EINVALIDCHILDNAME');\n  }\n\n  if (!options.size && options.size !== 0) {\n    throw errCode(new Error('No child size passed to addLink'), 'EINVALIDCHILDSIZE');\n  }\n\n  if (!parent.Data) {\n    throw errCode(new Error('Parent node with no data passed to addLink'), 'ERR_INVALID_PARENT');\n  }\n\n  const meta = UnixFS.unmarshal(parent.Data);\n\n  if (meta.type === 'hamt-sharded-directory') {\n    log('Adding link to sharded directory');\n    return addToShardedDirectory(context, { ...options,\n      parent\n    });\n  }\n\n  if (parent.Links.length >= options.shardSplitThreshold) {\n    log('Converting directory to sharded directory');\n    return convertToShardedDirectory(context, { ...options,\n      parent,\n      mtime: meta.mtime,\n      mode: meta.mode\n    });\n  }\n\n  log(`Adding ${options.name} (${options.cid}) to regular directory`);\n  return addToDirectory(context, { ...options,\n    parent\n  });\n};\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n * @param {Mtime} [options.mtime]\n * @param {number} [options.mode]\n */\n\n\nconst convertToShardedDirectory = async (context, options) => {\n  const result = await createShard(context, options.parent.Links.map(link => ({\n    name: link.Name || '',\n    size: link.Tsize || 0,\n    cid: link.Hash\n  })).concat({\n    name: options.name,\n    size: options.size,\n    cid: options.cid\n  }), options);\n  log(`Converted directory to sharded directory ${result.cid}`);\n  return result;\n};\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n * @param {Mtime} [options.mtime]\n * @param {number} [options.mode]\n */\n\n\nconst addToDirectory = async (context, options) => {\n  // Remove existing link if it exists\n  const parentLinks = options.parent.Links.filter(link => {\n    return link.Name !== options.name;\n  });\n  parentLinks.push({\n    Name: options.name,\n    Tsize: options.size,\n    Hash: options.cid\n  });\n\n  if (!options.parent.Data) {\n    throw errCode(new Error('Parent node with no data passed to addToDirectory'), 'ERR_INVALID_PARENT');\n  }\n\n  const node = UnixFS.unmarshal(options.parent.Data);\n  let data;\n\n  if (node.mtime) {\n    // Update mtime if previously set\n    const ms = Date.now();\n    const secs = Math.floor(ms / 1000);\n    node.mtime = {\n      secs: secs,\n      nsecs: (ms - secs * 1000) * 1000\n    };\n    data = node.marshal();\n  } else {\n    data = options.parent.Data;\n  }\n\n  options.parent = dagPb.prepare({\n    Data: data,\n    Links: parentLinks\n  }); // Persist the new parent PbNode\n\n  const hasher = await context.hashers.getHasher(options.hashAlg);\n  const buf = dagPb.encode(options.parent);\n  const hash = await hasher.digest(buf);\n  const cid = CID.create(options.cidVersion, dagPb.code, hash);\n\n  if (options.flush) {\n    await context.repo.blocks.put(cid, buf);\n  }\n\n  return {\n    node: options.parent,\n    cid,\n    size: buf.length\n  };\n};\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n */\n\n\nconst addToShardedDirectory = async (context, options) => {\n  const {\n    shard,\n    path\n  } = await addFileToShardedDirectory(context, options);\n  const result = await last(shard.flush(context.repo.blocks));\n\n  if (!result) {\n    throw new Error('No result from flushing shard');\n  }\n\n  const block = await context.repo.blocks.get(result.cid);\n  const node = dagPb.decode(block); // we have written out the shard, but only one sub-shard will have been written so replace it in the original shard\n\n  const parentLinks = options.parent.Links.filter(link => {\n    // TODO vmx 2021-03-31: Check that there cannot be multiple ones matching\n    // Remove the old link\n    return (link.Name || '').substring(0, 2) !== path[0].prefix;\n  });\n  const newLink = node.Links.find(link => (link.Name || '').substring(0, 2) === path[0].prefix);\n\n  if (!newLink) {\n    throw new Error(`No link found with prefix ${path[0].prefix}`);\n  }\n\n  parentLinks.push(newLink);\n  return updateHamtDirectory(context, parentLinks, path[0].bucket, options);\n};\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n */\n\n\nconst addFileToShardedDirectory = async (context, options) => {\n  const file = {\n    name: options.name,\n    cid: options.cid,\n    size: options.size\n  };\n\n  if (!options.parent.Data) {\n    throw errCode(new Error('Parent node with no data passed to addFileToShardedDirectory'), 'ERR_INVALID_PARENT');\n  } // start at the root bucket and descend, loading nodes as we go\n\n\n  const rootBucket = await recreateInitialHamtLevel(options.parent.Links);\n  const node = UnixFS.unmarshal(options.parent.Data);\n  const shard = new DirSharded({\n    root: true,\n    dir: true,\n    parent: undefined,\n    parentKey: undefined,\n    path: '',\n    dirty: true,\n    flat: false,\n    mode: node.mode\n  }, options);\n  shard._bucket = rootBucket;\n\n  if (node.mtime) {\n    // update mtime if previously set\n    shard.mtime = {\n      secs: Math.round(Date.now() / 1000)\n    };\n  } // load subshards until the bucket & position no longer changes\n\n\n  const position = await rootBucket._findNewBucketAndPos(file.name);\n  const path = toBucketPath(position);\n  path[0].node = options.parent;\n  let index = 0;\n\n  while (index < path.length) {\n    const segment = path[index];\n    index++;\n    const node = segment.node;\n\n    if (!node) {\n      throw new Error('Segment had no node');\n    }\n\n    const link = node.Links.find(link => (link.Name || '').substring(0, 2) === segment.prefix);\n\n    if (!link) {\n      // prefix is new, file will be added to the current bucket\n      log(`Link ${segment.prefix}${file.name} will be added`);\n      index = path.length;\n      break;\n    }\n\n    if (link.Name === `${segment.prefix}${file.name}`) {\n      // file already existed, file will be added to the current bucket\n      log(`Link ${segment.prefix}${file.name} will be replaced`);\n      index = path.length;\n      break;\n    }\n\n    if ((link.Name || '').length > 2) {\n      // another file had the same prefix, will be replaced with a subshard\n      log(`Link ${link.Name} ${link.Hash} will be replaced with a subshard`);\n      index = path.length;\n      break;\n    } // load sub-shard\n\n\n    log(`Found subshard ${segment.prefix}`);\n    const block = await context.repo.blocks.get(link.Hash);\n    const subShard = dagPb.decode(block); // subshard hasn't been loaded, descend to the next level of the HAMT\n\n    if (!path[index]) {\n      log(`Loaded new subshard ${segment.prefix}`);\n      await recreateHamtLevel(subShard.Links, rootBucket, segment.bucket, parseInt(segment.prefix, 16));\n      const position = await rootBucket._findNewBucketAndPos(file.name);\n      path.push({\n        bucket: position.bucket,\n        prefix: toPrefix(position.pos),\n        node: subShard\n      });\n      break;\n    }\n\n    const nextSegment = path[index]; // add next levels worth of links to bucket\n\n    await addLinksToHamtBucket(subShard.Links, nextSegment.bucket, rootBucket);\n    nextSegment.node = subShard;\n  } // finally add the new file into the shard\n\n\n  await shard._bucket.put(file.name, {\n    size: file.size,\n    cid: file.cid\n  });\n  return {\n    shard,\n    path\n  };\n};\n/**\n * @param {{ pos: number, bucket: Bucket }} position\n * @returns {{ bucket: Bucket, prefix: string, node?: PBNode }[]}\n */\n\n\nconst toBucketPath = position => {\n  const path = [{\n    bucket: position.bucket,\n    prefix: toPrefix(position.pos)\n  }];\n  let bucket = position.bucket._parent;\n  let positionInBucket = position.bucket._posAtParent;\n\n  while (bucket) {\n    path.push({\n      bucket,\n      prefix: toPrefix(positionInBucket)\n    });\n    positionInBucket = bucket._posAtParent;\n    bucket = bucket._parent;\n  }\n\n  path.reverse();\n  return path;\n};\n\nmodule.exports = addLink;","map":{"version":3,"names":["dagPb","require","CID","log","UnixFS","DirSharded","updateHamtDirectory","recreateHamtLevel","recreateInitialHamtLevel","createShard","toPrefix","addLinksToHamtBucket","errCode","last","addLink","context","options","parent","parentCid","asCID","Error","code","block","repo","blocks","get","decode","cid","name","size","Data","meta","unmarshal","type","addToShardedDirectory","Links","length","shardSplitThreshold","convertToShardedDirectory","mtime","mode","addToDirectory","result","map","link","Name","Tsize","Hash","concat","parentLinks","filter","push","node","data","ms","Date","now","secs","Math","floor","nsecs","marshal","prepare","hasher","hashers","getHasher","hashAlg","buf","encode","hash","digest","create","cidVersion","flush","put","shard","path","addFileToShardedDirectory","substring","prefix","newLink","find","bucket","file","rootBucket","root","dir","undefined","parentKey","dirty","flat","_bucket","round","position","_findNewBucketAndPos","toBucketPath","index","segment","subShard","parseInt","pos","nextSegment","_parent","positionInBucket","_posAtParent","reverse","module","exports"],"sources":["C:/Users/zajan/GitHub/chatApplication/node_modules/ipfs-core/src/components/files/utils/add-link.js"],"sourcesContent":["'use strict'\n\nconst dagPb = require('@ipld/dag-pb')\nconst { CID } = require('multiformats/cid')\nconst log = require('debug')('ipfs:mfs:core:utils:add-link')\nconst { UnixFS } = require('ipfs-unixfs')\nconst DirSharded = require('./dir-sharded')\nconst {\n  updateHamtDirectory,\n  recreateHamtLevel,\n  recreateInitialHamtLevel,\n  createShard,\n  toPrefix,\n  addLinksToHamtBucket\n} = require('./hamt-utils')\nconst errCode = require('err-code')\nconst last = require('it-last')\n\n/**\n * @typedef {import('ipfs-unixfs').Mtime} Mtime\n * @typedef {import('multiformats/cid').CIDVersion} CIDVersion\n * @typedef {import('hamt-sharding').Bucket<any>} Bucket\n * @typedef {import('../').MfsContext} MfsContext\n * @typedef {import('@ipld/dag-pb').PBNode} PBNode\n * @typedef {import('@ipld/dag-pb').PBLink} PBLink\n */\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {number} options.shardSplitThreshold\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n * @param {CID} [options.parentCid]\n * @param {PBNode} [options.parent]\n */\nconst addLink = async (context, options) => {\n  let parent = options.parent\n\n  if (options.parentCid) {\n    const parentCid = CID.asCID(options.parentCid)\n    if (parentCid === null) {\n      throw errCode(new Error('Invalid CID passed to addLink'), 'EINVALIDPARENTCID')\n    }\n\n    if (parentCid.code !== dagPb.code) {\n      throw errCode(new Error('Unsupported codec. Only DAG-PB is supported'), 'EINVALIDPARENTCID')\n    }\n\n    log(`Loading parent node ${parentCid}`)\n    const block = await context.repo.blocks.get(parentCid)\n    parent = dagPb.decode(block)\n  }\n\n  if (!parent) {\n    throw errCode(new Error('No parent node or CID passed to addLink'), 'EINVALIDPARENT')\n  }\n\n  if (!options.cid) {\n    throw errCode(new Error('No child cid passed to addLink'), 'EINVALIDCHILDCID')\n  }\n\n  if (!options.name) {\n    throw errCode(new Error('No child name passed to addLink'), 'EINVALIDCHILDNAME')\n  }\n\n  if (!options.size && options.size !== 0) {\n    throw errCode(new Error('No child size passed to addLink'), 'EINVALIDCHILDSIZE')\n  }\n\n  if (!parent.Data) {\n    throw errCode(new Error('Parent node with no data passed to addLink'), 'ERR_INVALID_PARENT')\n  }\n\n  const meta = UnixFS.unmarshal(parent.Data)\n\n  if (meta.type === 'hamt-sharded-directory') {\n    log('Adding link to sharded directory')\n\n    return addToShardedDirectory(context, {\n      ...options,\n      parent\n    })\n  }\n\n  if (parent.Links.length >= options.shardSplitThreshold) {\n    log('Converting directory to sharded directory')\n\n    return convertToShardedDirectory(context, {\n      ...options,\n      parent,\n      mtime: meta.mtime,\n      mode: meta.mode\n    })\n  }\n\n  log(`Adding ${options.name} (${options.cid}) to regular directory`)\n\n  return addToDirectory(context, {\n    ...options,\n    parent\n  })\n}\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n * @param {Mtime} [options.mtime]\n * @param {number} [options.mode]\n */\nconst convertToShardedDirectory = async (context, options) => {\n  const result = await createShard(context, options.parent.Links.map(link => ({\n    name: (link.Name || ''),\n    size: link.Tsize || 0,\n    cid: link.Hash\n  })).concat({\n    name: options.name,\n    size: options.size,\n    cid: options.cid\n  }), options)\n\n  log(`Converted directory to sharded directory ${result.cid}`)\n\n  return result\n}\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n * @param {Mtime} [options.mtime]\n * @param {number} [options.mode]\n */\nconst addToDirectory = async (context, options) => {\n  // Remove existing link if it exists\n  const parentLinks = options.parent.Links.filter((link) => {\n    return link.Name !== options.name\n  })\n  parentLinks.push({\n    Name: options.name,\n    Tsize: options.size,\n    Hash: options.cid\n  })\n\n  if (!options.parent.Data) {\n    throw errCode(new Error('Parent node with no data passed to addToDirectory'), 'ERR_INVALID_PARENT')\n  }\n\n  const node = UnixFS.unmarshal(options.parent.Data)\n\n  let data\n  if (node.mtime) {\n    // Update mtime if previously set\n    const ms = Date.now()\n    const secs = Math.floor(ms / 1000)\n\n    node.mtime = {\n      secs: secs,\n      nsecs: (ms - (secs * 1000)) * 1000\n    }\n\n    data = node.marshal()\n  } else {\n    data = options.parent.Data\n  }\n  options.parent = dagPb.prepare({\n    Data: data,\n    Links: parentLinks\n  })\n\n  // Persist the new parent PbNode\n  const hasher = await context.hashers.getHasher(options.hashAlg)\n  const buf = dagPb.encode(options.parent)\n  const hash = await hasher.digest(buf)\n  const cid = CID.create(options.cidVersion, dagPb.code, hash)\n\n  if (options.flush) {\n    await context.repo.blocks.put(cid, buf)\n  }\n\n  return {\n    node: options.parent,\n    cid,\n    size: buf.length\n  }\n}\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n */\nconst addToShardedDirectory = async (context, options) => {\n  const {\n    shard, path\n  } = await addFileToShardedDirectory(context, options)\n  const result = await last(shard.flush(context.repo.blocks))\n\n  if (!result) {\n    throw new Error('No result from flushing shard')\n  }\n\n  const block = await context.repo.blocks.get(result.cid)\n  const node = dagPb.decode(block)\n\n  // we have written out the shard, but only one sub-shard will have been written so replace it in the original shard\n  const parentLinks = options.parent.Links.filter((link) => {\n    // TODO vmx 2021-03-31: Check that there cannot be multiple ones matching\n    // Remove the old link\n    return (link.Name || '').substring(0, 2) !== path[0].prefix\n  })\n\n  const newLink = node.Links\n    .find(link => (link.Name || '').substring(0, 2) === path[0].prefix)\n\n  if (!newLink) {\n    throw new Error(`No link found with prefix ${path[0].prefix}`)\n  }\n\n  parentLinks.push(newLink)\n\n  return updateHamtDirectory(context, parentLinks, path[0].bucket, options)\n}\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n */\nconst addFileToShardedDirectory = async (context, options) => {\n  const file = {\n    name: options.name,\n    cid: options.cid,\n    size: options.size\n  }\n\n  if (!options.parent.Data) {\n    throw errCode(new Error('Parent node with no data passed to addFileToShardedDirectory'), 'ERR_INVALID_PARENT')\n  }\n\n  // start at the root bucket and descend, loading nodes as we go\n  const rootBucket = await recreateInitialHamtLevel(options.parent.Links)\n  const node = UnixFS.unmarshal(options.parent.Data)\n\n  const shard = new DirSharded({\n    root: true,\n    dir: true,\n    parent: undefined,\n    parentKey: undefined,\n    path: '',\n    dirty: true,\n    flat: false,\n    mode: node.mode\n  }, options)\n  shard._bucket = rootBucket\n\n  if (node.mtime) {\n    // update mtime if previously set\n    shard.mtime = {\n      secs: Math.round(Date.now() / 1000)\n    }\n  }\n\n  // load subshards until the bucket & position no longer changes\n  const position = await rootBucket._findNewBucketAndPos(file.name)\n  const path = toBucketPath(position)\n  path[0].node = options.parent\n  let index = 0\n\n  while (index < path.length) {\n    const segment = path[index]\n    index++\n    const node = segment.node\n\n    if (!node) {\n      throw new Error('Segment had no node')\n    }\n\n    const link = node.Links\n      .find(link => (link.Name || '').substring(0, 2) === segment.prefix)\n\n    if (!link) {\n      // prefix is new, file will be added to the current bucket\n      log(`Link ${segment.prefix}${file.name} will be added`)\n      index = path.length\n\n      break\n    }\n\n    if (link.Name === `${segment.prefix}${file.name}`) {\n      // file already existed, file will be added to the current bucket\n      log(`Link ${segment.prefix}${file.name} will be replaced`)\n      index = path.length\n\n      break\n    }\n\n    if ((link.Name || '').length > 2) {\n      // another file had the same prefix, will be replaced with a subshard\n      log(`Link ${link.Name} ${link.Hash} will be replaced with a subshard`)\n      index = path.length\n\n      break\n    }\n\n    // load sub-shard\n    log(`Found subshard ${segment.prefix}`)\n    const block = await context.repo.blocks.get(link.Hash)\n    const subShard = dagPb.decode(block)\n\n    // subshard hasn't been loaded, descend to the next level of the HAMT\n    if (!path[index]) {\n      log(`Loaded new subshard ${segment.prefix}`)\n      await recreateHamtLevel(subShard.Links, rootBucket, segment.bucket, parseInt(segment.prefix, 16))\n\n      const position = await rootBucket._findNewBucketAndPos(file.name)\n\n      path.push({\n        bucket: position.bucket,\n        prefix: toPrefix(position.pos),\n        node: subShard\n      })\n\n      break\n    }\n\n    const nextSegment = path[index]\n\n    // add next levels worth of links to bucket\n    await addLinksToHamtBucket(subShard.Links, nextSegment.bucket, rootBucket)\n\n    nextSegment.node = subShard\n  }\n\n  // finally add the new file into the shard\n  await shard._bucket.put(file.name, {\n    size: file.size,\n    cid: file.cid\n  })\n\n  return {\n    shard, path\n  }\n}\n\n/**\n * @param {{ pos: number, bucket: Bucket }} position\n * @returns {{ bucket: Bucket, prefix: string, node?: PBNode }[]}\n */\nconst toBucketPath = (position) => {\n  const path = [{\n    bucket: position.bucket,\n    prefix: toPrefix(position.pos)\n  }]\n\n  let bucket = position.bucket._parent\n  let positionInBucket = position.bucket._posAtParent\n\n  while (bucket) {\n    path.push({\n      bucket,\n      prefix: toPrefix(positionInBucket)\n    })\n\n    positionInBucket = bucket._posAtParent\n    bucket = bucket._parent\n  }\n\n  path.reverse()\n\n  return path\n}\n\nmodule.exports = addLink\n"],"mappings":"AAAA;;AAEA,MAAMA,KAAK,GAAGC,OAAO,CAAC,cAAD,CAArB;;AACA,MAAM;EAAEC;AAAF,IAAUD,OAAO,CAAC,kBAAD,CAAvB;;AACA,MAAME,GAAG,GAAGF,OAAO,CAAC,OAAD,CAAP,CAAiB,8BAAjB,CAAZ;;AACA,MAAM;EAAEG;AAAF,IAAaH,OAAO,CAAC,aAAD,CAA1B;;AACA,MAAMI,UAAU,GAAGJ,OAAO,CAAC,eAAD,CAA1B;;AACA,MAAM;EACJK,mBADI;EAEJC,iBAFI;EAGJC,wBAHI;EAIJC,WAJI;EAKJC,QALI;EAMJC;AANI,IAOFV,OAAO,CAAC,cAAD,CAPX;;AAQA,MAAMW,OAAO,GAAGX,OAAO,CAAC,UAAD,CAAvB;;AACA,MAAMY,IAAI,GAAGZ,OAAO,CAAC,SAAD,CAApB;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,MAAMa,OAAO,GAAG,OAAOC,OAAP,EAAgBC,OAAhB,KAA4B;EAC1C,IAAIC,MAAM,GAAGD,OAAO,CAACC,MAArB;;EAEA,IAAID,OAAO,CAACE,SAAZ,EAAuB;IACrB,MAAMA,SAAS,GAAGhB,GAAG,CAACiB,KAAJ,CAAUH,OAAO,CAACE,SAAlB,CAAlB;;IACA,IAAIA,SAAS,KAAK,IAAlB,EAAwB;MACtB,MAAMN,OAAO,CAAC,IAAIQ,KAAJ,CAAU,+BAAV,CAAD,EAA6C,mBAA7C,CAAb;IACD;;IAED,IAAIF,SAAS,CAACG,IAAV,KAAmBrB,KAAK,CAACqB,IAA7B,EAAmC;MACjC,MAAMT,OAAO,CAAC,IAAIQ,KAAJ,CAAU,6CAAV,CAAD,EAA2D,mBAA3D,CAAb;IACD;;IAEDjB,GAAG,CAAE,uBAAsBe,SAAU,EAAlC,CAAH;IACA,MAAMI,KAAK,GAAG,MAAMP,OAAO,CAACQ,IAAR,CAAaC,MAAb,CAAoBC,GAApB,CAAwBP,SAAxB,CAApB;IACAD,MAAM,GAAGjB,KAAK,CAAC0B,MAAN,CAAaJ,KAAb,CAAT;EACD;;EAED,IAAI,CAACL,MAAL,EAAa;IACX,MAAML,OAAO,CAAC,IAAIQ,KAAJ,CAAU,yCAAV,CAAD,EAAuD,gBAAvD,CAAb;EACD;;EAED,IAAI,CAACJ,OAAO,CAACW,GAAb,EAAkB;IAChB,MAAMf,OAAO,CAAC,IAAIQ,KAAJ,CAAU,gCAAV,CAAD,EAA8C,kBAA9C,CAAb;EACD;;EAED,IAAI,CAACJ,OAAO,CAACY,IAAb,EAAmB;IACjB,MAAMhB,OAAO,CAAC,IAAIQ,KAAJ,CAAU,iCAAV,CAAD,EAA+C,mBAA/C,CAAb;EACD;;EAED,IAAI,CAACJ,OAAO,CAACa,IAAT,IAAiBb,OAAO,CAACa,IAAR,KAAiB,CAAtC,EAAyC;IACvC,MAAMjB,OAAO,CAAC,IAAIQ,KAAJ,CAAU,iCAAV,CAAD,EAA+C,mBAA/C,CAAb;EACD;;EAED,IAAI,CAACH,MAAM,CAACa,IAAZ,EAAkB;IAChB,MAAMlB,OAAO,CAAC,IAAIQ,KAAJ,CAAU,4CAAV,CAAD,EAA0D,oBAA1D,CAAb;EACD;;EAED,MAAMW,IAAI,GAAG3B,MAAM,CAAC4B,SAAP,CAAiBf,MAAM,CAACa,IAAxB,CAAb;;EAEA,IAAIC,IAAI,CAACE,IAAL,KAAc,wBAAlB,EAA4C;IAC1C9B,GAAG,CAAC,kCAAD,CAAH;IAEA,OAAO+B,qBAAqB,CAACnB,OAAD,EAAU,EACpC,GAAGC,OADiC;MAEpCC;IAFoC,CAAV,CAA5B;EAID;;EAED,IAAIA,MAAM,CAACkB,KAAP,CAAaC,MAAb,IAAuBpB,OAAO,CAACqB,mBAAnC,EAAwD;IACtDlC,GAAG,CAAC,2CAAD,CAAH;IAEA,OAAOmC,yBAAyB,CAACvB,OAAD,EAAU,EACxC,GAAGC,OADqC;MAExCC,MAFwC;MAGxCsB,KAAK,EAAER,IAAI,CAACQ,KAH4B;MAIxCC,IAAI,EAAET,IAAI,CAACS;IAJ6B,CAAV,CAAhC;EAMD;;EAEDrC,GAAG,CAAE,UAASa,OAAO,CAACY,IAAK,KAAIZ,OAAO,CAACW,GAAI,wBAAxC,CAAH;EAEA,OAAOc,cAAc,CAAC1B,OAAD,EAAU,EAC7B,GAAGC,OAD0B;IAE7BC;EAF6B,CAAV,CAArB;AAID,CAlED;AAoEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,MAAMqB,yBAAyB,GAAG,OAAOvB,OAAP,EAAgBC,OAAhB,KAA4B;EAC5D,MAAM0B,MAAM,GAAG,MAAMjC,WAAW,CAACM,OAAD,EAAUC,OAAO,CAACC,MAAR,CAAekB,KAAf,CAAqBQ,GAArB,CAAyBC,IAAI,KAAK;IAC1EhB,IAAI,EAAGgB,IAAI,CAACC,IAAL,IAAa,EADsD;IAE1EhB,IAAI,EAAEe,IAAI,CAACE,KAAL,IAAc,CAFsD;IAG1EnB,GAAG,EAAEiB,IAAI,CAACG;EAHgE,CAAL,CAA7B,EAItCC,MAJsC,CAI/B;IACTpB,IAAI,EAAEZ,OAAO,CAACY,IADL;IAETC,IAAI,EAAEb,OAAO,CAACa,IAFL;IAGTF,GAAG,EAAEX,OAAO,CAACW;EAHJ,CAJ+B,CAAV,EAQ5BX,OAR4B,CAAhC;EAUAb,GAAG,CAAE,4CAA2CuC,MAAM,CAACf,GAAI,EAAxD,CAAH;EAEA,OAAOe,MAAP;AACD,CAdD;AAgBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,MAAMD,cAAc,GAAG,OAAO1B,OAAP,EAAgBC,OAAhB,KAA4B;EACjD;EACA,MAAMiC,WAAW,GAAGjC,OAAO,CAACC,MAAR,CAAekB,KAAf,CAAqBe,MAArB,CAA6BN,IAAD,IAAU;IACxD,OAAOA,IAAI,CAACC,IAAL,KAAc7B,OAAO,CAACY,IAA7B;EACD,CAFmB,CAApB;EAGAqB,WAAW,CAACE,IAAZ,CAAiB;IACfN,IAAI,EAAE7B,OAAO,CAACY,IADC;IAEfkB,KAAK,EAAE9B,OAAO,CAACa,IAFA;IAGfkB,IAAI,EAAE/B,OAAO,CAACW;EAHC,CAAjB;;EAMA,IAAI,CAACX,OAAO,CAACC,MAAR,CAAea,IAApB,EAA0B;IACxB,MAAMlB,OAAO,CAAC,IAAIQ,KAAJ,CAAU,mDAAV,CAAD,EAAiE,oBAAjE,CAAb;EACD;;EAED,MAAMgC,IAAI,GAAGhD,MAAM,CAAC4B,SAAP,CAAiBhB,OAAO,CAACC,MAAR,CAAea,IAAhC,CAAb;EAEA,IAAIuB,IAAJ;;EACA,IAAID,IAAI,CAACb,KAAT,EAAgB;IACd;IACA,MAAMe,EAAE,GAAGC,IAAI,CAACC,GAAL,EAAX;IACA,MAAMC,IAAI,GAAGC,IAAI,CAACC,KAAL,CAAWL,EAAE,GAAG,IAAhB,CAAb;IAEAF,IAAI,CAACb,KAAL,GAAa;MACXkB,IAAI,EAAEA,IADK;MAEXG,KAAK,EAAE,CAACN,EAAE,GAAIG,IAAI,GAAG,IAAd,IAAuB;IAFnB,CAAb;IAKAJ,IAAI,GAAGD,IAAI,CAACS,OAAL,EAAP;EACD,CAXD,MAWO;IACLR,IAAI,GAAGrC,OAAO,CAACC,MAAR,CAAea,IAAtB;EACD;;EACDd,OAAO,CAACC,MAAR,GAAiBjB,KAAK,CAAC8D,OAAN,CAAc;IAC7BhC,IAAI,EAAEuB,IADuB;IAE7BlB,KAAK,EAAEc;EAFsB,CAAd,CAAjB,CAhCiD,CAqCjD;;EACA,MAAMc,MAAM,GAAG,MAAMhD,OAAO,CAACiD,OAAR,CAAgBC,SAAhB,CAA0BjD,OAAO,CAACkD,OAAlC,CAArB;EACA,MAAMC,GAAG,GAAGnE,KAAK,CAACoE,MAAN,CAAapD,OAAO,CAACC,MAArB,CAAZ;EACA,MAAMoD,IAAI,GAAG,MAAMN,MAAM,CAACO,MAAP,CAAcH,GAAd,CAAnB;EACA,MAAMxC,GAAG,GAAGzB,GAAG,CAACqE,MAAJ,CAAWvD,OAAO,CAACwD,UAAnB,EAA+BxE,KAAK,CAACqB,IAArC,EAA2CgD,IAA3C,CAAZ;;EAEA,IAAIrD,OAAO,CAACyD,KAAZ,EAAmB;IACjB,MAAM1D,OAAO,CAACQ,IAAR,CAAaC,MAAb,CAAoBkD,GAApB,CAAwB/C,GAAxB,EAA6BwC,GAA7B,CAAN;EACD;;EAED,OAAO;IACLf,IAAI,EAAEpC,OAAO,CAACC,MADT;IAELU,GAFK;IAGLE,IAAI,EAAEsC,GAAG,CAAC/B;EAHL,CAAP;AAKD,CApDD;AAsDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,MAAMF,qBAAqB,GAAG,OAAOnB,OAAP,EAAgBC,OAAhB,KAA4B;EACxD,MAAM;IACJ2D,KADI;IACGC;EADH,IAEF,MAAMC,yBAAyB,CAAC9D,OAAD,EAAUC,OAAV,CAFnC;EAGA,MAAM0B,MAAM,GAAG,MAAM7B,IAAI,CAAC8D,KAAK,CAACF,KAAN,CAAY1D,OAAO,CAACQ,IAAR,CAAaC,MAAzB,CAAD,CAAzB;;EAEA,IAAI,CAACkB,MAAL,EAAa;IACX,MAAM,IAAItB,KAAJ,CAAU,+BAAV,CAAN;EACD;;EAED,MAAME,KAAK,GAAG,MAAMP,OAAO,CAACQ,IAAR,CAAaC,MAAb,CAAoBC,GAApB,CAAwBiB,MAAM,CAACf,GAA/B,CAApB;EACA,MAAMyB,IAAI,GAAGpD,KAAK,CAAC0B,MAAN,CAAaJ,KAAb,CAAb,CAXwD,CAaxD;;EACA,MAAM2B,WAAW,GAAGjC,OAAO,CAACC,MAAR,CAAekB,KAAf,CAAqBe,MAArB,CAA6BN,IAAD,IAAU;IACxD;IACA;IACA,OAAO,CAACA,IAAI,CAACC,IAAL,IAAa,EAAd,EAAkBiC,SAAlB,CAA4B,CAA5B,EAA+B,CAA/B,MAAsCF,IAAI,CAAC,CAAD,CAAJ,CAAQG,MAArD;EACD,CAJmB,CAApB;EAMA,MAAMC,OAAO,GAAG5B,IAAI,CAACjB,KAAL,CACb8C,IADa,CACRrC,IAAI,IAAI,CAACA,IAAI,CAACC,IAAL,IAAa,EAAd,EAAkBiC,SAAlB,CAA4B,CAA5B,EAA+B,CAA/B,MAAsCF,IAAI,CAAC,CAAD,CAAJ,CAAQG,MAD9C,CAAhB;;EAGA,IAAI,CAACC,OAAL,EAAc;IACZ,MAAM,IAAI5D,KAAJ,CAAW,6BAA4BwD,IAAI,CAAC,CAAD,CAAJ,CAAQG,MAAO,EAAtD,CAAN;EACD;;EAED9B,WAAW,CAACE,IAAZ,CAAiB6B,OAAjB;EAEA,OAAO1E,mBAAmB,CAACS,OAAD,EAAUkC,WAAV,EAAuB2B,IAAI,CAAC,CAAD,CAAJ,CAAQM,MAA/B,EAAuClE,OAAvC,CAA1B;AACD,CA9BD;AAgCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,MAAM6D,yBAAyB,GAAG,OAAO9D,OAAP,EAAgBC,OAAhB,KAA4B;EAC5D,MAAMmE,IAAI,GAAG;IACXvD,IAAI,EAAEZ,OAAO,CAACY,IADH;IAEXD,GAAG,EAAEX,OAAO,CAACW,GAFF;IAGXE,IAAI,EAAEb,OAAO,CAACa;EAHH,CAAb;;EAMA,IAAI,CAACb,OAAO,CAACC,MAAR,CAAea,IAApB,EAA0B;IACxB,MAAMlB,OAAO,CAAC,IAAIQ,KAAJ,CAAU,8DAAV,CAAD,EAA4E,oBAA5E,CAAb;EACD,CAT2D,CAW5D;;;EACA,MAAMgE,UAAU,GAAG,MAAM5E,wBAAwB,CAACQ,OAAO,CAACC,MAAR,CAAekB,KAAhB,CAAjD;EACA,MAAMiB,IAAI,GAAGhD,MAAM,CAAC4B,SAAP,CAAiBhB,OAAO,CAACC,MAAR,CAAea,IAAhC,CAAb;EAEA,MAAM6C,KAAK,GAAG,IAAItE,UAAJ,CAAe;IAC3BgF,IAAI,EAAE,IADqB;IAE3BC,GAAG,EAAE,IAFsB;IAG3BrE,MAAM,EAAEsE,SAHmB;IAI3BC,SAAS,EAAED,SAJgB;IAK3BX,IAAI,EAAE,EALqB;IAM3Ba,KAAK,EAAE,IANoB;IAO3BC,IAAI,EAAE,KAPqB;IAQ3BlD,IAAI,EAAEY,IAAI,CAACZ;EARgB,CAAf,EASXxB,OATW,CAAd;EAUA2D,KAAK,CAACgB,OAAN,GAAgBP,UAAhB;;EAEA,IAAIhC,IAAI,CAACb,KAAT,EAAgB;IACd;IACAoC,KAAK,CAACpC,KAAN,GAAc;MACZkB,IAAI,EAAEC,IAAI,CAACkC,KAAL,CAAWrC,IAAI,CAACC,GAAL,KAAa,IAAxB;IADM,CAAd;EAGD,CAhC2D,CAkC5D;;;EACA,MAAMqC,QAAQ,GAAG,MAAMT,UAAU,CAACU,oBAAX,CAAgCX,IAAI,CAACvD,IAArC,CAAvB;EACA,MAAMgD,IAAI,GAAGmB,YAAY,CAACF,QAAD,CAAzB;EACAjB,IAAI,CAAC,CAAD,CAAJ,CAAQxB,IAAR,GAAepC,OAAO,CAACC,MAAvB;EACA,IAAI+E,KAAK,GAAG,CAAZ;;EAEA,OAAOA,KAAK,GAAGpB,IAAI,CAACxC,MAApB,EAA4B;IAC1B,MAAM6D,OAAO,GAAGrB,IAAI,CAACoB,KAAD,CAApB;IACAA,KAAK;IACL,MAAM5C,IAAI,GAAG6C,OAAO,CAAC7C,IAArB;;IAEA,IAAI,CAACA,IAAL,EAAW;MACT,MAAM,IAAIhC,KAAJ,CAAU,qBAAV,CAAN;IACD;;IAED,MAAMwB,IAAI,GAAGQ,IAAI,CAACjB,KAAL,CACV8C,IADU,CACLrC,IAAI,IAAI,CAACA,IAAI,CAACC,IAAL,IAAa,EAAd,EAAkBiC,SAAlB,CAA4B,CAA5B,EAA+B,CAA/B,MAAsCmB,OAAO,CAAClB,MADjD,CAAb;;IAGA,IAAI,CAACnC,IAAL,EAAW;MACT;MACAzC,GAAG,CAAE,QAAO8F,OAAO,CAAClB,MAAO,GAAEI,IAAI,CAACvD,IAAK,gBAApC,CAAH;MACAoE,KAAK,GAAGpB,IAAI,CAACxC,MAAb;MAEA;IACD;;IAED,IAAIQ,IAAI,CAACC,IAAL,KAAe,GAAEoD,OAAO,CAAClB,MAAO,GAAEI,IAAI,CAACvD,IAAK,EAAhD,EAAmD;MACjD;MACAzB,GAAG,CAAE,QAAO8F,OAAO,CAAClB,MAAO,GAAEI,IAAI,CAACvD,IAAK,mBAApC,CAAH;MACAoE,KAAK,GAAGpB,IAAI,CAACxC,MAAb;MAEA;IACD;;IAED,IAAI,CAACQ,IAAI,CAACC,IAAL,IAAa,EAAd,EAAkBT,MAAlB,GAA2B,CAA/B,EAAkC;MAChC;MACAjC,GAAG,CAAE,QAAOyC,IAAI,CAACC,IAAK,IAAGD,IAAI,CAACG,IAAK,mCAAhC,CAAH;MACAiD,KAAK,GAAGpB,IAAI,CAACxC,MAAb;MAEA;IACD,CAlCyB,CAoC1B;;;IACAjC,GAAG,CAAE,kBAAiB8F,OAAO,CAAClB,MAAO,EAAlC,CAAH;IACA,MAAMzD,KAAK,GAAG,MAAMP,OAAO,CAACQ,IAAR,CAAaC,MAAb,CAAoBC,GAApB,CAAwBmB,IAAI,CAACG,IAA7B,CAApB;IACA,MAAMmD,QAAQ,GAAGlG,KAAK,CAAC0B,MAAN,CAAaJ,KAAb,CAAjB,CAvC0B,CAyC1B;;IACA,IAAI,CAACsD,IAAI,CAACoB,KAAD,CAAT,EAAkB;MAChB7F,GAAG,CAAE,uBAAsB8F,OAAO,CAAClB,MAAO,EAAvC,CAAH;MACA,MAAMxE,iBAAiB,CAAC2F,QAAQ,CAAC/D,KAAV,EAAiBiD,UAAjB,EAA6Ba,OAAO,CAACf,MAArC,EAA6CiB,QAAQ,CAACF,OAAO,CAAClB,MAAT,EAAiB,EAAjB,CAArD,CAAvB;MAEA,MAAMc,QAAQ,GAAG,MAAMT,UAAU,CAACU,oBAAX,CAAgCX,IAAI,CAACvD,IAArC,CAAvB;MAEAgD,IAAI,CAACzB,IAAL,CAAU;QACR+B,MAAM,EAAEW,QAAQ,CAACX,MADT;QAERH,MAAM,EAAErE,QAAQ,CAACmF,QAAQ,CAACO,GAAV,CAFR;QAGRhD,IAAI,EAAE8C;MAHE,CAAV;MAMA;IACD;;IAED,MAAMG,WAAW,GAAGzB,IAAI,CAACoB,KAAD,CAAxB,CAzD0B,CA2D1B;;IACA,MAAMrF,oBAAoB,CAACuF,QAAQ,CAAC/D,KAAV,EAAiBkE,WAAW,CAACnB,MAA7B,EAAqCE,UAArC,CAA1B;IAEAiB,WAAW,CAACjD,IAAZ,GAAmB8C,QAAnB;EACD,CAvG2D,CAyG5D;;;EACA,MAAMvB,KAAK,CAACgB,OAAN,CAAcjB,GAAd,CAAkBS,IAAI,CAACvD,IAAvB,EAA6B;IACjCC,IAAI,EAAEsD,IAAI,CAACtD,IADsB;IAEjCF,GAAG,EAAEwD,IAAI,CAACxD;EAFuB,CAA7B,CAAN;EAKA,OAAO;IACLgD,KADK;IACEC;EADF,CAAP;AAGD,CAlHD;AAoHA;AACA;AACA;AACA;;;AACA,MAAMmB,YAAY,GAAIF,QAAD,IAAc;EACjC,MAAMjB,IAAI,GAAG,CAAC;IACZM,MAAM,EAAEW,QAAQ,CAACX,MADL;IAEZH,MAAM,EAAErE,QAAQ,CAACmF,QAAQ,CAACO,GAAV;EAFJ,CAAD,CAAb;EAKA,IAAIlB,MAAM,GAAGW,QAAQ,CAACX,MAAT,CAAgBoB,OAA7B;EACA,IAAIC,gBAAgB,GAAGV,QAAQ,CAACX,MAAT,CAAgBsB,YAAvC;;EAEA,OAAOtB,MAAP,EAAe;IACbN,IAAI,CAACzB,IAAL,CAAU;MACR+B,MADQ;MAERH,MAAM,EAAErE,QAAQ,CAAC6F,gBAAD;IAFR,CAAV;IAKAA,gBAAgB,GAAGrB,MAAM,CAACsB,YAA1B;IACAtB,MAAM,GAAGA,MAAM,CAACoB,OAAhB;EACD;;EAED1B,IAAI,CAAC6B,OAAL;EAEA,OAAO7B,IAAP;AACD,CAtBD;;AAwBA8B,MAAM,CAACC,OAAP,GAAiB7F,OAAjB"},"metadata":{},"sourceType":"script"}