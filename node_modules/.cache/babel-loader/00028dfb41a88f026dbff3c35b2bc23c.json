{"ast":null,"code":"'use strict';\n\nvar _regeneratorRuntime = require(\"C:/Users/zajan/GitHub/chatApplication/node_modules/@babel/runtime/helpers/regeneratorRuntime.js\").default;\n\nvar _objectSpread = require(\"C:/Users/zajan/GitHub/chatApplication/node_modules/@babel/runtime/helpers/objectSpread2.js\").default;\n\nvar _asyncToGenerator = require(\"C:/Users/zajan/GitHub/chatApplication/node_modules/@babel/runtime/helpers/asyncToGenerator.js\").default;\n\nvar dagPb = require('@ipld/dag-pb');\n\nvar _require = require('multiformats/cid'),\n    CID = _require.CID;\n\nvar log = require('debug')('ipfs:mfs:core:utils:add-link');\n\nvar _require2 = require('ipfs-unixfs'),\n    UnixFS = _require2.UnixFS;\n\nvar DirSharded = require('./dir-sharded');\n\nvar _require3 = require('./hamt-utils'),\n    updateHamtDirectory = _require3.updateHamtDirectory,\n    recreateHamtLevel = _require3.recreateHamtLevel,\n    recreateInitialHamtLevel = _require3.recreateInitialHamtLevel,\n    createShard = _require3.createShard,\n    toPrefix = _require3.toPrefix,\n    addLinksToHamtBucket = _require3.addLinksToHamtBucket;\n\nvar errCode = require('err-code');\n\nvar last = require('it-last');\n/**\n * @typedef {import('ipfs-unixfs').Mtime} Mtime\n * @typedef {import('multiformats/cid').CIDVersion} CIDVersion\n * @typedef {import('hamt-sharding').Bucket<any>} Bucket\n * @typedef {import('../').MfsContext} MfsContext\n * @typedef {import('@ipld/dag-pb').PBNode} PBNode\n * @typedef {import('@ipld/dag-pb').PBLink} PBLink\n */\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {number} options.shardSplitThreshold\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n * @param {CID} [options.parentCid]\n * @param {PBNode} [options.parent]\n */\n\n\nvar addLink = /*#__PURE__*/function () {\n  var _ref = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee(context, options) {\n    var parent, parentCid, block, meta;\n    return _regeneratorRuntime().wrap(function _callee$(_context) {\n      while (1) {\n        switch (_context.prev = _context.next) {\n          case 0:\n            parent = options.parent;\n\n            if (!options.parentCid) {\n              _context.next = 12;\n              break;\n            }\n\n            parentCid = CID.asCID(options.parentCid);\n\n            if (!(parentCid === null)) {\n              _context.next = 5;\n              break;\n            }\n\n            throw errCode(new Error('Invalid CID passed to addLink'), 'EINVALIDPARENTCID');\n\n          case 5:\n            if (!(parentCid.code !== dagPb.code)) {\n              _context.next = 7;\n              break;\n            }\n\n            throw errCode(new Error('Unsupported codec. Only DAG-PB is supported'), 'EINVALIDPARENTCID');\n\n          case 7:\n            log(\"Loading parent node \".concat(parentCid));\n            _context.next = 10;\n            return context.repo.blocks.get(parentCid);\n\n          case 10:\n            block = _context.sent;\n            parent = dagPb.decode(block);\n\n          case 12:\n            if (parent) {\n              _context.next = 14;\n              break;\n            }\n\n            throw errCode(new Error('No parent node or CID passed to addLink'), 'EINVALIDPARENT');\n\n          case 14:\n            if (options.cid) {\n              _context.next = 16;\n              break;\n            }\n\n            throw errCode(new Error('No child cid passed to addLink'), 'EINVALIDCHILDCID');\n\n          case 16:\n            if (options.name) {\n              _context.next = 18;\n              break;\n            }\n\n            throw errCode(new Error('No child name passed to addLink'), 'EINVALIDCHILDNAME');\n\n          case 18:\n            if (!(!options.size && options.size !== 0)) {\n              _context.next = 20;\n              break;\n            }\n\n            throw errCode(new Error('No child size passed to addLink'), 'EINVALIDCHILDSIZE');\n\n          case 20:\n            if (parent.Data) {\n              _context.next = 22;\n              break;\n            }\n\n            throw errCode(new Error('Parent node with no data passed to addLink'), 'ERR_INVALID_PARENT');\n\n          case 22:\n            meta = UnixFS.unmarshal(parent.Data);\n\n            if (!(meta.type === 'hamt-sharded-directory')) {\n              _context.next = 26;\n              break;\n            }\n\n            log('Adding link to sharded directory');\n            return _context.abrupt(\"return\", addToShardedDirectory(context, _objectSpread(_objectSpread({}, options), {}, {\n              parent: parent\n            })));\n\n          case 26:\n            if (!(parent.Links.length >= options.shardSplitThreshold)) {\n              _context.next = 29;\n              break;\n            }\n\n            log('Converting directory to sharded directory');\n            return _context.abrupt(\"return\", convertToShardedDirectory(context, _objectSpread(_objectSpread({}, options), {}, {\n              parent: parent,\n              mtime: meta.mtime,\n              mode: meta.mode\n            })));\n\n          case 29:\n            log(\"Adding \".concat(options.name, \" (\").concat(options.cid, \") to regular directory\"));\n            return _context.abrupt(\"return\", addToDirectory(context, _objectSpread(_objectSpread({}, options), {}, {\n              parent: parent\n            })));\n\n          case 31:\n          case \"end\":\n            return _context.stop();\n        }\n      }\n    }, _callee);\n  }));\n\n  return function addLink(_x, _x2) {\n    return _ref.apply(this, arguments);\n  };\n}();\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n * @param {Mtime} [options.mtime]\n * @param {number} [options.mode]\n */\n\n\nvar convertToShardedDirectory = /*#__PURE__*/function () {\n  var _ref2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee2(context, options) {\n    var result;\n    return _regeneratorRuntime().wrap(function _callee2$(_context2) {\n      while (1) {\n        switch (_context2.prev = _context2.next) {\n          case 0:\n            _context2.next = 2;\n            return createShard(context, options.parent.Links.map(function (link) {\n              return {\n                name: link.Name || '',\n                size: link.Tsize || 0,\n                cid: link.Hash\n              };\n            }).concat({\n              name: options.name,\n              size: options.size,\n              cid: options.cid\n            }), options);\n\n          case 2:\n            result = _context2.sent;\n            log(\"Converted directory to sharded directory \".concat(result.cid));\n            return _context2.abrupt(\"return\", result);\n\n          case 5:\n          case \"end\":\n            return _context2.stop();\n        }\n      }\n    }, _callee2);\n  }));\n\n  return function convertToShardedDirectory(_x3, _x4) {\n    return _ref2.apply(this, arguments);\n  };\n}();\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n * @param {Mtime} [options.mtime]\n * @param {number} [options.mode]\n */\n\n\nvar addToDirectory = /*#__PURE__*/function () {\n  var _ref3 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee3(context, options) {\n    var parentLinks, node, data, ms, secs, hasher, buf, hash, cid;\n    return _regeneratorRuntime().wrap(function _callee3$(_context3) {\n      while (1) {\n        switch (_context3.prev = _context3.next) {\n          case 0:\n            // Remove existing link if it exists\n            parentLinks = options.parent.Links.filter(function (link) {\n              return link.Name !== options.name;\n            });\n            parentLinks.push({\n              Name: options.name,\n              Tsize: options.size,\n              Hash: options.cid\n            });\n\n            if (options.parent.Data) {\n              _context3.next = 4;\n              break;\n            }\n\n            throw errCode(new Error('Parent node with no data passed to addToDirectory'), 'ERR_INVALID_PARENT');\n\n          case 4:\n            node = UnixFS.unmarshal(options.parent.Data);\n\n            if (node.mtime) {\n              // Update mtime if previously set\n              ms = Date.now();\n              secs = Math.floor(ms / 1000);\n              node.mtime = {\n                secs: secs,\n                nsecs: (ms - secs * 1000) * 1000\n              };\n              data = node.marshal();\n            } else {\n              data = options.parent.Data;\n            }\n\n            options.parent = dagPb.prepare({\n              Data: data,\n              Links: parentLinks\n            }); // Persist the new parent PbNode\n\n            _context3.next = 9;\n            return context.hashers.getHasher(options.hashAlg);\n\n          case 9:\n            hasher = _context3.sent;\n            buf = dagPb.encode(options.parent);\n            _context3.next = 13;\n            return hasher.digest(buf);\n\n          case 13:\n            hash = _context3.sent;\n            cid = CID.create(options.cidVersion, dagPb.code, hash);\n\n            if (!options.flush) {\n              _context3.next = 18;\n              break;\n            }\n\n            _context3.next = 18;\n            return context.repo.blocks.put(cid, buf);\n\n          case 18:\n            return _context3.abrupt(\"return\", {\n              node: options.parent,\n              cid: cid,\n              size: buf.length\n            });\n\n          case 19:\n          case \"end\":\n            return _context3.stop();\n        }\n      }\n    }, _callee3);\n  }));\n\n  return function addToDirectory(_x5, _x6) {\n    return _ref3.apply(this, arguments);\n  };\n}();\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n */\n\n\nvar addToShardedDirectory = /*#__PURE__*/function () {\n  var _ref4 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee4(context, options) {\n    var _yield$addFileToShard, shard, path, result, block, node, parentLinks, newLink;\n\n    return _regeneratorRuntime().wrap(function _callee4$(_context4) {\n      while (1) {\n        switch (_context4.prev = _context4.next) {\n          case 0:\n            _context4.next = 2;\n            return addFileToShardedDirectory(context, options);\n\n          case 2:\n            _yield$addFileToShard = _context4.sent;\n            shard = _yield$addFileToShard.shard;\n            path = _yield$addFileToShard.path;\n            _context4.next = 7;\n            return last(shard.flush(context.repo.blocks));\n\n          case 7:\n            result = _context4.sent;\n\n            if (result) {\n              _context4.next = 10;\n              break;\n            }\n\n            throw new Error('No result from flushing shard');\n\n          case 10:\n            _context4.next = 12;\n            return context.repo.blocks.get(result.cid);\n\n          case 12:\n            block = _context4.sent;\n            node = dagPb.decode(block); // we have written out the shard, but only one sub-shard will have been written so replace it in the original shard\n\n            parentLinks = options.parent.Links.filter(function (link) {\n              // TODO vmx 2021-03-31: Check that there cannot be multiple ones matching\n              // Remove the old link\n              return (link.Name || '').substring(0, 2) !== path[0].prefix;\n            });\n            newLink = node.Links.find(function (link) {\n              return (link.Name || '').substring(0, 2) === path[0].prefix;\n            });\n\n            if (newLink) {\n              _context4.next = 18;\n              break;\n            }\n\n            throw new Error(\"No link found with prefix \".concat(path[0].prefix));\n\n          case 18:\n            parentLinks.push(newLink);\n            return _context4.abrupt(\"return\", updateHamtDirectory(context, parentLinks, path[0].bucket, options));\n\n          case 20:\n          case \"end\":\n            return _context4.stop();\n        }\n      }\n    }, _callee4);\n  }));\n\n  return function addToShardedDirectory(_x7, _x8) {\n    return _ref4.apply(this, arguments);\n  };\n}();\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n */\n\n\nvar addFileToShardedDirectory = /*#__PURE__*/function () {\n  var _ref5 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee5(context, options) {\n    var file, rootBucket, node, shard, position, path, index, _loop, _ret;\n\n    return _regeneratorRuntime().wrap(function _callee5$(_context6) {\n      while (1) {\n        switch (_context6.prev = _context6.next) {\n          case 0:\n            file = {\n              name: options.name,\n              cid: options.cid,\n              size: options.size\n            };\n\n            if (options.parent.Data) {\n              _context6.next = 3;\n              break;\n            }\n\n            throw errCode(new Error('Parent node with no data passed to addFileToShardedDirectory'), 'ERR_INVALID_PARENT');\n\n          case 3:\n            _context6.next = 5;\n            return recreateInitialHamtLevel(options.parent.Links);\n\n          case 5:\n            rootBucket = _context6.sent;\n            node = UnixFS.unmarshal(options.parent.Data);\n            shard = new DirSharded({\n              root: true,\n              dir: true,\n              parent: undefined,\n              parentKey: undefined,\n              path: '',\n              dirty: true,\n              flat: false,\n              mode: node.mode\n            }, options);\n            shard._bucket = rootBucket;\n\n            if (node.mtime) {\n              // update mtime if previously set\n              shard.mtime = {\n                secs: Math.round(Date.now() / 1000)\n              };\n            } // load subshards until the bucket & position no longer changes\n\n\n            _context6.next = 12;\n            return rootBucket._findNewBucketAndPos(file.name);\n\n          case 12:\n            position = _context6.sent;\n            path = toBucketPath(position);\n            path[0].node = options.parent;\n            index = 0;\n            _loop = /*#__PURE__*/_regeneratorRuntime().mark(function _loop() {\n              var segment, node, link, block, subShard, _position, nextSegment;\n\n              return _regeneratorRuntime().wrap(function _loop$(_context5) {\n                while (1) {\n                  switch (_context5.prev = _context5.next) {\n                    case 0:\n                      segment = path[index];\n                      index++;\n                      node = segment.node;\n\n                      if (node) {\n                        _context5.next = 5;\n                        break;\n                      }\n\n                      throw new Error('Segment had no node');\n\n                    case 5:\n                      link = node.Links.find(function (link) {\n                        return (link.Name || '').substring(0, 2) === segment.prefix;\n                      });\n\n                      if (link) {\n                        _context5.next = 10;\n                        break;\n                      }\n\n                      // prefix is new, file will be added to the current bucket\n                      log(\"Link \".concat(segment.prefix).concat(file.name, \" will be added\"));\n                      index = path.length;\n                      return _context5.abrupt(\"return\", \"break\");\n\n                    case 10:\n                      if (!(link.Name === \"\".concat(segment.prefix).concat(file.name))) {\n                        _context5.next = 14;\n                        break;\n                      }\n\n                      // file already existed, file will be added to the current bucket\n                      log(\"Link \".concat(segment.prefix).concat(file.name, \" will be replaced\"));\n                      index = path.length;\n                      return _context5.abrupt(\"return\", \"break\");\n\n                    case 14:\n                      if (!((link.Name || '').length > 2)) {\n                        _context5.next = 18;\n                        break;\n                      }\n\n                      // another file had the same prefix, will be replaced with a subshard\n                      log(\"Link \".concat(link.Name, \" \").concat(link.Hash, \" will be replaced with a subshard\"));\n                      index = path.length;\n                      return _context5.abrupt(\"return\", \"break\");\n\n                    case 18:\n                      // load sub-shard\n                      log(\"Found subshard \".concat(segment.prefix));\n                      _context5.next = 21;\n                      return context.repo.blocks.get(link.Hash);\n\n                    case 21:\n                      block = _context5.sent;\n                      subShard = dagPb.decode(block); // subshard hasn't been loaded, descend to the next level of the HAMT\n\n                      if (path[index]) {\n                        _context5.next = 32;\n                        break;\n                      }\n\n                      log(\"Loaded new subshard \".concat(segment.prefix));\n                      _context5.next = 27;\n                      return recreateHamtLevel(subShard.Links, rootBucket, segment.bucket, parseInt(segment.prefix, 16));\n\n                    case 27:\n                      _context5.next = 29;\n                      return rootBucket._findNewBucketAndPos(file.name);\n\n                    case 29:\n                      _position = _context5.sent;\n                      path.push({\n                        bucket: _position.bucket,\n                        prefix: toPrefix(_position.pos),\n                        node: subShard\n                      });\n                      return _context5.abrupt(\"return\", \"break\");\n\n                    case 32:\n                      nextSegment = path[index]; // add next levels worth of links to bucket\n\n                      _context5.next = 35;\n                      return addLinksToHamtBucket(subShard.Links, nextSegment.bucket, rootBucket);\n\n                    case 35:\n                      nextSegment.node = subShard;\n\n                    case 36:\n                    case \"end\":\n                      return _context5.stop();\n                  }\n                }\n              }, _loop);\n            });\n\n          case 17:\n            if (!(index < path.length)) {\n              _context6.next = 24;\n              break;\n            }\n\n            return _context6.delegateYield(_loop(), \"t0\", 19);\n\n          case 19:\n            _ret = _context6.t0;\n\n            if (!(_ret === \"break\")) {\n              _context6.next = 22;\n              break;\n            }\n\n            return _context6.abrupt(\"break\", 24);\n\n          case 22:\n            _context6.next = 17;\n            break;\n\n          case 24:\n            _context6.next = 26;\n            return shard._bucket.put(file.name, {\n              size: file.size,\n              cid: file.cid\n            });\n\n          case 26:\n            return _context6.abrupt(\"return\", {\n              shard: shard,\n              path: path\n            });\n\n          case 27:\n          case \"end\":\n            return _context6.stop();\n        }\n      }\n    }, _callee5);\n  }));\n\n  return function addFileToShardedDirectory(_x9, _x10) {\n    return _ref5.apply(this, arguments);\n  };\n}();\n/**\n * @param {{ pos: number, bucket: Bucket }} position\n * @returns {{ bucket: Bucket, prefix: string, node?: PBNode }[]}\n */\n\n\nvar toBucketPath = function toBucketPath(position) {\n  var path = [{\n    bucket: position.bucket,\n    prefix: toPrefix(position.pos)\n  }];\n  var bucket = position.bucket._parent;\n  var positionInBucket = position.bucket._posAtParent;\n\n  while (bucket) {\n    path.push({\n      bucket: bucket,\n      prefix: toPrefix(positionInBucket)\n    });\n    positionInBucket = bucket._posAtParent;\n    bucket = bucket._parent;\n  }\n\n  path.reverse();\n  return path;\n};\n\nmodule.exports = addLink;","map":{"version":3,"names":["dagPb","require","CID","log","UnixFS","DirSharded","updateHamtDirectory","recreateHamtLevel","recreateInitialHamtLevel","createShard","toPrefix","addLinksToHamtBucket","errCode","last","addLink","context","options","parent","parentCid","asCID","Error","code","repo","blocks","get","block","decode","cid","name","size","Data","meta","unmarshal","type","addToShardedDirectory","Links","length","shardSplitThreshold","convertToShardedDirectory","mtime","mode","addToDirectory","map","link","Name","Tsize","Hash","concat","result","parentLinks","filter","push","node","ms","Date","now","secs","Math","floor","nsecs","data","marshal","prepare","hashers","getHasher","hashAlg","hasher","buf","encode","digest","hash","create","cidVersion","flush","put","addFileToShardedDirectory","shard","path","substring","prefix","newLink","find","bucket","file","rootBucket","root","dir","undefined","parentKey","dirty","flat","_bucket","round","_findNewBucketAndPos","position","toBucketPath","index","segment","subShard","parseInt","pos","nextSegment","_parent","positionInBucket","_posAtParent","reverse","module","exports"],"sources":["C:/Users/zajan/GitHub/chatApplication/node_modules/ipfs-core/src/components/files/utils/add-link.js"],"sourcesContent":["'use strict'\n\nconst dagPb = require('@ipld/dag-pb')\nconst { CID } = require('multiformats/cid')\nconst log = require('debug')('ipfs:mfs:core:utils:add-link')\nconst { UnixFS } = require('ipfs-unixfs')\nconst DirSharded = require('./dir-sharded')\nconst {\n  updateHamtDirectory,\n  recreateHamtLevel,\n  recreateInitialHamtLevel,\n  createShard,\n  toPrefix,\n  addLinksToHamtBucket\n} = require('./hamt-utils')\nconst errCode = require('err-code')\nconst last = require('it-last')\n\n/**\n * @typedef {import('ipfs-unixfs').Mtime} Mtime\n * @typedef {import('multiformats/cid').CIDVersion} CIDVersion\n * @typedef {import('hamt-sharding').Bucket<any>} Bucket\n * @typedef {import('../').MfsContext} MfsContext\n * @typedef {import('@ipld/dag-pb').PBNode} PBNode\n * @typedef {import('@ipld/dag-pb').PBLink} PBLink\n */\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {number} options.shardSplitThreshold\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n * @param {CID} [options.parentCid]\n * @param {PBNode} [options.parent]\n */\nconst addLink = async (context, options) => {\n  let parent = options.parent\n\n  if (options.parentCid) {\n    const parentCid = CID.asCID(options.parentCid)\n    if (parentCid === null) {\n      throw errCode(new Error('Invalid CID passed to addLink'), 'EINVALIDPARENTCID')\n    }\n\n    if (parentCid.code !== dagPb.code) {\n      throw errCode(new Error('Unsupported codec. Only DAG-PB is supported'), 'EINVALIDPARENTCID')\n    }\n\n    log(`Loading parent node ${parentCid}`)\n    const block = await context.repo.blocks.get(parentCid)\n    parent = dagPb.decode(block)\n  }\n\n  if (!parent) {\n    throw errCode(new Error('No parent node or CID passed to addLink'), 'EINVALIDPARENT')\n  }\n\n  if (!options.cid) {\n    throw errCode(new Error('No child cid passed to addLink'), 'EINVALIDCHILDCID')\n  }\n\n  if (!options.name) {\n    throw errCode(new Error('No child name passed to addLink'), 'EINVALIDCHILDNAME')\n  }\n\n  if (!options.size && options.size !== 0) {\n    throw errCode(new Error('No child size passed to addLink'), 'EINVALIDCHILDSIZE')\n  }\n\n  if (!parent.Data) {\n    throw errCode(new Error('Parent node with no data passed to addLink'), 'ERR_INVALID_PARENT')\n  }\n\n  const meta = UnixFS.unmarshal(parent.Data)\n\n  if (meta.type === 'hamt-sharded-directory') {\n    log('Adding link to sharded directory')\n\n    return addToShardedDirectory(context, {\n      ...options,\n      parent\n    })\n  }\n\n  if (parent.Links.length >= options.shardSplitThreshold) {\n    log('Converting directory to sharded directory')\n\n    return convertToShardedDirectory(context, {\n      ...options,\n      parent,\n      mtime: meta.mtime,\n      mode: meta.mode\n    })\n  }\n\n  log(`Adding ${options.name} (${options.cid}) to regular directory`)\n\n  return addToDirectory(context, {\n    ...options,\n    parent\n  })\n}\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n * @param {Mtime} [options.mtime]\n * @param {number} [options.mode]\n */\nconst convertToShardedDirectory = async (context, options) => {\n  const result = await createShard(context, options.parent.Links.map(link => ({\n    name: (link.Name || ''),\n    size: link.Tsize || 0,\n    cid: link.Hash\n  })).concat({\n    name: options.name,\n    size: options.size,\n    cid: options.cid\n  }), options)\n\n  log(`Converted directory to sharded directory ${result.cid}`)\n\n  return result\n}\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n * @param {Mtime} [options.mtime]\n * @param {number} [options.mode]\n */\nconst addToDirectory = async (context, options) => {\n  // Remove existing link if it exists\n  const parentLinks = options.parent.Links.filter((link) => {\n    return link.Name !== options.name\n  })\n  parentLinks.push({\n    Name: options.name,\n    Tsize: options.size,\n    Hash: options.cid\n  })\n\n  if (!options.parent.Data) {\n    throw errCode(new Error('Parent node with no data passed to addToDirectory'), 'ERR_INVALID_PARENT')\n  }\n\n  const node = UnixFS.unmarshal(options.parent.Data)\n\n  let data\n  if (node.mtime) {\n    // Update mtime if previously set\n    const ms = Date.now()\n    const secs = Math.floor(ms / 1000)\n\n    node.mtime = {\n      secs: secs,\n      nsecs: (ms - (secs * 1000)) * 1000\n    }\n\n    data = node.marshal()\n  } else {\n    data = options.parent.Data\n  }\n  options.parent = dagPb.prepare({\n    Data: data,\n    Links: parentLinks\n  })\n\n  // Persist the new parent PbNode\n  const hasher = await context.hashers.getHasher(options.hashAlg)\n  const buf = dagPb.encode(options.parent)\n  const hash = await hasher.digest(buf)\n  const cid = CID.create(options.cidVersion, dagPb.code, hash)\n\n  if (options.flush) {\n    await context.repo.blocks.put(cid, buf)\n  }\n\n  return {\n    node: options.parent,\n    cid,\n    size: buf.length\n  }\n}\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n */\nconst addToShardedDirectory = async (context, options) => {\n  const {\n    shard, path\n  } = await addFileToShardedDirectory(context, options)\n  const result = await last(shard.flush(context.repo.blocks))\n\n  if (!result) {\n    throw new Error('No result from flushing shard')\n  }\n\n  const block = await context.repo.blocks.get(result.cid)\n  const node = dagPb.decode(block)\n\n  // we have written out the shard, but only one sub-shard will have been written so replace it in the original shard\n  const parentLinks = options.parent.Links.filter((link) => {\n    // TODO vmx 2021-03-31: Check that there cannot be multiple ones matching\n    // Remove the old link\n    return (link.Name || '').substring(0, 2) !== path[0].prefix\n  })\n\n  const newLink = node.Links\n    .find(link => (link.Name || '').substring(0, 2) === path[0].prefix)\n\n  if (!newLink) {\n    throw new Error(`No link found with prefix ${path[0].prefix}`)\n  }\n\n  parentLinks.push(newLink)\n\n  return updateHamtDirectory(context, parentLinks, path[0].bucket, options)\n}\n\n/**\n * @param {MfsContext} context\n * @param {object} options\n * @param {CID} options.cid\n * @param {string} options.name\n * @param {number} options.size\n * @param {PBNode} options.parent\n * @param {string} options.hashAlg\n * @param {CIDVersion} options.cidVersion\n */\nconst addFileToShardedDirectory = async (context, options) => {\n  const file = {\n    name: options.name,\n    cid: options.cid,\n    size: options.size\n  }\n\n  if (!options.parent.Data) {\n    throw errCode(new Error('Parent node with no data passed to addFileToShardedDirectory'), 'ERR_INVALID_PARENT')\n  }\n\n  // start at the root bucket and descend, loading nodes as we go\n  const rootBucket = await recreateInitialHamtLevel(options.parent.Links)\n  const node = UnixFS.unmarshal(options.parent.Data)\n\n  const shard = new DirSharded({\n    root: true,\n    dir: true,\n    parent: undefined,\n    parentKey: undefined,\n    path: '',\n    dirty: true,\n    flat: false,\n    mode: node.mode\n  }, options)\n  shard._bucket = rootBucket\n\n  if (node.mtime) {\n    // update mtime if previously set\n    shard.mtime = {\n      secs: Math.round(Date.now() / 1000)\n    }\n  }\n\n  // load subshards until the bucket & position no longer changes\n  const position = await rootBucket._findNewBucketAndPos(file.name)\n  const path = toBucketPath(position)\n  path[0].node = options.parent\n  let index = 0\n\n  while (index < path.length) {\n    const segment = path[index]\n    index++\n    const node = segment.node\n\n    if (!node) {\n      throw new Error('Segment had no node')\n    }\n\n    const link = node.Links\n      .find(link => (link.Name || '').substring(0, 2) === segment.prefix)\n\n    if (!link) {\n      // prefix is new, file will be added to the current bucket\n      log(`Link ${segment.prefix}${file.name} will be added`)\n      index = path.length\n\n      break\n    }\n\n    if (link.Name === `${segment.prefix}${file.name}`) {\n      // file already existed, file will be added to the current bucket\n      log(`Link ${segment.prefix}${file.name} will be replaced`)\n      index = path.length\n\n      break\n    }\n\n    if ((link.Name || '').length > 2) {\n      // another file had the same prefix, will be replaced with a subshard\n      log(`Link ${link.Name} ${link.Hash} will be replaced with a subshard`)\n      index = path.length\n\n      break\n    }\n\n    // load sub-shard\n    log(`Found subshard ${segment.prefix}`)\n    const block = await context.repo.blocks.get(link.Hash)\n    const subShard = dagPb.decode(block)\n\n    // subshard hasn't been loaded, descend to the next level of the HAMT\n    if (!path[index]) {\n      log(`Loaded new subshard ${segment.prefix}`)\n      await recreateHamtLevel(subShard.Links, rootBucket, segment.bucket, parseInt(segment.prefix, 16))\n\n      const position = await rootBucket._findNewBucketAndPos(file.name)\n\n      path.push({\n        bucket: position.bucket,\n        prefix: toPrefix(position.pos),\n        node: subShard\n      })\n\n      break\n    }\n\n    const nextSegment = path[index]\n\n    // add next levels worth of links to bucket\n    await addLinksToHamtBucket(subShard.Links, nextSegment.bucket, rootBucket)\n\n    nextSegment.node = subShard\n  }\n\n  // finally add the new file into the shard\n  await shard._bucket.put(file.name, {\n    size: file.size,\n    cid: file.cid\n  })\n\n  return {\n    shard, path\n  }\n}\n\n/**\n * @param {{ pos: number, bucket: Bucket }} position\n * @returns {{ bucket: Bucket, prefix: string, node?: PBNode }[]}\n */\nconst toBucketPath = (position) => {\n  const path = [{\n    bucket: position.bucket,\n    prefix: toPrefix(position.pos)\n  }]\n\n  let bucket = position.bucket._parent\n  let positionInBucket = position.bucket._posAtParent\n\n  while (bucket) {\n    path.push({\n      bucket,\n      prefix: toPrefix(positionInBucket)\n    })\n\n    positionInBucket = bucket._posAtParent\n    bucket = bucket._parent\n  }\n\n  path.reverse()\n\n  return path\n}\n\nmodule.exports = addLink\n"],"mappings":"AAAA;;;;;;;;AAEA,IAAMA,KAAK,GAAGC,OAAO,CAAC,cAAD,CAArB;;AACA,eAAgBA,OAAO,CAAC,kBAAD,CAAvB;AAAA,IAAQC,GAAR,YAAQA,GAAR;;AACA,IAAMC,GAAG,GAAGF,OAAO,CAAC,OAAD,CAAP,CAAiB,8BAAjB,CAAZ;;AACA,gBAAmBA,OAAO,CAAC,aAAD,CAA1B;AAAA,IAAQG,MAAR,aAAQA,MAAR;;AACA,IAAMC,UAAU,GAAGJ,OAAO,CAAC,eAAD,CAA1B;;AACA,gBAOIA,OAAO,CAAC,cAAD,CAPX;AAAA,IACEK,mBADF,aACEA,mBADF;AAAA,IAEEC,iBAFF,aAEEA,iBAFF;AAAA,IAGEC,wBAHF,aAGEA,wBAHF;AAAA,IAIEC,WAJF,aAIEA,WAJF;AAAA,IAKEC,QALF,aAKEA,QALF;AAAA,IAMEC,oBANF,aAMEA,oBANF;;AAQA,IAAMC,OAAO,GAAGX,OAAO,CAAC,UAAD,CAAvB;;AACA,IAAMY,IAAI,GAAGZ,OAAO,CAAC,SAAD,CAApB;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,IAAMa,OAAO;EAAA,sEAAG,iBAAOC,OAAP,EAAgBC,OAAhB;IAAA;IAAA;MAAA;QAAA;UAAA;YACVC,MADU,GACDD,OAAO,CAACC,MADP;;YAAA,KAGVD,OAAO,CAACE,SAHE;cAAA;cAAA;YAAA;;YAINA,SAJM,GAIMhB,GAAG,CAACiB,KAAJ,CAAUH,OAAO,CAACE,SAAlB,CAJN;;YAAA,MAKRA,SAAS,KAAK,IALN;cAAA;cAAA;YAAA;;YAAA,MAMJN,OAAO,CAAC,IAAIQ,KAAJ,CAAU,+BAAV,CAAD,EAA6C,mBAA7C,CANH;;UAAA;YAAA,MASRF,SAAS,CAACG,IAAV,KAAmBrB,KAAK,CAACqB,IATjB;cAAA;cAAA;YAAA;;YAAA,MAUJT,OAAO,CAAC,IAAIQ,KAAJ,CAAU,6CAAV,CAAD,EAA2D,mBAA3D,CAVH;;UAAA;YAaZjB,GAAG,+BAAwBe,SAAxB,EAAH;YAbY;YAAA,OAcQH,OAAO,CAACO,IAAR,CAAaC,MAAb,CAAoBC,GAApB,CAAwBN,SAAxB,CAdR;;UAAA;YAcNO,KAdM;YAeZR,MAAM,GAAGjB,KAAK,CAAC0B,MAAN,CAAaD,KAAb,CAAT;;UAfY;YAAA,IAkBTR,MAlBS;cAAA;cAAA;YAAA;;YAAA,MAmBNL,OAAO,CAAC,IAAIQ,KAAJ,CAAU,yCAAV,CAAD,EAAuD,gBAAvD,CAnBD;;UAAA;YAAA,IAsBTJ,OAAO,CAACW,GAtBC;cAAA;cAAA;YAAA;;YAAA,MAuBNf,OAAO,CAAC,IAAIQ,KAAJ,CAAU,gCAAV,CAAD,EAA8C,kBAA9C,CAvBD;;UAAA;YAAA,IA0BTJ,OAAO,CAACY,IA1BC;cAAA;cAAA;YAAA;;YAAA,MA2BNhB,OAAO,CAAC,IAAIQ,KAAJ,CAAU,iCAAV,CAAD,EAA+C,mBAA/C,CA3BD;;UAAA;YAAA,MA8BV,CAACJ,OAAO,CAACa,IAAT,IAAiBb,OAAO,CAACa,IAAR,KAAiB,CA9BxB;cAAA;cAAA;YAAA;;YAAA,MA+BNjB,OAAO,CAAC,IAAIQ,KAAJ,CAAU,iCAAV,CAAD,EAA+C,mBAA/C,CA/BD;;UAAA;YAAA,IAkCTH,MAAM,CAACa,IAlCE;cAAA;cAAA;YAAA;;YAAA,MAmCNlB,OAAO,CAAC,IAAIQ,KAAJ,CAAU,4CAAV,CAAD,EAA0D,oBAA1D,CAnCD;;UAAA;YAsCRW,IAtCQ,GAsCD3B,MAAM,CAAC4B,SAAP,CAAiBf,MAAM,CAACa,IAAxB,CAtCC;;YAAA,MAwCVC,IAAI,CAACE,IAAL,KAAc,wBAxCJ;cAAA;cAAA;YAAA;;YAyCZ9B,GAAG,CAAC,kCAAD,CAAH;YAzCY,iCA2CL+B,qBAAqB,CAACnB,OAAD,kCACvBC,OADuB;cAE1BC,MAAM,EAANA;YAF0B,GA3ChB;;UAAA;YAAA,MAiDVA,MAAM,CAACkB,KAAP,CAAaC,MAAb,IAAuBpB,OAAO,CAACqB,mBAjDrB;cAAA;cAAA;YAAA;;YAkDZlC,GAAG,CAAC,2CAAD,CAAH;YAlDY,iCAoDLmC,yBAAyB,CAACvB,OAAD,kCAC3BC,OAD2B;cAE9BC,MAAM,EAANA,MAF8B;cAG9BsB,KAAK,EAAER,IAAI,CAACQ,KAHkB;cAI9BC,IAAI,EAAET,IAAI,CAACS;YAJmB,GApDpB;;UAAA;YA4DdrC,GAAG,kBAAWa,OAAO,CAACY,IAAnB,eAA4BZ,OAAO,CAACW,GAApC,4BAAH;YA5Dc,iCA8DPc,cAAc,CAAC1B,OAAD,kCAChBC,OADgB;cAEnBC,MAAM,EAANA;YAFmB,GA9DP;;UAAA;UAAA;YAAA;QAAA;MAAA;IAAA;EAAA,CAAH;;EAAA,gBAAPH,OAAO;IAAA;EAAA;AAAA,GAAb;AAoEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,IAAMwB,yBAAyB;EAAA,uEAAG,kBAAOvB,OAAP,EAAgBC,OAAhB;IAAA;IAAA;MAAA;QAAA;UAAA;YAAA;YAAA,OACXP,WAAW,CAACM,OAAD,EAAUC,OAAO,CAACC,MAAR,CAAekB,KAAf,CAAqBO,GAArB,CAAyB,UAAAC,IAAI;cAAA,OAAK;gBAC1Ef,IAAI,EAAGe,IAAI,CAACC,IAAL,IAAa,EADsD;gBAE1Ef,IAAI,EAAEc,IAAI,CAACE,KAAL,IAAc,CAFsD;gBAG1ElB,GAAG,EAAEgB,IAAI,CAACG;cAHgE,CAAL;YAAA,CAA7B,EAItCC,MAJsC,CAI/B;cACTnB,IAAI,EAAEZ,OAAO,CAACY,IADL;cAETC,IAAI,EAAEb,OAAO,CAACa,IAFL;cAGTF,GAAG,EAAEX,OAAO,CAACW;YAHJ,CAJ+B,CAAV,EAQ5BX,OAR4B,CADA;;UAAA;YAC1BgC,MAD0B;YAWhC7C,GAAG,oDAA6C6C,MAAM,CAACrB,GAApD,EAAH;YAXgC,kCAazBqB,MAbyB;;UAAA;UAAA;YAAA;QAAA;MAAA;IAAA;EAAA,CAAH;;EAAA,gBAAzBV,yBAAyB;IAAA;EAAA;AAAA,GAA/B;AAgBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,IAAMG,cAAc;EAAA,uEAAG,kBAAO1B,OAAP,EAAgBC,OAAhB;IAAA;IAAA;MAAA;QAAA;UAAA;YACrB;YACMiC,WAFe,GAEDjC,OAAO,CAACC,MAAR,CAAekB,KAAf,CAAqBe,MAArB,CAA4B,UAACP,IAAD,EAAU;cACxD,OAAOA,IAAI,CAACC,IAAL,KAAc5B,OAAO,CAACY,IAA7B;YACD,CAFmB,CAFC;YAKrBqB,WAAW,CAACE,IAAZ,CAAiB;cACfP,IAAI,EAAE5B,OAAO,CAACY,IADC;cAEfiB,KAAK,EAAE7B,OAAO,CAACa,IAFA;cAGfiB,IAAI,EAAE9B,OAAO,CAACW;YAHC,CAAjB;;YALqB,IAWhBX,OAAO,CAACC,MAAR,CAAea,IAXC;cAAA;cAAA;YAAA;;YAAA,MAYblB,OAAO,CAAC,IAAIQ,KAAJ,CAAU,mDAAV,CAAD,EAAiE,oBAAjE,CAZM;;UAAA;YAefgC,IAfe,GAeRhD,MAAM,CAAC4B,SAAP,CAAiBhB,OAAO,CAACC,MAAR,CAAea,IAAhC,CAfQ;;YAkBrB,IAAIsB,IAAI,CAACb,KAAT,EAAgB;cACd;cACMc,EAFQ,GAEHC,IAAI,CAACC,GAAL,EAFG;cAGRC,IAHQ,GAGDC,IAAI,CAACC,KAAL,CAAWL,EAAE,GAAG,IAAhB,CAHC;cAKdD,IAAI,CAACb,KAAL,GAAa;gBACXiB,IAAI,EAAEA,IADK;gBAEXG,KAAK,EAAE,CAACN,EAAE,GAAIG,IAAI,GAAG,IAAd,IAAuB;cAFnB,CAAb;cAKAI,IAAI,GAAGR,IAAI,CAACS,OAAL,EAAP;YACD,CAXD,MAWO;cACLD,IAAI,GAAG5C,OAAO,CAACC,MAAR,CAAea,IAAtB;YACD;;YACDd,OAAO,CAACC,MAAR,GAAiBjB,KAAK,CAAC8D,OAAN,CAAc;cAC7BhC,IAAI,EAAE8B,IADuB;cAE7BzB,KAAK,EAAEc;YAFsB,CAAd,CAAjB,CAhCqB,CAqCrB;;YArCqB;YAAA,OAsCAlC,OAAO,CAACgD,OAAR,CAAgBC,SAAhB,CAA0BhD,OAAO,CAACiD,OAAlC,CAtCA;;UAAA;YAsCfC,MAtCe;YAuCfC,GAvCe,GAuCTnE,KAAK,CAACoE,MAAN,CAAapD,OAAO,CAACC,MAArB,CAvCS;YAAA;YAAA,OAwCFiD,MAAM,CAACG,MAAP,CAAcF,GAAd,CAxCE;;UAAA;YAwCfG,IAxCe;YAyCf3C,GAzCe,GAyCTzB,GAAG,CAACqE,MAAJ,CAAWvD,OAAO,CAACwD,UAAnB,EAA+BxE,KAAK,CAACqB,IAArC,EAA2CiD,IAA3C,CAzCS;;YAAA,KA2CjBtD,OAAO,CAACyD,KA3CS;cAAA;cAAA;YAAA;;YAAA;YAAA,OA4Cb1D,OAAO,CAACO,IAAR,CAAaC,MAAb,CAAoBmD,GAApB,CAAwB/C,GAAxB,EAA6BwC,GAA7B,CA5Ca;;UAAA;YAAA,kCA+Cd;cACLf,IAAI,EAAEpC,OAAO,CAACC,MADT;cAELU,GAAG,EAAHA,GAFK;cAGLE,IAAI,EAAEsC,GAAG,CAAC/B;YAHL,CA/Cc;;UAAA;UAAA;YAAA;QAAA;MAAA;IAAA;EAAA,CAAH;;EAAA,gBAAdK,cAAc;IAAA;EAAA;AAAA,GAApB;AAsDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,IAAMP,qBAAqB;EAAA,uEAAG,kBAAOnB,OAAP,EAAgBC,OAAhB;IAAA;;IAAA;MAAA;QAAA;UAAA;YAAA;YAAA,OAGlB2D,yBAAyB,CAAC5D,OAAD,EAAUC,OAAV,CAHP;;UAAA;YAAA;YAE1B4D,KAF0B,yBAE1BA,KAF0B;YAEnBC,IAFmB,yBAEnBA,IAFmB;YAAA;YAAA,OAIPhE,IAAI,CAAC+D,KAAK,CAACH,KAAN,CAAY1D,OAAO,CAACO,IAAR,CAAaC,MAAzB,CAAD,CAJG;;UAAA;YAItByB,MAJsB;;YAAA,IAMvBA,MANuB;cAAA;cAAA;YAAA;;YAAA,MAOpB,IAAI5B,KAAJ,CAAU,+BAAV,CAPoB;;UAAA;YAAA;YAAA,OAURL,OAAO,CAACO,IAAR,CAAaC,MAAb,CAAoBC,GAApB,CAAwBwB,MAAM,CAACrB,GAA/B,CAVQ;;UAAA;YAUtBF,KAVsB;YAWtB2B,IAXsB,GAWfpD,KAAK,CAAC0B,MAAN,CAAaD,KAAb,CAXe,EAa5B;;YACMwB,WAdsB,GAcRjC,OAAO,CAACC,MAAR,CAAekB,KAAf,CAAqBe,MAArB,CAA4B,UAACP,IAAD,EAAU;cACxD;cACA;cACA,OAAO,CAACA,IAAI,CAACC,IAAL,IAAa,EAAd,EAAkBkC,SAAlB,CAA4B,CAA5B,EAA+B,CAA/B,MAAsCD,IAAI,CAAC,CAAD,CAAJ,CAAQE,MAArD;YACD,CAJmB,CAdQ;YAoBtBC,OApBsB,GAoBZ5B,IAAI,CAACjB,KAAL,CACb8C,IADa,CACR,UAAAtC,IAAI;cAAA,OAAI,CAACA,IAAI,CAACC,IAAL,IAAa,EAAd,EAAkBkC,SAAlB,CAA4B,CAA5B,EAA+B,CAA/B,MAAsCD,IAAI,CAAC,CAAD,CAAJ,CAAQE,MAAlD;YAAA,CADI,CApBY;;YAAA,IAuBvBC,OAvBuB;cAAA;cAAA;YAAA;;YAAA,MAwBpB,IAAI5D,KAAJ,qCAAuCyD,IAAI,CAAC,CAAD,CAAJ,CAAQE,MAA/C,EAxBoB;;UAAA;YA2B5B9B,WAAW,CAACE,IAAZ,CAAiB6B,OAAjB;YA3B4B,kCA6BrB1E,mBAAmB,CAACS,OAAD,EAAUkC,WAAV,EAAuB4B,IAAI,CAAC,CAAD,CAAJ,CAAQK,MAA/B,EAAuClE,OAAvC,CA7BE;;UAAA;UAAA;YAAA;QAAA;MAAA;IAAA;EAAA,CAAH;;EAAA,gBAArBkB,qBAAqB;IAAA;EAAA;AAAA,GAA3B;AAgCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,IAAMyC,yBAAyB;EAAA,uEAAG,kBAAO5D,OAAP,EAAgBC,OAAhB;IAAA;;IAAA;MAAA;QAAA;UAAA;YAC1BmE,IAD0B,GACnB;cACXvD,IAAI,EAAEZ,OAAO,CAACY,IADH;cAEXD,GAAG,EAAEX,OAAO,CAACW,GAFF;cAGXE,IAAI,EAAEb,OAAO,CAACa;YAHH,CADmB;;YAAA,IAO3Bb,OAAO,CAACC,MAAR,CAAea,IAPY;cAAA;cAAA;YAAA;;YAAA,MAQxBlB,OAAO,CAAC,IAAIQ,KAAJ,CAAU,8DAAV,CAAD,EAA4E,oBAA5E,CARiB;;UAAA;YAAA;YAAA,OAYPZ,wBAAwB,CAACQ,OAAO,CAACC,MAAR,CAAekB,KAAhB,CAZjB;;UAAA;YAY1BiD,UAZ0B;YAa1BhC,IAb0B,GAanBhD,MAAM,CAAC4B,SAAP,CAAiBhB,OAAO,CAACC,MAAR,CAAea,IAAhC,CAbmB;YAe1B8C,KAf0B,GAelB,IAAIvE,UAAJ,CAAe;cAC3BgF,IAAI,EAAE,IADqB;cAE3BC,GAAG,EAAE,IAFsB;cAG3BrE,MAAM,EAAEsE,SAHmB;cAI3BC,SAAS,EAAED,SAJgB;cAK3BV,IAAI,EAAE,EALqB;cAM3BY,KAAK,EAAE,IANoB;cAO3BC,IAAI,EAAE,KAPqB;cAQ3BlD,IAAI,EAAEY,IAAI,CAACZ;YARgB,CAAf,EASXxB,OATW,CAfkB;YAyBhC4D,KAAK,CAACe,OAAN,GAAgBP,UAAhB;;YAEA,IAAIhC,IAAI,CAACb,KAAT,EAAgB;cACd;cACAqC,KAAK,CAACrC,KAAN,GAAc;gBACZiB,IAAI,EAAEC,IAAI,CAACmC,KAAL,CAAWtC,IAAI,CAACC,GAAL,KAAa,IAAxB;cADM,CAAd;YAGD,CAhC+B,CAkChC;;;YAlCgC;YAAA,OAmCT6B,UAAU,CAACS,oBAAX,CAAgCV,IAAI,CAACvD,IAArC,CAnCS;;UAAA;YAmC1BkE,QAnC0B;YAoC1BjB,IApC0B,GAoCnBkB,YAAY,CAACD,QAAD,CApCO;YAqChCjB,IAAI,CAAC,CAAD,CAAJ,CAAQzB,IAAR,GAAepC,OAAO,CAACC,MAAvB;YACI+E,KAtC4B,GAsCpB,CAtCoB;YAAA;cAAA;;cAAA;gBAAA;kBAAA;oBAAA;sBAyCxBC,OAzCwB,GAyCdpB,IAAI,CAACmB,KAAD,CAzCU;sBA0C9BA,KAAK;sBACC5C,IA3CwB,GA2CjB6C,OAAO,CAAC7C,IA3CS;;sBAAA,IA6CzBA,IA7CyB;wBAAA;wBAAA;sBAAA;;sBAAA,MA8CtB,IAAIhC,KAAJ,CAAU,qBAAV,CA9CsB;;oBAAA;sBAiDxBuB,IAjDwB,GAiDjBS,IAAI,CAACjB,KAAL,CACV8C,IADU,CACL,UAAAtC,IAAI;wBAAA,OAAI,CAACA,IAAI,CAACC,IAAL,IAAa,EAAd,EAAkBkC,SAAlB,CAA4B,CAA5B,EAA+B,CAA/B,MAAsCmB,OAAO,CAAClB,MAAlD;sBAAA,CADC,CAjDiB;;sBAAA,IAoDzBpC,IApDyB;wBAAA;wBAAA;sBAAA;;sBAqD5B;sBACAxC,GAAG,gBAAS8F,OAAO,CAAClB,MAAjB,SAA0BI,IAAI,CAACvD,IAA/B,oBAAH;sBACAoE,KAAK,GAAGnB,IAAI,CAACzC,MAAb;sBAvD4B;;oBAAA;sBAAA,MA4D1BO,IAAI,CAACC,IAAL,eAAiBqD,OAAO,CAAClB,MAAzB,SAAkCI,IAAI,CAACvD,IAAvC,CA5D0B;wBAAA;wBAAA;sBAAA;;sBA6D5B;sBACAzB,GAAG,gBAAS8F,OAAO,CAAClB,MAAjB,SAA0BI,IAAI,CAACvD,IAA/B,uBAAH;sBACAoE,KAAK,GAAGnB,IAAI,CAACzC,MAAb;sBA/D4B;;oBAAA;sBAAA,MAoE1B,CAACO,IAAI,CAACC,IAAL,IAAa,EAAd,EAAkBR,MAAlB,GAA2B,CApED;wBAAA;wBAAA;sBAAA;;sBAqE5B;sBACAjC,GAAG,gBAASwC,IAAI,CAACC,IAAd,cAAsBD,IAAI,CAACG,IAA3B,uCAAH;sBACAkD,KAAK,GAAGnB,IAAI,CAACzC,MAAb;sBAvE4B;;oBAAA;sBA4E9B;sBACAjC,GAAG,0BAAmB8F,OAAO,CAAClB,MAA3B,EAAH;sBA7E8B;sBAAA,OA8EVhE,OAAO,CAACO,IAAR,CAAaC,MAAb,CAAoBC,GAApB,CAAwBmB,IAAI,CAACG,IAA7B,CA9EU;;oBAAA;sBA8ExBrB,KA9EwB;sBA+ExByE,QA/EwB,GA+EblG,KAAK,CAAC0B,MAAN,CAAaD,KAAb,CA/Ea,EAiF9B;;sBAjF8B,IAkFzBoD,IAAI,CAACmB,KAAD,CAlFqB;wBAAA;wBAAA;sBAAA;;sBAmF5B7F,GAAG,+BAAwB8F,OAAO,CAAClB,MAAhC,EAAH;sBAnF4B;sBAAA,OAoFtBxE,iBAAiB,CAAC2F,QAAQ,CAAC/D,KAAV,EAAiBiD,UAAjB,EAA6Ba,OAAO,CAACf,MAArC,EAA6CiB,QAAQ,CAACF,OAAO,CAAClB,MAAT,EAAiB,EAAjB,CAArD,CApFK;;oBAAA;sBAAA;sBAAA,OAsFLK,UAAU,CAACS,oBAAX,CAAgCV,IAAI,CAACvD,IAArC,CAtFK;;oBAAA;sBAsFtBkE,SAtFsB;sBAwF5BjB,IAAI,CAAC1B,IAAL,CAAU;wBACR+B,MAAM,EAAEY,SAAQ,CAACZ,MADT;wBAERH,MAAM,EAAErE,QAAQ,CAACoF,SAAQ,CAACM,GAAV,CAFR;wBAGRhD,IAAI,EAAE8C;sBAHE,CAAV;sBAxF4B;;oBAAA;sBAiGxBG,WAjGwB,GAiGVxB,IAAI,CAACmB,KAAD,CAjGM,EAmG9B;;sBAnG8B;sBAAA,OAoGxBrF,oBAAoB,CAACuF,QAAQ,CAAC/D,KAAV,EAAiBkE,WAAW,CAACnB,MAA7B,EAAqCE,UAArC,CApGI;;oBAAA;sBAsG9BiB,WAAW,CAACjD,IAAZ,GAAmB8C,QAAnB;;oBAtG8B;oBAAA;sBAAA;kBAAA;gBAAA;cAAA;YAAA;;UAAA;YAAA,MAwCzBF,KAAK,GAAGnB,IAAI,CAACzC,MAxCY;cAAA;cAAA;YAAA;;YAAA;;UAAA;YAAA;;YAAA;cAAA;cAAA;YAAA;;YAAA;;UAAA;YAAA;YAAA;;UAAA;YAAA;YAAA,OA0G1BwC,KAAK,CAACe,OAAN,CAAcjB,GAAd,CAAkBS,IAAI,CAACvD,IAAvB,EAA6B;cACjCC,IAAI,EAAEsD,IAAI,CAACtD,IADsB;cAEjCF,GAAG,EAAEwD,IAAI,CAACxD;YAFuB,CAA7B,CA1G0B;;UAAA;YAAA,kCA+GzB;cACLiD,KAAK,EAALA,KADK;cACEC,IAAI,EAAJA;YADF,CA/GyB;;UAAA;UAAA;YAAA;QAAA;MAAA;IAAA;EAAA,CAAH;;EAAA,gBAAzBF,yBAAyB;IAAA;EAAA;AAAA,GAA/B;AAoHA;AACA;AACA;AACA;;;AACA,IAAMoB,YAAY,GAAG,SAAfA,YAAe,CAACD,QAAD,EAAc;EACjC,IAAMjB,IAAI,GAAG,CAAC;IACZK,MAAM,EAAEY,QAAQ,CAACZ,MADL;IAEZH,MAAM,EAAErE,QAAQ,CAACoF,QAAQ,CAACM,GAAV;EAFJ,CAAD,CAAb;EAKA,IAAIlB,MAAM,GAAGY,QAAQ,CAACZ,MAAT,CAAgBoB,OAA7B;EACA,IAAIC,gBAAgB,GAAGT,QAAQ,CAACZ,MAAT,CAAgBsB,YAAvC;;EAEA,OAAOtB,MAAP,EAAe;IACbL,IAAI,CAAC1B,IAAL,CAAU;MACR+B,MAAM,EAANA,MADQ;MAERH,MAAM,EAAErE,QAAQ,CAAC6F,gBAAD;IAFR,CAAV;IAKAA,gBAAgB,GAAGrB,MAAM,CAACsB,YAA1B;IACAtB,MAAM,GAAGA,MAAM,CAACoB,OAAhB;EACD;;EAEDzB,IAAI,CAAC4B,OAAL;EAEA,OAAO5B,IAAP;AACD,CAtBD;;AAwBA6B,MAAM,CAACC,OAAP,GAAiB7F,OAAjB"},"metadata":{},"sourceType":"script"}