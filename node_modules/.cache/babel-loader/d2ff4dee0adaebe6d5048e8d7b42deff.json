{"ast":null,"code":"'use strict';\n\nvar _regeneratorRuntime = require(\"C:/Users/zajan/GitHub/chatApplication/node_modules/@babel/runtime/helpers/regeneratorRuntime.js\").default;\n\nvar _asyncToGenerator = require(\"C:/Users/zajan/GitHub/chatApplication/node_modules/@babel/runtime/helpers/asyncToGenerator.js\").default;\n\nvar dagPb = require('@ipld/dag-pb');\n\nvar _require = require('hamt-sharding'),\n    Bucket = _require.Bucket,\n    createHAMT = _require.createHAMT;\n\nvar DirSharded = require('./dir-sharded');\n\nvar log = require('debug')('ipfs:mfs:core:utils:hamt-utils');\n\nvar _require2 = require('ipfs-unixfs'),\n    UnixFS = _require2.UnixFS;\n\nvar last = require('it-last');\n\nvar _require3 = require('multiformats/cid'),\n    CID = _require3.CID;\n\nvar _require4 = require('./hamt-constants'),\n    hamtHashCode = _require4.hamtHashCode,\n    hamtHashFn = _require4.hamtHashFn,\n    hamtBucketBits = _require4.hamtBucketBits;\n/**\n * @typedef {import('multiformats/cid').CIDVersion} CIDVersion\n * @typedef {import('ipfs-unixfs').Mtime} Mtime\n * @typedef {import('../').MfsContext} MfsContext\n * @typedef {import('@ipld/dag-pb').PBNode} PBNode\n * @typedef {import('@ipld/dag-pb').PBLink} PBLink\n */\n\n/**\n * @param {MfsContext} context\n * @param {PBLink[]} links\n * @param {Bucket<any>} bucket\n * @param {object} options\n * @param {PBNode} options.parent\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n * @param {string} options.hashAlg\n */\n\n\nvar updateHamtDirectory = /*#__PURE__*/function () {\n  var _ref = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee(context, links, bucket, options) {\n    var data, node, dir, hasher, parent, buf, hash, cid;\n    return _regeneratorRuntime().wrap(function _callee$(_context) {\n      while (1) {\n        switch (_context.prev = _context.next) {\n          case 0:\n            if (options.parent.Data) {\n              _context.next = 2;\n              break;\n            }\n\n            throw new Error('Could not update HAMT directory because parent had no data');\n\n          case 2:\n            // update parent with new bit field\n            data = Uint8Array.from(bucket._children.bitField().reverse());\n            node = UnixFS.unmarshal(options.parent.Data);\n            dir = new UnixFS({\n              type: 'hamt-sharded-directory',\n              data: data,\n              fanout: bucket.tableSize(),\n              hashType: hamtHashCode,\n              mode: node.mode,\n              mtime: node.mtime\n            });\n            _context.next = 7;\n            return context.hashers.getHasher(options.hashAlg);\n\n          case 7:\n            hasher = _context.sent;\n            parent = {\n              Data: dir.marshal(),\n              Links: links.sort(function (a, b) {\n                return (a.Name || '').localeCompare(b.Name || '');\n              })\n            };\n            buf = dagPb.encode(parent);\n            _context.next = 12;\n            return hasher.digest(buf);\n\n          case 12:\n            hash = _context.sent;\n            cid = CID.create(options.cidVersion, dagPb.code, hash);\n\n            if (!options.flush) {\n              _context.next = 17;\n              break;\n            }\n\n            _context.next = 17;\n            return context.repo.blocks.put(cid, buf);\n\n          case 17:\n            return _context.abrupt(\"return\", {\n              node: parent,\n              cid: cid,\n              size: links.reduce(function (sum, link) {\n                return sum + (link.Tsize || 0);\n              }, buf.length)\n            });\n\n          case 18:\n          case \"end\":\n            return _context.stop();\n        }\n      }\n    }, _callee);\n  }));\n\n  return function updateHamtDirectory(_x, _x2, _x3, _x4) {\n    return _ref.apply(this, arguments);\n  };\n}();\n/**\n * @param {PBLink[]} links\n * @param {Bucket<any>} rootBucket\n * @param {Bucket<any>} parentBucket\n * @param {number} positionAtParent\n */\n\n\nvar recreateHamtLevel = /*#__PURE__*/function () {\n  var _ref2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee2(links, rootBucket, parentBucket, positionAtParent) {\n    var bucket;\n    return _regeneratorRuntime().wrap(function _callee2$(_context2) {\n      while (1) {\n        switch (_context2.prev = _context2.next) {\n          case 0:\n            // recreate this level of the HAMT\n            bucket = new Bucket({\n              hash: rootBucket._options.hash,\n              bits: rootBucket._options.bits\n            }, parentBucket, positionAtParent);\n\n            parentBucket._putObjectAt(positionAtParent, bucket);\n\n            _context2.next = 4;\n            return addLinksToHamtBucket(links, bucket, rootBucket);\n\n          case 4:\n            return _context2.abrupt(\"return\", bucket);\n\n          case 5:\n          case \"end\":\n            return _context2.stop();\n        }\n      }\n    }, _callee2);\n  }));\n\n  return function recreateHamtLevel(_x5, _x6, _x7, _x8) {\n    return _ref2.apply(this, arguments);\n  };\n}();\n/**\n * @param {PBLink[]} links\n */\n\n\nvar recreateInitialHamtLevel = /*#__PURE__*/function () {\n  var _ref3 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee3(links) {\n    var bucket;\n    return _regeneratorRuntime().wrap(function _callee3$(_context3) {\n      while (1) {\n        switch (_context3.prev = _context3.next) {\n          case 0:\n            bucket = createHAMT({\n              hashFn: hamtHashFn,\n              bits: hamtBucketBits\n            });\n            _context3.next = 3;\n            return addLinksToHamtBucket(links, bucket, bucket);\n\n          case 3:\n            return _context3.abrupt(\"return\", bucket);\n\n          case 4:\n          case \"end\":\n            return _context3.stop();\n        }\n      }\n    }, _callee3);\n  }));\n\n  return function recreateInitialHamtLevel(_x9) {\n    return _ref3.apply(this, arguments);\n  };\n}();\n/**\n * @param {PBLink[]} links\n * @param {Bucket<any>} bucket\n * @param {Bucket<any>} rootBucket\n */\n\n\nvar addLinksToHamtBucket = /*#__PURE__*/function () {\n  var _ref4 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee4(links, bucket, rootBucket) {\n    return _regeneratorRuntime().wrap(function _callee4$(_context4) {\n      while (1) {\n        switch (_context4.prev = _context4.next) {\n          case 0:\n            _context4.next = 2;\n            return Promise.all(links.map(function (link) {\n              var linkName = link.Name || '';\n\n              if (linkName.length === 2) {\n                var pos = parseInt(linkName, 16);\n\n                bucket._putObjectAt(pos, new Bucket({\n                  hash: rootBucket._options.hash,\n                  bits: rootBucket._options.bits\n                }, bucket, pos));\n\n                return Promise.resolve();\n              }\n\n              return rootBucket.put(linkName.substring(2), {\n                size: link.Tsize,\n                cid: link.Hash\n              });\n            }));\n\n          case 2:\n          case \"end\":\n            return _context4.stop();\n        }\n      }\n    }, _callee4);\n  }));\n\n  return function addLinksToHamtBucket(_x10, _x11, _x12) {\n    return _ref4.apply(this, arguments);\n  };\n}();\n/**\n * @param {number} position\n */\n\n\nvar toPrefix = function toPrefix(position) {\n  return position.toString(16).toUpperCase().padStart(2, '0').substring(0, 2);\n};\n/**\n * @param {MfsContext} context\n * @param {string} fileName\n * @param {PBNode} rootNode\n */\n\n\nvar generatePath = /*#__PURE__*/function () {\n  var _ref5 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee5(context, fileName, rootNode) {\n    var rootBucket, position, path, currentBucket, _loop, i, _ret;\n\n    return _regeneratorRuntime().wrap(function _callee5$(_context6) {\n      while (1) {\n        switch (_context6.prev = _context6.next) {\n          case 0:\n            _context6.next = 2;\n            return recreateInitialHamtLevel(rootNode.Links);\n\n          case 2:\n            rootBucket = _context6.sent;\n            _context6.next = 5;\n            return rootBucket._findNewBucketAndPos(fileName);\n\n          case 5:\n            position = _context6.sent;\n            // the path to the root bucket\n\n            /** @type {{ bucket: Bucket<any>, prefix: string, node?: PBNode }[]} */\n            path = [{\n              bucket: position.bucket,\n              prefix: toPrefix(position.pos)\n            }];\n            currentBucket = position.bucket;\n\n            while (currentBucket !== rootBucket) {\n              path.push({\n                bucket: currentBucket,\n                prefix: toPrefix(currentBucket._posAtParent)\n              }); // @ts-ignore - only the root bucket's parent will be undefined\n\n              currentBucket = currentBucket._parent;\n            }\n\n            path.reverse();\n            path[0].node = rootNode; // load PbNode for each path segment\n\n            _loop = /*#__PURE__*/_regeneratorRuntime().mark(function _loop(i) {\n              var segment, link, block, node, _position, nextSegment;\n\n              return _regeneratorRuntime().wrap(function _loop$(_context5) {\n                while (1) {\n                  switch (_context5.prev = _context5.next) {\n                    case 0:\n                      segment = path[i];\n\n                      if (segment.node) {\n                        _context5.next = 3;\n                        break;\n                      }\n\n                      throw new Error('Could not generate HAMT path');\n\n                    case 3:\n                      // find prefix in links\n                      link = segment.node.Links.filter(function (link) {\n                        return (link.Name || '').substring(0, 2) === segment.prefix;\n                      }).pop(); // entry was not in shard\n\n                      if (link) {\n                        _context5.next = 7;\n                        break;\n                      }\n\n                      // reached bottom of tree, file will be added to the current bucket\n                      log(\"Link \".concat(segment.prefix).concat(fileName, \" will be added\")); // return path\n\n                      return _context5.abrupt(\"return\", \"continue\");\n\n                    case 7:\n                      if (!(link.Name === \"\".concat(segment.prefix).concat(fileName))) {\n                        _context5.next = 10;\n                        break;\n                      }\n\n                      log(\"Link \".concat(segment.prefix).concat(fileName, \" will be replaced\")); // file already existed, file will be added to the current bucket\n                      // return path\n\n                      return _context5.abrupt(\"return\", \"continue\");\n\n                    case 10:\n                      // found subshard\n                      log(\"Found subshard \".concat(segment.prefix));\n                      _context5.next = 13;\n                      return context.repo.blocks.get(link.Hash);\n\n                    case 13:\n                      block = _context5.sent;\n                      node = dagPb.decode(block); // subshard hasn't been loaded, descend to the next level of the HAMT\n\n                      if (path[i + 1]) {\n                        _context5.next = 24;\n                        break;\n                      }\n\n                      log(\"Loaded new subshard \".concat(segment.prefix));\n                      _context5.next = 19;\n                      return recreateHamtLevel(node.Links, rootBucket, segment.bucket, parseInt(segment.prefix, 16));\n\n                    case 19:\n                      _context5.next = 21;\n                      return rootBucket._findNewBucketAndPos(fileName);\n\n                    case 21:\n                      _position = _context5.sent;\n                      // i--\n                      path.push({\n                        bucket: _position.bucket,\n                        prefix: toPrefix(_position.pos),\n                        node: node\n                      });\n                      return _context5.abrupt(\"return\", \"continue\");\n\n                    case 24:\n                      nextSegment = path[i + 1]; // add intermediate links to bucket\n\n                      _context5.next = 27;\n                      return addLinksToHamtBucket(node.Links, nextSegment.bucket, rootBucket);\n\n                    case 27:\n                      nextSegment.node = node;\n\n                    case 28:\n                    case \"end\":\n                      return _context5.stop();\n                  }\n                }\n              }, _loop);\n            });\n            i = 0;\n\n          case 13:\n            if (!(i < path.length)) {\n              _context6.next = 21;\n              break;\n            }\n\n            return _context6.delegateYield(_loop(i), \"t0\", 15);\n\n          case 15:\n            _ret = _context6.t0;\n\n            if (!(_ret === \"continue\")) {\n              _context6.next = 18;\n              break;\n            }\n\n            return _context6.abrupt(\"continue\", 18);\n\n          case 18:\n            i++;\n            _context6.next = 13;\n            break;\n\n          case 21:\n            _context6.next = 23;\n            return rootBucket.put(fileName, true);\n\n          case 23:\n            path.reverse();\n            return _context6.abrupt(\"return\", {\n              rootBucket: rootBucket,\n              path: path\n            });\n\n          case 25:\n          case \"end\":\n            return _context6.stop();\n        }\n      }\n    }, _callee5);\n  }));\n\n  return function generatePath(_x13, _x14, _x15) {\n    return _ref5.apply(this, arguments);\n  };\n}();\n/**\n * @param {MfsContext} context\n * @param {{ name: string, size: number, cid: CID }[]} contents\n * @param {object} [options]\n * @param {Mtime} [options.mtime]\n * @param {number} [options.mode]\n */\n\n\nvar createShard = /*#__PURE__*/function () {\n  var _ref6 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee6(context, contents) {\n    var options,\n        shard,\n        i,\n        res,\n        _args7 = arguments;\n    return _regeneratorRuntime().wrap(function _callee6$(_context7) {\n      while (1) {\n        switch (_context7.prev = _context7.next) {\n          case 0:\n            options = _args7.length > 2 && _args7[2] !== undefined ? _args7[2] : {};\n            shard = new DirSharded({\n              root: true,\n              dir: true,\n              parent: undefined,\n              parentKey: undefined,\n              path: '',\n              dirty: true,\n              flat: false,\n              mtime: options.mtime,\n              mode: options.mode\n            }, options);\n            i = 0;\n\n          case 3:\n            if (!(i < contents.length)) {\n              _context7.next = 9;\n              break;\n            }\n\n            _context7.next = 6;\n            return shard._bucket.put(contents[i].name, {\n              size: contents[i].size,\n              cid: contents[i].cid\n            });\n\n          case 6:\n            i++;\n            _context7.next = 3;\n            break;\n\n          case 9:\n            _context7.next = 11;\n            return last(shard.flush(context.repo.blocks));\n\n          case 11:\n            res = _context7.sent;\n\n            if (res) {\n              _context7.next = 14;\n              break;\n            }\n\n            throw new Error('Flushing shard yielded no result');\n\n          case 14:\n            return _context7.abrupt(\"return\", res);\n\n          case 15:\n          case \"end\":\n            return _context7.stop();\n        }\n      }\n    }, _callee6);\n  }));\n\n  return function createShard(_x16, _x17) {\n    return _ref6.apply(this, arguments);\n  };\n}();\n\nmodule.exports = {\n  generatePath: generatePath,\n  updateHamtDirectory: updateHamtDirectory,\n  recreateHamtLevel: recreateHamtLevel,\n  recreateInitialHamtLevel: recreateInitialHamtLevel,\n  addLinksToHamtBucket: addLinksToHamtBucket,\n  toPrefix: toPrefix,\n  createShard: createShard\n};","map":{"version":3,"names":["dagPb","require","Bucket","createHAMT","DirSharded","log","UnixFS","last","CID","hamtHashCode","hamtHashFn","hamtBucketBits","updateHamtDirectory","context","links","bucket","options","parent","Data","Error","data","Uint8Array","from","_children","bitField","reverse","node","unmarshal","dir","type","fanout","tableSize","hashType","mode","mtime","hashers","getHasher","hashAlg","hasher","marshal","Links","sort","a","b","Name","localeCompare","buf","encode","digest","hash","cid","create","cidVersion","code","flush","repo","blocks","put","size","reduce","sum","link","Tsize","length","recreateHamtLevel","rootBucket","parentBucket","positionAtParent","_options","bits","_putObjectAt","addLinksToHamtBucket","recreateInitialHamtLevel","hashFn","Promise","all","map","linkName","pos","parseInt","resolve","substring","Hash","toPrefix","position","toString","toUpperCase","padStart","generatePath","fileName","rootNode","_findNewBucketAndPos","path","prefix","currentBucket","push","_posAtParent","_parent","i","segment","filter","pop","get","block","decode","nextSegment","createShard","contents","shard","root","undefined","parentKey","dirty","flat","_bucket","name","res","module","exports"],"sources":["C:/Users/zajan/GitHub/chatApplication/node_modules/ipfs-core/src/components/files/utils/hamt-utils.js"],"sourcesContent":["'use strict'\n\nconst dagPb = require('@ipld/dag-pb')\nconst {\n  Bucket,\n  createHAMT\n} = require('hamt-sharding')\nconst DirSharded = require('./dir-sharded')\nconst log = require('debug')('ipfs:mfs:core:utils:hamt-utils')\nconst { UnixFS } = require('ipfs-unixfs')\nconst last = require('it-last')\nconst { CID } = require('multiformats/cid')\nconst {\n  hamtHashCode,\n  hamtHashFn,\n  hamtBucketBits\n} = require('./hamt-constants')\n\n/**\n * @typedef {import('multiformats/cid').CIDVersion} CIDVersion\n * @typedef {import('ipfs-unixfs').Mtime} Mtime\n * @typedef {import('../').MfsContext} MfsContext\n * @typedef {import('@ipld/dag-pb').PBNode} PBNode\n * @typedef {import('@ipld/dag-pb').PBLink} PBLink\n */\n\n/**\n * @param {MfsContext} context\n * @param {PBLink[]} links\n * @param {Bucket<any>} bucket\n * @param {object} options\n * @param {PBNode} options.parent\n * @param {CIDVersion} options.cidVersion\n * @param {boolean} options.flush\n * @param {string} options.hashAlg\n */\nconst updateHamtDirectory = async (context, links, bucket, options) => {\n  if (!options.parent.Data) {\n    throw new Error('Could not update HAMT directory because parent had no data')\n  }\n\n  // update parent with new bit field\n  const data = Uint8Array.from(bucket._children.bitField().reverse())\n  const node = UnixFS.unmarshal(options.parent.Data)\n  const dir = new UnixFS({\n    type: 'hamt-sharded-directory',\n    data,\n    fanout: bucket.tableSize(),\n    hashType: hamtHashCode,\n    mode: node.mode,\n    mtime: node.mtime\n  })\n\n  const hasher = await context.hashers.getHasher(options.hashAlg)\n  const parent = {\n    Data: dir.marshal(),\n    Links: links.sort((a, b) => (a.Name || '').localeCompare(b.Name || ''))\n  }\n  const buf = dagPb.encode(parent)\n  const hash = await hasher.digest(buf)\n  const cid = CID.create(options.cidVersion, dagPb.code, hash)\n\n  if (options.flush) {\n    await context.repo.blocks.put(cid, buf)\n  }\n\n  return {\n    node: parent,\n    cid,\n    size: links.reduce((sum, link) => sum + (link.Tsize || 0), buf.length)\n  }\n}\n\n/**\n * @param {PBLink[]} links\n * @param {Bucket<any>} rootBucket\n * @param {Bucket<any>} parentBucket\n * @param {number} positionAtParent\n */\nconst recreateHamtLevel = async (links, rootBucket, parentBucket, positionAtParent) => {\n  // recreate this level of the HAMT\n  const bucket = new Bucket({\n    hash: rootBucket._options.hash,\n    bits: rootBucket._options.bits\n  }, parentBucket, positionAtParent)\n  parentBucket._putObjectAt(positionAtParent, bucket)\n\n  await addLinksToHamtBucket(links, bucket, rootBucket)\n\n  return bucket\n}\n\n/**\n * @param {PBLink[]} links\n */\nconst recreateInitialHamtLevel = async (links) => {\n  const bucket = createHAMT({\n    hashFn: hamtHashFn,\n    bits: hamtBucketBits\n  })\n\n  await addLinksToHamtBucket(links, bucket, bucket)\n\n  return bucket\n}\n\n/**\n * @param {PBLink[]} links\n * @param {Bucket<any>} bucket\n * @param {Bucket<any>} rootBucket\n */\nconst addLinksToHamtBucket = async (links, bucket, rootBucket) => {\n  await Promise.all(\n    links.map(link => {\n      const linkName = (link.Name || '')\n\n      if (linkName.length === 2) {\n        const pos = parseInt(linkName, 16)\n\n        bucket._putObjectAt(pos, new Bucket({\n          hash: rootBucket._options.hash,\n          bits: rootBucket._options.bits\n        }, bucket, pos))\n\n        return Promise.resolve()\n      }\n\n      return rootBucket.put(linkName.substring(2), {\n        size: link.Tsize,\n        cid: link.Hash\n      })\n    })\n  )\n}\n\n/**\n * @param {number} position\n */\nconst toPrefix = (position) => {\n  return position\n    .toString(16)\n    .toUpperCase()\n    .padStart(2, '0')\n    .substring(0, 2)\n}\n\n/**\n * @param {MfsContext} context\n * @param {string} fileName\n * @param {PBNode} rootNode\n */\nconst generatePath = async (context, fileName, rootNode) => {\n  // start at the root bucket and descend, loading nodes as we go\n  const rootBucket = await recreateInitialHamtLevel(rootNode.Links)\n  const position = await rootBucket._findNewBucketAndPos(fileName)\n\n  // the path to the root bucket\n  /** @type {{ bucket: Bucket<any>, prefix: string, node?: PBNode }[]} */\n  const path = [{\n    bucket: position.bucket,\n    prefix: toPrefix(position.pos)\n  }]\n  let currentBucket = position.bucket\n\n  while (currentBucket !== rootBucket) {\n    path.push({\n      bucket: currentBucket,\n      prefix: toPrefix(currentBucket._posAtParent)\n    })\n\n    // @ts-ignore - only the root bucket's parent will be undefined\n    currentBucket = currentBucket._parent\n  }\n\n  path.reverse()\n  path[0].node = rootNode\n\n  // load PbNode for each path segment\n  for (let i = 0; i < path.length; i++) {\n    const segment = path[i]\n\n    if (!segment.node) {\n      throw new Error('Could not generate HAMT path')\n    }\n\n    // find prefix in links\n    const link = segment.node.Links\n      .filter(link => (link.Name || '').substring(0, 2) === segment.prefix)\n      .pop()\n\n    // entry was not in shard\n    if (!link) {\n      // reached bottom of tree, file will be added to the current bucket\n      log(`Link ${segment.prefix}${fileName} will be added`)\n      // return path\n      continue\n    }\n\n    // found entry\n    if (link.Name === `${segment.prefix}${fileName}`) {\n      log(`Link ${segment.prefix}${fileName} will be replaced`)\n      // file already existed, file will be added to the current bucket\n      // return path\n      continue\n    }\n\n    // found subshard\n    log(`Found subshard ${segment.prefix}`)\n    const block = await context.repo.blocks.get(link.Hash)\n    const node = dagPb.decode(block)\n\n    // subshard hasn't been loaded, descend to the next level of the HAMT\n    if (!path[i + 1]) {\n      log(`Loaded new subshard ${segment.prefix}`)\n\n      await recreateHamtLevel(node.Links, rootBucket, segment.bucket, parseInt(segment.prefix, 16))\n      const position = await rootBucket._findNewBucketAndPos(fileName)\n\n      // i--\n      path.push({\n        bucket: position.bucket,\n        prefix: toPrefix(position.pos),\n        node: node\n      })\n\n      continue\n    }\n\n    const nextSegment = path[i + 1]\n\n    // add intermediate links to bucket\n    await addLinksToHamtBucket(node.Links, nextSegment.bucket, rootBucket)\n\n    nextSegment.node = node\n  }\n\n  await rootBucket.put(fileName, true)\n\n  path.reverse()\n\n  return {\n    rootBucket,\n    path\n  }\n}\n\n/**\n * @param {MfsContext} context\n * @param {{ name: string, size: number, cid: CID }[]} contents\n * @param {object} [options]\n * @param {Mtime} [options.mtime]\n * @param {number} [options.mode]\n */\nconst createShard = async (context, contents, options = {}) => {\n  const shard = new DirSharded({\n    root: true,\n    dir: true,\n    parent: undefined,\n    parentKey: undefined,\n    path: '',\n    dirty: true,\n    flat: false,\n    mtime: options.mtime,\n    mode: options.mode\n  }, options)\n\n  for (let i = 0; i < contents.length; i++) {\n    await shard._bucket.put(contents[i].name, {\n      size: contents[i].size,\n      cid: contents[i].cid\n    })\n  }\n\n  const res = await last(shard.flush(context.repo.blocks))\n\n  if (!res) {\n    throw new Error('Flushing shard yielded no result')\n  }\n\n  return res\n}\n\nmodule.exports = {\n  generatePath,\n  updateHamtDirectory,\n  recreateHamtLevel,\n  recreateInitialHamtLevel,\n  addLinksToHamtBucket,\n  toPrefix,\n  createShard\n}\n"],"mappings":"AAAA;;;;;;AAEA,IAAMA,KAAK,GAAGC,OAAO,CAAC,cAAD,CAArB;;AACA,eAGIA,OAAO,CAAC,eAAD,CAHX;AAAA,IACEC,MADF,YACEA,MADF;AAAA,IAEEC,UAFF,YAEEA,UAFF;;AAIA,IAAMC,UAAU,GAAGH,OAAO,CAAC,eAAD,CAA1B;;AACA,IAAMI,GAAG,GAAGJ,OAAO,CAAC,OAAD,CAAP,CAAiB,gCAAjB,CAAZ;;AACA,gBAAmBA,OAAO,CAAC,aAAD,CAA1B;AAAA,IAAQK,MAAR,aAAQA,MAAR;;AACA,IAAMC,IAAI,GAAGN,OAAO,CAAC,SAAD,CAApB;;AACA,gBAAgBA,OAAO,CAAC,kBAAD,CAAvB;AAAA,IAAQO,GAAR,aAAQA,GAAR;;AACA,gBAIIP,OAAO,CAAC,kBAAD,CAJX;AAAA,IACEQ,YADF,aACEA,YADF;AAAA,IAEEC,UAFF,aAEEA,UAFF;AAAA,IAGEC,cAHF,aAGEA,cAHF;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,IAAMC,mBAAmB;EAAA,sEAAG,iBAAOC,OAAP,EAAgBC,KAAhB,EAAuBC,MAAvB,EAA+BC,OAA/B;IAAA;IAAA;MAAA;QAAA;UAAA;YAAA,IACrBA,OAAO,CAACC,MAAR,CAAeC,IADM;cAAA;cAAA;YAAA;;YAAA,MAElB,IAAIC,KAAJ,CAAU,4DAAV,CAFkB;;UAAA;YAK1B;YACMC,IANoB,GAMbC,UAAU,CAACC,IAAX,CAAgBP,MAAM,CAACQ,SAAP,CAAiBC,QAAjB,GAA4BC,OAA5B,EAAhB,CANa;YAOpBC,IAPoB,GAObpB,MAAM,CAACqB,SAAP,CAAiBX,OAAO,CAACC,MAAR,CAAeC,IAAhC,CAPa;YAQpBU,GARoB,GAQd,IAAItB,MAAJ,CAAW;cACrBuB,IAAI,EAAE,wBADe;cAErBT,IAAI,EAAJA,IAFqB;cAGrBU,MAAM,EAAEf,MAAM,CAACgB,SAAP,EAHa;cAIrBC,QAAQ,EAAEvB,YAJW;cAKrBwB,IAAI,EAAEP,IAAI,CAACO,IALU;cAMrBC,KAAK,EAAER,IAAI,CAACQ;YANS,CAAX,CARc;YAAA;YAAA,OAiBLrB,OAAO,CAACsB,OAAR,CAAgBC,SAAhB,CAA0BpB,OAAO,CAACqB,OAAlC,CAjBK;;UAAA;YAiBpBC,MAjBoB;YAkBpBrB,MAlBoB,GAkBX;cACbC,IAAI,EAAEU,GAAG,CAACW,OAAJ,EADO;cAEbC,KAAK,EAAE1B,KAAK,CAAC2B,IAAN,CAAW,UAACC,CAAD,EAAIC,CAAJ;gBAAA,OAAU,CAACD,CAAC,CAACE,IAAF,IAAU,EAAX,EAAeC,aAAf,CAA6BF,CAAC,CAACC,IAAF,IAAU,EAAvC,CAAV;cAAA,CAAX;YAFM,CAlBW;YAsBpBE,GAtBoB,GAsBd9C,KAAK,CAAC+C,MAAN,CAAa9B,MAAb,CAtBc;YAAA;YAAA,OAuBPqB,MAAM,CAACU,MAAP,CAAcF,GAAd,CAvBO;;UAAA;YAuBpBG,IAvBoB;YAwBpBC,GAxBoB,GAwBd1C,GAAG,CAAC2C,MAAJ,CAAWnC,OAAO,CAACoC,UAAnB,EAA+BpD,KAAK,CAACqD,IAArC,EAA2CJ,IAA3C,CAxBc;;YAAA,KA0BtBjC,OAAO,CAACsC,KA1Bc;cAAA;cAAA;YAAA;;YAAA;YAAA,OA2BlBzC,OAAO,CAAC0C,IAAR,CAAaC,MAAb,CAAoBC,GAApB,CAAwBP,GAAxB,EAA6BJ,GAA7B,CA3BkB;;UAAA;YAAA,iCA8BnB;cACLpB,IAAI,EAAET,MADD;cAELiC,GAAG,EAAHA,GAFK;cAGLQ,IAAI,EAAE5C,KAAK,CAAC6C,MAAN,CAAa,UAACC,GAAD,EAAMC,IAAN;gBAAA,OAAeD,GAAG,IAAIC,IAAI,CAACC,KAAL,IAAc,CAAlB,CAAlB;cAAA,CAAb,EAAqDhB,GAAG,CAACiB,MAAzD;YAHD,CA9BmB;;UAAA;UAAA;YAAA;QAAA;MAAA;IAAA;EAAA,CAAH;;EAAA,gBAAnBnD,mBAAmB;IAAA;EAAA;AAAA,GAAzB;AAqCA;AACA;AACA;AACA;AACA;AACA;;;AACA,IAAMoD,iBAAiB;EAAA,uEAAG,kBAAOlD,KAAP,EAAcmD,UAAd,EAA0BC,YAA1B,EAAwCC,gBAAxC;IAAA;IAAA;MAAA;QAAA;UAAA;YACxB;YACMpD,MAFkB,GAET,IAAIb,MAAJ,CAAW;cACxB+C,IAAI,EAAEgB,UAAU,CAACG,QAAX,CAAoBnB,IADF;cAExBoB,IAAI,EAAEJ,UAAU,CAACG,QAAX,CAAoBC;YAFF,CAAX,EAGZH,YAHY,EAGEC,gBAHF,CAFS;;YAMxBD,YAAY,CAACI,YAAb,CAA0BH,gBAA1B,EAA4CpD,MAA5C;;YANwB;YAAA,OAQlBwD,oBAAoB,CAACzD,KAAD,EAAQC,MAAR,EAAgBkD,UAAhB,CARF;;UAAA;YAAA,kCAUjBlD,MAViB;;UAAA;UAAA;YAAA;QAAA;MAAA;IAAA;EAAA,CAAH;;EAAA,gBAAjBiD,iBAAiB;IAAA;EAAA;AAAA,GAAvB;AAaA;AACA;AACA;;;AACA,IAAMQ,wBAAwB;EAAA,uEAAG,kBAAO1D,KAAP;IAAA;IAAA;MAAA;QAAA;UAAA;YACzBC,MADyB,GAChBZ,UAAU,CAAC;cACxBsE,MAAM,EAAE/D,UADgB;cAExB2D,IAAI,EAAE1D;YAFkB,CAAD,CADM;YAAA;YAAA,OAMzB4D,oBAAoB,CAACzD,KAAD,EAAQC,MAAR,EAAgBA,MAAhB,CANK;;UAAA;YAAA,kCAQxBA,MARwB;;UAAA;UAAA;YAAA;QAAA;MAAA;IAAA;EAAA,CAAH;;EAAA,gBAAxByD,wBAAwB;IAAA;EAAA;AAAA,GAA9B;AAWA;AACA;AACA;AACA;AACA;;;AACA,IAAMD,oBAAoB;EAAA,uEAAG,kBAAOzD,KAAP,EAAcC,MAAd,EAAsBkD,UAAtB;IAAA;MAAA;QAAA;UAAA;YAAA;YAAA,OACrBS,OAAO,CAACC,GAAR,CACJ7D,KAAK,CAAC8D,GAAN,CAAU,UAAAf,IAAI,EAAI;cAChB,IAAMgB,QAAQ,GAAIhB,IAAI,CAACjB,IAAL,IAAa,EAA/B;;cAEA,IAAIiC,QAAQ,CAACd,MAAT,KAAoB,CAAxB,EAA2B;gBACzB,IAAMe,GAAG,GAAGC,QAAQ,CAACF,QAAD,EAAW,EAAX,CAApB;;gBAEA9D,MAAM,CAACuD,YAAP,CAAoBQ,GAApB,EAAyB,IAAI5E,MAAJ,CAAW;kBAClC+C,IAAI,EAAEgB,UAAU,CAACG,QAAX,CAAoBnB,IADQ;kBAElCoB,IAAI,EAAEJ,UAAU,CAACG,QAAX,CAAoBC;gBAFQ,CAAX,EAGtBtD,MAHsB,EAGd+D,GAHc,CAAzB;;gBAKA,OAAOJ,OAAO,CAACM,OAAR,EAAP;cACD;;cAED,OAAOf,UAAU,CAACR,GAAX,CAAeoB,QAAQ,CAACI,SAAT,CAAmB,CAAnB,CAAf,EAAsC;gBAC3CvB,IAAI,EAAEG,IAAI,CAACC,KADgC;gBAE3CZ,GAAG,EAAEW,IAAI,CAACqB;cAFiC,CAAtC,CAAP;YAID,CAlBD,CADI,CADqB;;UAAA;UAAA;YAAA;QAAA;MAAA;IAAA;EAAA,CAAH;;EAAA,gBAApBX,oBAAoB;IAAA;EAAA;AAAA,GAA1B;AAwBA;AACA;AACA;;;AACA,IAAMY,QAAQ,GAAG,SAAXA,QAAW,CAACC,QAAD,EAAc;EAC7B,OAAOA,QAAQ,CACZC,QADI,CACK,EADL,EAEJC,WAFI,GAGJC,QAHI,CAGK,CAHL,EAGQ,GAHR,EAIJN,SAJI,CAIM,CAJN,EAIS,CAJT,CAAP;AAKD,CAND;AAQA;AACA;AACA;AACA;AACA;;;AACA,IAAMO,YAAY;EAAA,uEAAG,kBAAO3E,OAAP,EAAgB4E,QAAhB,EAA0BC,QAA1B;IAAA;;IAAA;MAAA;QAAA;UAAA;YAAA;YAAA,OAEMlB,wBAAwB,CAACkB,QAAQ,CAAClD,KAAV,CAF9B;;UAAA;YAEbyB,UAFa;YAAA;YAAA,OAGIA,UAAU,CAAC0B,oBAAX,CAAgCF,QAAhC,CAHJ;;UAAA;YAGbL,QAHa;YAKnB;;YACA;YACMQ,IAPa,GAON,CAAC;cACZ7E,MAAM,EAAEqE,QAAQ,CAACrE,MADL;cAEZ8E,MAAM,EAAEV,QAAQ,CAACC,QAAQ,CAACN,GAAV;YAFJ,CAAD,CAPM;YAWfgB,aAXe,GAWCV,QAAQ,CAACrE,MAXV;;YAanB,OAAO+E,aAAa,KAAK7B,UAAzB,EAAqC;cACnC2B,IAAI,CAACG,IAAL,CAAU;gBACRhF,MAAM,EAAE+E,aADA;gBAERD,MAAM,EAAEV,QAAQ,CAACW,aAAa,CAACE,YAAf;cAFR,CAAV,EADmC,CAMnC;;cACAF,aAAa,GAAGA,aAAa,CAACG,OAA9B;YACD;;YAEDL,IAAI,CAACnE,OAAL;YACAmE,IAAI,CAAC,CAAD,CAAJ,CAAQlE,IAAR,GAAegE,QAAf,CAxBmB,CA0BnB;;YA1BmB,+DA2BVQ,CA3BU;cAAA;;cAAA;gBAAA;kBAAA;oBAAA;sBA4BXC,OA5BW,GA4BDP,IAAI,CAACM,CAAD,CA5BH;;sBAAA,IA8BZC,OAAO,CAACzE,IA9BI;wBAAA;wBAAA;sBAAA;;sBAAA,MA+BT,IAAIP,KAAJ,CAAU,8BAAV,CA/BS;;oBAAA;sBAkCjB;sBACM0C,IAnCW,GAmCJsC,OAAO,CAACzE,IAAR,CAAac,KAAb,CACV4D,MADU,CACH,UAAAvC,IAAI;wBAAA,OAAI,CAACA,IAAI,CAACjB,IAAL,IAAa,EAAd,EAAkBqC,SAAlB,CAA4B,CAA5B,EAA+B,CAA/B,MAAsCkB,OAAO,CAACN,MAAlD;sBAAA,CADD,EAEVQ,GAFU,EAnCI,EAuCjB;;sBAvCiB,IAwCZxC,IAxCY;wBAAA;wBAAA;sBAAA;;sBAyCf;sBACAxD,GAAG,gBAAS8F,OAAO,CAACN,MAAjB,SAA0BJ,QAA1B,oBAAH,CA1Ce,CA2Cf;;sBA3Ce;;oBAAA;sBAAA,MAgDb5B,IAAI,CAACjB,IAAL,eAAiBuD,OAAO,CAACN,MAAzB,SAAkCJ,QAAlC,CAhDa;wBAAA;wBAAA;sBAAA;;sBAiDfpF,GAAG,gBAAS8F,OAAO,CAACN,MAAjB,SAA0BJ,QAA1B,uBAAH,CAjDe,CAkDf;sBACA;;sBAnDe;;oBAAA;sBAuDjB;sBACApF,GAAG,0BAAmB8F,OAAO,CAACN,MAA3B,EAAH;sBAxDiB;sBAAA,OAyDGhF,OAAO,CAAC0C,IAAR,CAAaC,MAAb,CAAoB8C,GAApB,CAAwBzC,IAAI,CAACqB,IAA7B,CAzDH;;oBAAA;sBAyDXqB,KAzDW;sBA0DX7E,IA1DW,GA0DJ1B,KAAK,CAACwG,MAAN,CAAaD,KAAb,CA1DI,EA4DjB;;sBA5DiB,IA6DZX,IAAI,CAACM,CAAC,GAAG,CAAL,CA7DQ;wBAAA;wBAAA;sBAAA;;sBA8Df7F,GAAG,+BAAwB8F,OAAO,CAACN,MAAhC,EAAH;sBA9De;sBAAA,OAgET7B,iBAAiB,CAACtC,IAAI,CAACc,KAAN,EAAayB,UAAb,EAAyBkC,OAAO,CAACpF,MAAjC,EAAyCgE,QAAQ,CAACoB,OAAO,CAACN,MAAT,EAAiB,EAAjB,CAAjD,CAhER;;oBAAA;sBAAA;sBAAA,OAiEQ5B,UAAU,CAAC0B,oBAAX,CAAgCF,QAAhC,CAjER;;oBAAA;sBAiETL,SAjES;sBAmEf;sBACAQ,IAAI,CAACG,IAAL,CAAU;wBACRhF,MAAM,EAAEqE,SAAQ,CAACrE,MADT;wBAER8E,MAAM,EAAEV,QAAQ,CAACC,SAAQ,CAACN,GAAV,CAFR;wBAGRpD,IAAI,EAAEA;sBAHE,CAAV;sBApEe;;oBAAA;sBA6EX+E,WA7EW,GA6EGb,IAAI,CAACM,CAAC,GAAG,CAAL,CA7EP,EA+EjB;;sBA/EiB;sBAAA,OAgFX3B,oBAAoB,CAAC7C,IAAI,CAACc,KAAN,EAAaiE,WAAW,CAAC1F,MAAzB,EAAiCkD,UAAjC,CAhFT;;oBAAA;sBAkFjBwC,WAAW,CAAC/E,IAAZ,GAAmBA,IAAnB;;oBAlFiB;oBAAA;sBAAA;kBAAA;gBAAA;cAAA;YAAA;YA2BVwE,CA3BU,GA2BN,CA3BM;;UAAA;YAAA,MA2BHA,CAAC,GAAGN,IAAI,CAAC7B,MA3BN;cAAA;cAAA;YAAA;;YAAA,qCA2BVmC,CA3BU;;UAAA;YAAA;;YAAA;cAAA;cAAA;YAAA;;YAAA;;UAAA;YA2BcA,CAAC,EA3Bf;YAAA;YAAA;;UAAA;YAAA;YAAA,OAqFbjC,UAAU,CAACR,GAAX,CAAegC,QAAf,EAAyB,IAAzB,CArFa;;UAAA;YAuFnBG,IAAI,CAACnE,OAAL;YAvFmB,kCAyFZ;cACLwC,UAAU,EAAVA,UADK;cAEL2B,IAAI,EAAJA;YAFK,CAzFY;;UAAA;UAAA;YAAA;QAAA;MAAA;IAAA;EAAA,CAAH;;EAAA,gBAAZJ,YAAY;IAAA;EAAA;AAAA,GAAlB;AA+FA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,IAAMkB,WAAW;EAAA,uEAAG,kBAAO7F,OAAP,EAAgB8F,QAAhB;IAAA;IAAA;IAAA;IAAA;IAAA;IAAA;MAAA;QAAA;UAAA;YAA0B3F,OAA1B,8DAAoC,EAApC;YACZ4F,KADY,GACJ,IAAIxG,UAAJ,CAAe;cAC3ByG,IAAI,EAAE,IADqB;cAE3BjF,GAAG,EAAE,IAFsB;cAG3BX,MAAM,EAAE6F,SAHmB;cAI3BC,SAAS,EAAED,SAJgB;cAK3BlB,IAAI,EAAE,EALqB;cAM3BoB,KAAK,EAAE,IANoB;cAO3BC,IAAI,EAAE,KAPqB;cAQ3B/E,KAAK,EAAElB,OAAO,CAACkB,KARY;cAS3BD,IAAI,EAAEjB,OAAO,CAACiB;YATa,CAAf,EAUXjB,OAVW,CADI;YAaTkF,CAbS,GAaL,CAbK;;UAAA;YAAA,MAaFA,CAAC,GAAGS,QAAQ,CAAC5C,MAbX;cAAA;cAAA;YAAA;;YAAA;YAAA,OAcV6C,KAAK,CAACM,OAAN,CAAczD,GAAd,CAAkBkD,QAAQ,CAACT,CAAD,CAAR,CAAYiB,IAA9B,EAAoC;cACxCzD,IAAI,EAAEiD,QAAQ,CAACT,CAAD,CAAR,CAAYxC,IADsB;cAExCR,GAAG,EAAEyD,QAAQ,CAACT,CAAD,CAAR,CAAYhD;YAFuB,CAApC,CAdU;;UAAA;YAamBgD,CAAC,EAbpB;YAAA;YAAA;;UAAA;YAAA;YAAA,OAoBA3F,IAAI,CAACqG,KAAK,CAACtD,KAAN,CAAYzC,OAAO,CAAC0C,IAAR,CAAaC,MAAzB,CAAD,CApBJ;;UAAA;YAoBZ4D,GApBY;;YAAA,IAsBbA,GAtBa;cAAA;cAAA;YAAA;;YAAA,MAuBV,IAAIjG,KAAJ,CAAU,kCAAV,CAvBU;;UAAA;YAAA,kCA0BXiG,GA1BW;;UAAA;UAAA;YAAA;QAAA;MAAA;IAAA;EAAA,CAAH;;EAAA,gBAAXV,WAAW;IAAA;EAAA;AAAA,GAAjB;;AA6BAW,MAAM,CAACC,OAAP,GAAiB;EACf9B,YAAY,EAAZA,YADe;EAEf5E,mBAAmB,EAAnBA,mBAFe;EAGfoD,iBAAiB,EAAjBA,iBAHe;EAIfQ,wBAAwB,EAAxBA,wBAJe;EAKfD,oBAAoB,EAApBA,oBALe;EAMfY,QAAQ,EAARA,QANe;EAOfuB,WAAW,EAAXA;AAPe,CAAjB"},"metadata":{},"sourceType":"script"}