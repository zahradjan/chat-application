{"ast":null,"code":"'use strict';\n\nconst pMap = require('p-map');\n\nconst pDoWhilst = require('p-do-whilst');\n\nconst Entry = require('./entry');\n\nconst hasItems = arr => arr && arr.length > 0;\n\nclass EntryIO {\n  // Fetch log graphs in parallel\n  static async fetchParallel(ipfs, hashes, _ref) {\n    let {\n      length,\n      exclude = [],\n      shouldExclude,\n      timeout,\n      concurrency,\n      onProgressCallback\n    } = _ref;\n\n    const fetchOne = async hash => EntryIO.fetchAll(ipfs, hash, {\n      length,\n      exclude,\n      shouldExclude,\n      timeout,\n      onProgressCallback,\n      concurrency\n    });\n\n    const concatArrays = (arr1, arr2) => arr1.concat(arr2);\n\n    const flatten = arr => arr.reduce(concatArrays, []);\n\n    const res = await pMap(hashes, fetchOne, {\n      concurrency: Math.max(concurrency || hashes.length, 1)\n    });\n    return flatten(res);\n  }\n  /**\n   * Fetch log entries\n   *\n   * @param {IPFS} [ipfs] An IPFS instance\n   * @param {string} [hash] Multihash of the entry to fetch\n   * @param {string} [parent] Parent of the node to be fetched\n   * @param {Object} [all] Entries to skip\n   * @param {Number} [amount=-1] How many entries to fetch\n   * @param {Number} [depth=0] Current depth of the recursion\n   * @param {function(entry)} shouldExclude A function that can be passed to determine whether a specific hash should be excluded, ie. not fetched. The function should return true to indicate exclusion, otherwise return false.\n   * @param {function(entry)} onProgressCallback Called when an entry was fetched\n   * @returns {Promise<Array<Entry>>}\n   */\n\n\n  static async fetchAll(ipfs, hashes) {\n    let {\n      length = -1,\n      exclude = [],\n      shouldExclude,\n      timeout,\n      onProgressCallback,\n      onStartProgressCallback,\n      concurrency = 32,\n      delay = 0\n    } = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n    const result = [];\n    const cache = {};\n    const loadingCache = {};\n    const loadingQueue = Array.isArray(hashes) ? {\n      0: hashes.slice()\n    } : {\n      0: [hashes]\n    };\n    let running = 0; // keep track of how many entries are being fetched at any time\n\n    let maxClock = 0; // keep track of the latest clock time during load\n\n    let minClock = 0; // keep track of the minimum clock time during load\n\n    shouldExclude = shouldExclude || (() => false); // default fn returns false to not exclude any hash\n    // Does the loading queue have more to process?\n\n\n    const loadingQueueHasMore = () => Object.values(loadingQueue).find(hasItems) !== undefined; // Add a multihash to the loading queue\n\n\n    const addToLoadingQueue = (e, idx) => {\n      if (!loadingCache[e] && !shouldExclude(e)) {\n        if (!loadingQueue[idx]) loadingQueue[idx] = [];\n\n        if (!loadingQueue[idx].includes(e)) {\n          loadingQueue[idx].push(e);\n        }\n\n        loadingCache[e] = true;\n      }\n    }; // Get the next items to process from the loading queue\n\n\n    const getNextFromQueue = function () {\n      let length = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 1;\n\n      const getNext = (res, key, idx) => {\n        const nextItems = loadingQueue[key];\n\n        while (nextItems.length > 0 && res.length < length) {\n          const hash = nextItems.shift();\n          res.push(hash);\n        }\n\n        if (nextItems.length === 0) {\n          delete loadingQueue[key];\n        }\n\n        return res;\n      };\n\n      return Object.keys(loadingQueue).reduce(getNext, []);\n    }; // Add entries that we don't need to fetch to the \"cache\"\n\n\n    const addToExcludeCache = e => {\n      cache[e.hash || e] = true;\n    }; // Fetch one entry and add it to the results\n\n\n    const fetchEntry = async hash => {\n      if (!hash || cache[hash] || shouldExclude(hash)) {\n        return;\n      }\n      /* eslint-disable no-async-promise-executor */\n\n\n      return new Promise(async (resolve, reject) => {\n        // Resolve the promise after a timeout (if given) in order to\n        // not get stuck loading a block that is unreachable\n        const timer = timeout && timeout > 0 ? setTimeout(() => {\n          console.warn(`Warning: Couldn't fetch entry '${hash}', request timed out (${timeout}ms)`);\n          resolve();\n        }, timeout) : null;\n\n        const addToResults = entry => {\n          if (Entry.isEntry(entry) && !cache[entry.hash] && !shouldExclude(entry.hash)) {\n            const ts = entry.clock.time; // Update min/max clocks\n\n            maxClock = Math.max(maxClock, ts);\n            minClock = result.length > 0 ? Math.min(result[result.length - 1].clock.time, minClock) : maxClock;\n            const isLater = result.length >= length && ts >= minClock;\n\n            const calculateIndex = idx => maxClock - ts + (idx + 1) * idx; // Add the entry to the results if\n            // 1) we're fetching all entries\n            // 2) results is not filled yet\n            // the clock of the entry is later than current known minimum clock time\n\n\n            if ((length < 0 || result.length < length || isLater) && !shouldExclude(entry.hash) && !cache[entry.hash]) {\n              result.push(entry);\n              cache[entry.hash] = true;\n\n              if (onProgressCallback) {\n                onProgressCallback(entry);\n              }\n            }\n\n            if (length < 0) {\n              // If we're fetching all entries (length === -1), adds nexts and refs to the queue\n              entry.next.forEach(addToLoadingQueue);\n              if (entry.refs) entry.refs.forEach(addToLoadingQueue);\n            } else {\n              // If we're fetching entries up to certain length,\n              // fetch the next if result is filled up, to make sure we \"check\"\n              // the next entry if its clock is later than what we have in the result\n              if (result.length < length || ts > minClock || ts === minClock && !cache[entry.hash] && !shouldExclude(entry.hash)) {\n                entry.next.forEach(e => addToLoadingQueue(e, calculateIndex(0)));\n              }\n\n              if (entry.refs && result.length + entry.refs.length <= length) {\n                entry.refs.forEach((e, i) => addToLoadingQueue(e, calculateIndex(i)));\n              }\n            }\n          }\n        };\n\n        if (onStartProgressCallback) {\n          onStartProgressCallback(hash, null, 0, result.length);\n        }\n\n        try {\n          // Load the entry\n          const entry = await Entry.fromMultihash(ipfs, hash); // Simulate network latency (for debugging purposes)\n\n          if (delay > 0) {\n            const sleep = function () {\n              let ms = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;\n              return new Promise(resolve => setTimeout(resolve, ms));\n            };\n\n            await sleep(delay);\n          } // Add it to the results\n\n\n          addToResults(entry);\n          resolve();\n        } catch (e) {\n          reject(e);\n        } finally {\n          clearTimeout(timer);\n        }\n      });\n    }; // One loop of processing the loading queue\n\n\n    const _processQueue = async () => {\n      if (running < concurrency) {\n        const nexts = getNextFromQueue(concurrency);\n        running += nexts.length;\n        await pMap(nexts, fetchEntry, {\n          concurrency\n        });\n        running -= nexts.length;\n      }\n    }; // Add entries to exclude from processing to the cache before we start\n\n\n    exclude.forEach(addToExcludeCache); // Fetch entries\n\n    await pDoWhilst(_processQueue, loadingQueueHasMore);\n    return result;\n  }\n\n}\n\nmodule.exports = EntryIO;","map":{"version":3,"names":["pMap","require","pDoWhilst","Entry","hasItems","arr","length","EntryIO","fetchParallel","ipfs","hashes","exclude","shouldExclude","timeout","concurrency","onProgressCallback","fetchOne","hash","fetchAll","concatArrays","arr1","arr2","concat","flatten","reduce","res","Math","max","onStartProgressCallback","delay","result","cache","loadingCache","loadingQueue","Array","isArray","slice","running","maxClock","minClock","loadingQueueHasMore","Object","values","find","undefined","addToLoadingQueue","e","idx","includes","push","getNextFromQueue","getNext","key","nextItems","shift","keys","addToExcludeCache","fetchEntry","Promise","resolve","reject","timer","setTimeout","console","warn","addToResults","entry","isEntry","ts","clock","time","min","isLater","calculateIndex","next","forEach","refs","i","fromMultihash","sleep","ms","clearTimeout","_processQueue","nexts","module","exports"],"sources":["C:/Users/zajan/GitHub/chatApplication/node_modules/ipfs-log/src/entry-io.js"],"sourcesContent":["'use strict'\n\nconst pMap = require('p-map')\nconst pDoWhilst = require('p-do-whilst')\nconst Entry = require('./entry')\n\nconst hasItems = arr => arr && arr.length > 0\n\nclass EntryIO {\n  // Fetch log graphs in parallel\n  static async fetchParallel (ipfs, hashes, { length, exclude = [], shouldExclude, timeout, concurrency, onProgressCallback }) {\n    const fetchOne = async (hash) => EntryIO.fetchAll(ipfs, hash, { length, exclude, shouldExclude, timeout, onProgressCallback, concurrency })\n    const concatArrays = (arr1, arr2) => arr1.concat(arr2)\n    const flatten = (arr) => arr.reduce(concatArrays, [])\n    const res = await pMap(hashes, fetchOne, { concurrency: Math.max(concurrency || hashes.length, 1) })\n    return flatten(res)\n  }\n\n  /**\n   * Fetch log entries\n   *\n   * @param {IPFS} [ipfs] An IPFS instance\n   * @param {string} [hash] Multihash of the entry to fetch\n   * @param {string} [parent] Parent of the node to be fetched\n   * @param {Object} [all] Entries to skip\n   * @param {Number} [amount=-1] How many entries to fetch\n   * @param {Number} [depth=0] Current depth of the recursion\n   * @param {function(entry)} shouldExclude A function that can be passed to determine whether a specific hash should be excluded, ie. not fetched. The function should return true to indicate exclusion, otherwise return false.\n   * @param {function(entry)} onProgressCallback Called when an entry was fetched\n   * @returns {Promise<Array<Entry>>}\n   */\n  static async fetchAll (ipfs, hashes, { length = -1, exclude = [], shouldExclude, timeout, onProgressCallback, onStartProgressCallback, concurrency = 32, delay = 0 } = {}) {\n    const result = []\n    const cache = {}\n    const loadingCache = {}\n    const loadingQueue = Array.isArray(hashes)\n      ? { 0: hashes.slice() }\n      : { 0: [hashes] }\n    let running = 0 // keep track of how many entries are being fetched at any time\n    let maxClock = 0 // keep track of the latest clock time during load\n    let minClock = 0 // keep track of the minimum clock time during load\n    shouldExclude = shouldExclude || (() => false) // default fn returns false to not exclude any hash\n\n    // Does the loading queue have more to process?\n    const loadingQueueHasMore = () => Object.values(loadingQueue).find(hasItems) !== undefined\n\n    // Add a multihash to the loading queue\n    const addToLoadingQueue = (e, idx) => {\n      if (!loadingCache[e] && !shouldExclude(e)) {\n        if (!loadingQueue[idx]) loadingQueue[idx] = []\n        if (!loadingQueue[idx].includes(e)) {\n          loadingQueue[idx].push(e)\n        }\n        loadingCache[e] = true\n      }\n    }\n\n    // Get the next items to process from the loading queue\n    const getNextFromQueue = (length = 1) => {\n      const getNext = (res, key, idx) => {\n        const nextItems = loadingQueue[key]\n        while (nextItems.length > 0 && res.length < length) {\n          const hash = nextItems.shift()\n          res.push(hash)\n        }\n        if (nextItems.length === 0) {\n          delete loadingQueue[key]\n        }\n        return res\n      }\n      return Object.keys(loadingQueue).reduce(getNext, [])\n    }\n\n    // Add entries that we don't need to fetch to the \"cache\"\n    const addToExcludeCache = e => { cache[e.hash || e] = true }\n\n    // Fetch one entry and add it to the results\n    const fetchEntry = async (hash) => {\n      if (!hash || cache[hash] || shouldExclude(hash)) {\n        return\n      }\n\n      /* eslint-disable no-async-promise-executor */\n      return new Promise(async (resolve, reject) => {\n        // Resolve the promise after a timeout (if given) in order to\n        // not get stuck loading a block that is unreachable\n        const timer = timeout && timeout > 0\n          ? setTimeout(() => {\n              console.warn(`Warning: Couldn't fetch entry '${hash}', request timed out (${timeout}ms)`)\n              resolve()\n            }, timeout)\n          : null\n\n        const addToResults = (entry) => {\n          if (Entry.isEntry(entry) && !cache[entry.hash] && !shouldExclude(entry.hash)) {\n            const ts = entry.clock.time\n\n            // Update min/max clocks\n            maxClock = Math.max(maxClock, ts)\n            minClock = result.length > 0\n              ? Math.min(result[result.length - 1].clock.time, minClock)\n              : maxClock\n\n            const isLater = (result.length >= length && ts >= minClock)\n            const calculateIndex = (idx) => maxClock - ts + ((idx + 1) * idx)\n\n            // Add the entry to the results if\n            // 1) we're fetching all entries\n            // 2) results is not filled yet\n            // the clock of the entry is later than current known minimum clock time\n            if ((length < 0 || result.length < length || isLater) && !shouldExclude(entry.hash) && !cache[entry.hash]) {\n              result.push(entry)\n              cache[entry.hash] = true\n\n              if (onProgressCallback) {\n                onProgressCallback(entry)\n              }\n            }\n\n            if (length < 0) {\n              // If we're fetching all entries (length === -1), adds nexts and refs to the queue\n              entry.next.forEach(addToLoadingQueue)\n              if (entry.refs) entry.refs.forEach(addToLoadingQueue)\n            } else {\n              // If we're fetching entries up to certain length,\n              // fetch the next if result is filled up, to make sure we \"check\"\n              // the next entry if its clock is later than what we have in the result\n              if (result.length < length || ts > minClock || (ts === minClock && !cache[entry.hash] && !shouldExclude(entry.hash))) {\n                entry.next.forEach(e => addToLoadingQueue(e, calculateIndex(0)))\n              }\n              if (entry.refs && (result.length + entry.refs.length <= length)) {\n                entry.refs.forEach((e, i) => addToLoadingQueue(e, calculateIndex(i)))\n              }\n            }\n          }\n        }\n\n        if (onStartProgressCallback) {\n          onStartProgressCallback(hash, null, 0, result.length)\n        }\n\n        try {\n          // Load the entry\n          const entry = await Entry.fromMultihash(ipfs, hash)\n          // Simulate network latency (for debugging purposes)\n          if (delay > 0) {\n            const sleep = (ms = 0) => new Promise(resolve => setTimeout(resolve, ms))\n            await sleep(delay)\n          }\n          // Add it to the results\n          addToResults(entry)\n          resolve()\n        } catch (e) {\n          reject(e)\n        } finally {\n          clearTimeout(timer)\n        }\n      })\n    }\n\n    // One loop of processing the loading queue\n    const _processQueue = async () => {\n      if (running < concurrency) {\n        const nexts = getNextFromQueue(concurrency)\n        running += nexts.length\n        await pMap(nexts, fetchEntry, { concurrency })\n        running -= nexts.length\n      }\n    }\n\n    // Add entries to exclude from processing to the cache before we start\n    exclude.forEach(addToExcludeCache)\n\n    // Fetch entries\n    await pDoWhilst(_processQueue, loadingQueueHasMore)\n\n    return result\n  }\n}\n\nmodule.exports = EntryIO\n"],"mappings":"AAAA;;AAEA,MAAMA,IAAI,GAAGC,OAAO,CAAC,OAAD,CAApB;;AACA,MAAMC,SAAS,GAAGD,OAAO,CAAC,aAAD,CAAzB;;AACA,MAAME,KAAK,GAAGF,OAAO,CAAC,SAAD,CAArB;;AAEA,MAAMG,QAAQ,GAAGC,GAAG,IAAIA,GAAG,IAAIA,GAAG,CAACC,MAAJ,GAAa,CAA5C;;AAEA,MAAMC,OAAN,CAAc;EACZ;EAC0B,aAAbC,aAAa,CAAEC,IAAF,EAAQC,MAAR,QAAmG;IAAA,IAAnF;MAAEJ,MAAF;MAAUK,OAAO,GAAG,EAApB;MAAwBC,aAAxB;MAAuCC,OAAvC;MAAgDC,WAAhD;MAA6DC;IAA7D,CAAmF;;IAC3H,MAAMC,QAAQ,GAAG,MAAOC,IAAP,IAAgBV,OAAO,CAACW,QAAR,CAAiBT,IAAjB,EAAuBQ,IAAvB,EAA6B;MAAEX,MAAF;MAAUK,OAAV;MAAmBC,aAAnB;MAAkCC,OAAlC;MAA2CE,kBAA3C;MAA+DD;IAA/D,CAA7B,CAAjC;;IACA,MAAMK,YAAY,GAAG,CAACC,IAAD,EAAOC,IAAP,KAAgBD,IAAI,CAACE,MAAL,CAAYD,IAAZ,CAArC;;IACA,MAAME,OAAO,GAAIlB,GAAD,IAASA,GAAG,CAACmB,MAAJ,CAAWL,YAAX,EAAyB,EAAzB,CAAzB;;IACA,MAAMM,GAAG,GAAG,MAAMzB,IAAI,CAACU,MAAD,EAASM,QAAT,EAAmB;MAAEF,WAAW,EAAEY,IAAI,CAACC,GAAL,CAASb,WAAW,IAAIJ,MAAM,CAACJ,MAA/B,EAAuC,CAAvC;IAAf,CAAnB,CAAtB;IACA,OAAOiB,OAAO,CAACE,GAAD,CAAd;EACD;EAED;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;EACuB,aAARP,QAAQ,CAAET,IAAF,EAAQC,MAAR,EAAsJ;IAAA,IAAtI;MAAEJ,MAAM,GAAG,CAAC,CAAZ;MAAeK,OAAO,GAAG,EAAzB;MAA6BC,aAA7B;MAA4CC,OAA5C;MAAqDE,kBAArD;MAAyEa,uBAAzE;MAAkGd,WAAW,GAAG,EAAhH;MAAoHe,KAAK,GAAG;IAA5H,CAAsI,uEAAJ,EAAI;IACzK,MAAMC,MAAM,GAAG,EAAf;IACA,MAAMC,KAAK,GAAG,EAAd;IACA,MAAMC,YAAY,GAAG,EAArB;IACA,MAAMC,YAAY,GAAGC,KAAK,CAACC,OAAN,CAAczB,MAAd,IACjB;MAAE,GAAGA,MAAM,CAAC0B,KAAP;IAAL,CADiB,GAEjB;MAAE,GAAG,CAAC1B,MAAD;IAAL,CAFJ;IAGA,IAAI2B,OAAO,GAAG,CAAd,CAPyK,CAOzJ;;IAChB,IAAIC,QAAQ,GAAG,CAAf,CARyK,CAQxJ;;IACjB,IAAIC,QAAQ,GAAG,CAAf,CATyK,CASxJ;;IACjB3B,aAAa,GAAGA,aAAa,KAAK,MAAM,KAAX,CAA7B,CAVyK,CAU1H;IAE/C;;;IACA,MAAM4B,mBAAmB,GAAG,MAAMC,MAAM,CAACC,MAAP,CAAcT,YAAd,EAA4BU,IAA5B,CAAiCvC,QAAjC,MAA+CwC,SAAjF,CAbyK,CAezK;;;IACA,MAAMC,iBAAiB,GAAG,CAACC,CAAD,EAAIC,GAAJ,KAAY;MACpC,IAAI,CAACf,YAAY,CAACc,CAAD,CAAb,IAAoB,CAAClC,aAAa,CAACkC,CAAD,CAAtC,EAA2C;QACzC,IAAI,CAACb,YAAY,CAACc,GAAD,CAAjB,EAAwBd,YAAY,CAACc,GAAD,CAAZ,GAAoB,EAApB;;QACxB,IAAI,CAACd,YAAY,CAACc,GAAD,CAAZ,CAAkBC,QAAlB,CAA2BF,CAA3B,CAAL,EAAoC;UAClCb,YAAY,CAACc,GAAD,CAAZ,CAAkBE,IAAlB,CAAuBH,CAAvB;QACD;;QACDd,YAAY,CAACc,CAAD,CAAZ,GAAkB,IAAlB;MACD;IACF,CARD,CAhByK,CA0BzK;;;IACA,MAAMI,gBAAgB,GAAG,YAAgB;MAAA,IAAf5C,MAAe,uEAAN,CAAM;;MACvC,MAAM6C,OAAO,GAAG,CAAC1B,GAAD,EAAM2B,GAAN,EAAWL,GAAX,KAAmB;QACjC,MAAMM,SAAS,GAAGpB,YAAY,CAACmB,GAAD,CAA9B;;QACA,OAAOC,SAAS,CAAC/C,MAAV,GAAmB,CAAnB,IAAwBmB,GAAG,CAACnB,MAAJ,GAAaA,MAA5C,EAAoD;UAClD,MAAMW,IAAI,GAAGoC,SAAS,CAACC,KAAV,EAAb;UACA7B,GAAG,CAACwB,IAAJ,CAAShC,IAAT;QACD;;QACD,IAAIoC,SAAS,CAAC/C,MAAV,KAAqB,CAAzB,EAA4B;UAC1B,OAAO2B,YAAY,CAACmB,GAAD,CAAnB;QACD;;QACD,OAAO3B,GAAP;MACD,CAVD;;MAWA,OAAOgB,MAAM,CAACc,IAAP,CAAYtB,YAAZ,EAA0BT,MAA1B,CAAiC2B,OAAjC,EAA0C,EAA1C,CAAP;IACD,CAbD,CA3ByK,CA0CzK;;;IACA,MAAMK,iBAAiB,GAAGV,CAAC,IAAI;MAAEf,KAAK,CAACe,CAAC,CAAC7B,IAAF,IAAU6B,CAAX,CAAL,GAAqB,IAArB;IAA2B,CAA5D,CA3CyK,CA6CzK;;;IACA,MAAMW,UAAU,GAAG,MAAOxC,IAAP,IAAgB;MACjC,IAAI,CAACA,IAAD,IAASc,KAAK,CAACd,IAAD,CAAd,IAAwBL,aAAa,CAACK,IAAD,CAAzC,EAAiD;QAC/C;MACD;MAED;;;MACA,OAAO,IAAIyC,OAAJ,CAAY,OAAOC,OAAP,EAAgBC,MAAhB,KAA2B;QAC5C;QACA;QACA,MAAMC,KAAK,GAAGhD,OAAO,IAAIA,OAAO,GAAG,CAArB,GACViD,UAAU,CAAC,MAAM;UACfC,OAAO,CAACC,IAAR,CAAc,kCAAiC/C,IAAK,yBAAwBJ,OAAQ,KAApF;UACA8C,OAAO;QACR,CAHS,EAGP9C,OAHO,CADA,GAKV,IALJ;;QAOA,MAAMoD,YAAY,GAAIC,KAAD,IAAW;UAC9B,IAAI/D,KAAK,CAACgE,OAAN,CAAcD,KAAd,KAAwB,CAACnC,KAAK,CAACmC,KAAK,CAACjD,IAAP,CAA9B,IAA8C,CAACL,aAAa,CAACsD,KAAK,CAACjD,IAAP,CAAhE,EAA8E;YAC5E,MAAMmD,EAAE,GAAGF,KAAK,CAACG,KAAN,CAAYC,IAAvB,CAD4E,CAG5E;;YACAhC,QAAQ,GAAGZ,IAAI,CAACC,GAAL,CAASW,QAAT,EAAmB8B,EAAnB,CAAX;YACA7B,QAAQ,GAAGT,MAAM,CAACxB,MAAP,GAAgB,CAAhB,GACPoB,IAAI,CAAC6C,GAAL,CAASzC,MAAM,CAACA,MAAM,CAACxB,MAAP,GAAgB,CAAjB,CAAN,CAA0B+D,KAA1B,CAAgCC,IAAzC,EAA+C/B,QAA/C,CADO,GAEPD,QAFJ;YAIA,MAAMkC,OAAO,GAAI1C,MAAM,CAACxB,MAAP,IAAiBA,MAAjB,IAA2B8D,EAAE,IAAI7B,QAAlD;;YACA,MAAMkC,cAAc,GAAI1B,GAAD,IAAST,QAAQ,GAAG8B,EAAX,GAAiB,CAACrB,GAAG,GAAG,CAAP,IAAYA,GAA7D,CAV4E,CAY5E;YACA;YACA;YACA;;;YACA,IAAI,CAACzC,MAAM,GAAG,CAAT,IAAcwB,MAAM,CAACxB,MAAP,GAAgBA,MAA9B,IAAwCkE,OAAzC,KAAqD,CAAC5D,aAAa,CAACsD,KAAK,CAACjD,IAAP,CAAnE,IAAmF,CAACc,KAAK,CAACmC,KAAK,CAACjD,IAAP,CAA7F,EAA2G;cACzGa,MAAM,CAACmB,IAAP,CAAYiB,KAAZ;cACAnC,KAAK,CAACmC,KAAK,CAACjD,IAAP,CAAL,GAAoB,IAApB;;cAEA,IAAIF,kBAAJ,EAAwB;gBACtBA,kBAAkB,CAACmD,KAAD,CAAlB;cACD;YACF;;YAED,IAAI5D,MAAM,GAAG,CAAb,EAAgB;cACd;cACA4D,KAAK,CAACQ,IAAN,CAAWC,OAAX,CAAmB9B,iBAAnB;cACA,IAAIqB,KAAK,CAACU,IAAV,EAAgBV,KAAK,CAACU,IAAN,CAAWD,OAAX,CAAmB9B,iBAAnB;YACjB,CAJD,MAIO;cACL;cACA;cACA;cACA,IAAIf,MAAM,CAACxB,MAAP,GAAgBA,MAAhB,IAA0B8D,EAAE,GAAG7B,QAA/B,IAA4C6B,EAAE,KAAK7B,QAAP,IAAmB,CAACR,KAAK,CAACmC,KAAK,CAACjD,IAAP,CAAzB,IAAyC,CAACL,aAAa,CAACsD,KAAK,CAACjD,IAAP,CAAvG,EAAsH;gBACpHiD,KAAK,CAACQ,IAAN,CAAWC,OAAX,CAAmB7B,CAAC,IAAID,iBAAiB,CAACC,CAAD,EAAI2B,cAAc,CAAC,CAAD,CAAlB,CAAzC;cACD;;cACD,IAAIP,KAAK,CAACU,IAAN,IAAe9C,MAAM,CAACxB,MAAP,GAAgB4D,KAAK,CAACU,IAAN,CAAWtE,MAA3B,IAAqCA,MAAxD,EAAiE;gBAC/D4D,KAAK,CAACU,IAAN,CAAWD,OAAX,CAAmB,CAAC7B,CAAD,EAAI+B,CAAJ,KAAUhC,iBAAiB,CAACC,CAAD,EAAI2B,cAAc,CAACI,CAAD,CAAlB,CAA9C;cACD;YACF;UACF;QACF,CA1CD;;QA4CA,IAAIjD,uBAAJ,EAA6B;UAC3BA,uBAAuB,CAACX,IAAD,EAAO,IAAP,EAAa,CAAb,EAAgBa,MAAM,CAACxB,MAAvB,CAAvB;QACD;;QAED,IAAI;UACF;UACA,MAAM4D,KAAK,GAAG,MAAM/D,KAAK,CAAC2E,aAAN,CAAoBrE,IAApB,EAA0BQ,IAA1B,CAApB,CAFE,CAGF;;UACA,IAAIY,KAAK,GAAG,CAAZ,EAAe;YACb,MAAMkD,KAAK,GAAG;cAAA,IAACC,EAAD,uEAAM,CAAN;cAAA,OAAY,IAAItB,OAAJ,CAAYC,OAAO,IAAIG,UAAU,CAACH,OAAD,EAAUqB,EAAV,CAAjC,CAAZ;YAAA,CAAd;;YACA,MAAMD,KAAK,CAAClD,KAAD,CAAX;UACD,CAPC,CAQF;;;UACAoC,YAAY,CAACC,KAAD,CAAZ;UACAP,OAAO;QACR,CAXD,CAWE,OAAOb,CAAP,EAAU;UACVc,MAAM,CAACd,CAAD,CAAN;QACD,CAbD,SAaU;UACRmC,YAAY,CAACpB,KAAD,CAAZ;QACD;MACF,CA1EM,CAAP;IA2ED,CAjFD,CA9CyK,CAiIzK;;;IACA,MAAMqB,aAAa,GAAG,YAAY;MAChC,IAAI7C,OAAO,GAAGvB,WAAd,EAA2B;QACzB,MAAMqE,KAAK,GAAGjC,gBAAgB,CAACpC,WAAD,CAA9B;QACAuB,OAAO,IAAI8C,KAAK,CAAC7E,MAAjB;QACA,MAAMN,IAAI,CAACmF,KAAD,EAAQ1B,UAAR,EAAoB;UAAE3C;QAAF,CAApB,CAAV;QACAuB,OAAO,IAAI8C,KAAK,CAAC7E,MAAjB;MACD;IACF,CAPD,CAlIyK,CA2IzK;;;IACAK,OAAO,CAACgE,OAAR,CAAgBnB,iBAAhB,EA5IyK,CA8IzK;;IACA,MAAMtD,SAAS,CAACgF,aAAD,EAAgB1C,mBAAhB,CAAf;IAEA,OAAOV,MAAP;EACD;;AAzKW;;AA4KdsD,MAAM,CAACC,OAAP,GAAiB9E,OAAjB"},"metadata":{},"sourceType":"script"}