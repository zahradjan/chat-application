{"ast":null,"code":"var _regeneratorRuntime = require(\"C:/Users/zajan/GitHub/chatApplication/node_modules/@babel/runtime/helpers/regeneratorRuntime.js\").default;\n\nvar _asyncToGenerator = require(\"C:/Users/zajan/GitHub/chatApplication/node_modules/@babel/runtime/helpers/asyncToGenerator.js\").default;\n\nvar _classCallCheck = require(\"C:/Users/zajan/GitHub/chatApplication/node_modules/@babel/runtime/helpers/classCallCheck.js\").default;\n\nvar _createClass = require(\"C:/Users/zajan/GitHub/chatApplication/node_modules/@babel/runtime/helpers/createClass.js\").default;\n\nvar _toConsumableArray = require(\"C:/Users/zajan/GitHub/chatApplication/node_modules/@babel/runtime/helpers/toConsumableArray.js\").default;\n\nvar PQueue = require('p-queue').default;\n\nvar Log = require('ipfs-log');\n\nvar getNextAndRefsUnion = function getNextAndRefsUnion(e) {\n  return _toConsumableArray(new Set([].concat(_toConsumableArray(e.next), _toConsumableArray(e.refs))));\n};\n\nvar flatMap = function flatMap(res, val) {\n  return res.concat(val);\n};\n\nvar defaultConcurrency = 32;\n\nvar Replicator = /*#__PURE__*/function () {\n  \"use strict\";\n\n  function Replicator(store, concurrency) {\n    var _this = this;\n\n    _classCallCheck(this, Replicator);\n\n    this._store = store;\n    this._concurrency = concurrency || defaultConcurrency; // Tasks processing queue where each log sync request is\n    // added as a task that fetches the log\n\n    this._q = new PQueue({\n      concurrency: this._concurrency\n    });\n    /* Internal caches */\n    // For storing fetched logs before \"load is complete\".\n    // Cleared when processing is complete.\n\n    this._logs = []; // Index of hashes (CIDs) for checking which entries are currently being fetched.\n    // Hashes are added to this cache before fetching a log starts and removed after\n    // the log was fetched.\n\n    this._fetching = {}; // Index of hashes (CIDs) for checking which entries have been fetched.\n    // Cleared when processing is complete.\n\n    this._fetched = {}; // Listen for an event when the task queue has emptied\n    // and all tasks have been processed. We call the\n    // onReplicationComplete callback which then updates the Store's\n    // state (eg. index, replication state, etc)\n\n    this._q.on('idle', /*#__PURE__*/_asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee() {\n      var logs;\n      return _regeneratorRuntime().wrap(function _callee$(_context) {\n        while (1) {\n          switch (_context.prev = _context.next) {\n            case 0:\n              logs = _this._logs.slice();\n              _this._logs = [];\n\n              if (!(_this.onReplicationComplete && logs.length > 0 && _this._store._oplog)) {\n                _context.next = 12;\n                break;\n              }\n\n              _context.prev = 3;\n              _context.next = 6;\n              return _this.onReplicationComplete(logs);\n\n            case 6:\n              // Remove from internal cache\n              logs.forEach(function (log) {\n                return log.values.forEach(function (e) {\n                  return delete _this._fetched[e.hash];\n                });\n              });\n              _context.next = 12;\n              break;\n\n            case 9:\n              _context.prev = 9;\n              _context.t0 = _context[\"catch\"](3);\n              console.error(_context.t0);\n\n            case 12:\n            case \"end\":\n              return _context.stop();\n          }\n        }\n      }, _callee, null, [[3, 9]]);\n    })));\n  }\n  /**\n   * Returns the number of replication tasks running currently\n   * @return {[Integer]} [Number of replication tasks running]\n   */\n\n\n  _createClass(Replicator, [{\n    key: \"tasksRunning\",\n    get: function get() {\n      return this._q.pending;\n    }\n    /**\n     * Returns the number of replication tasks currently queued\n     * @return {[Integer]} [Number of replication tasks queued]\n     */\n\n  }, {\n    key: \"tasksQueued\",\n    get: function get() {\n      return this._q.size;\n    }\n    /**\n     * Returns the hashes currently queued or being processed\n     * @return {[Array]} [Strings of hashes of entries currently queued or being processed]\n     */\n\n  }, {\n    key: \"unfinished\",\n    get: function get() {\n      return Object.keys(this._fetching);\n    }\n    /*\n      Process new heads.\n      Param 'entries' is an Array of Entry instances or strings (of CIDs).\n     */\n\n  }, {\n    key: \"load\",\n    value: function () {\n      var _load = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee2(entries) {\n        return _regeneratorRuntime().wrap(function _callee2$(_context2) {\n          while (1) {\n            switch (_context2.prev = _context2.next) {\n              case 0:\n                try {\n                  // Add entries to the replication queue\n                  this._addToQueue(entries);\n                } catch (e) {\n                  console.error(e);\n                }\n\n              case 1:\n              case \"end\":\n                return _context2.stop();\n            }\n          }\n        }, _callee2, this);\n      }));\n\n      function load(_x) {\n        return _load.apply(this, arguments);\n      }\n\n      return load;\n    }()\n  }, {\n    key: \"_addToQueue\",\n    value: function () {\n      var _addToQueue2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee4(entries) {\n        var _this2 = this;\n\n        var shouldExclude, createReplicationTask, tasks;\n        return _regeneratorRuntime().wrap(function _callee4$(_context4) {\n          while (1) {\n            switch (_context4.prev = _context4.next) {\n              case 0:\n                // Function to determine if an entry should be fetched (ie. do we have it somewhere already?)\n                shouldExclude = function shouldExclude(h) {\n                  return h && _this2._store._oplog && (_this2._store._oplog.has(h) || _this2._fetching[h] !== undefined || _this2._fetched[h]);\n                }; // A task to process a given entries\n\n\n                createReplicationTask = function createReplicationTask(e) {\n                  // Add to internal \"currently fetching\" cache\n                  _this2._fetching[e.hash || e] = true; // The returned function is the processing function / task\n                  // to run concurrently\n\n                  return /*#__PURE__*/_asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee3() {\n                    var log;\n                    return _regeneratorRuntime().wrap(function _callee3$(_context3) {\n                      while (1) {\n                        switch (_context3.prev = _context3.next) {\n                          case 0:\n                            // Call onReplicationProgress only for entries that have .hash field,\n                            // if it is a string don't call it (added internally from .next)\n                            if (e.hash && _this2.onReplicationQueued) {\n                              _this2.onReplicationQueued(e);\n                            }\n\n                            _context3.prev = 1;\n                            _context3.next = 4;\n                            return _this2._replicateLog(e);\n\n                          case 4:\n                            log = _context3.sent;\n\n                            // Add the fetched log to the internal cache to wait\n                            // for \"onReplicationComplete\"\n                            _this2._logs.push(log);\n\n                            _context3.next = 12;\n                            break;\n\n                          case 8:\n                            _context3.prev = 8;\n                            _context3.t0 = _context3[\"catch\"](1);\n                            console.error(_context3.t0);\n                            throw _context3.t0;\n\n                          case 12:\n                            // Remove from internal cache\n                            delete _this2._fetching[e.hash || e];\n\n                          case 13:\n                          case \"end\":\n                            return _context3.stop();\n                        }\n                      }\n                    }, _callee3, null, [[1, 8]]);\n                  }));\n                };\n\n                if (entries.length > 0) {\n                  // Create a processing tasks from each entry/hash that we\n                  // should include based on the exclusion filter function\n                  tasks = entries.filter(function (e) {\n                    return !shouldExclude(e.hash || e);\n                  }).map(function (e) {\n                    return createReplicationTask(e);\n                  }); // Add the tasks to the processing queue\n\n                  if (tasks.length > 0) {\n                    this._q.addAll(tasks);\n                  }\n                }\n\n              case 3:\n              case \"end\":\n                return _context4.stop();\n            }\n          }\n        }, _callee4, this);\n      }));\n\n      function _addToQueue(_x2) {\n        return _addToQueue2.apply(this, arguments);\n      }\n\n      return _addToQueue;\n    }()\n  }, {\n    key: \"stop\",\n    value: function () {\n      var _stop = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee5() {\n        return _regeneratorRuntime().wrap(function _callee5$(_context5) {\n          while (1) {\n            switch (_context5.prev = _context5.next) {\n              case 0:\n                // Clear the task queue\n                this._q.pause();\n\n                this._q.clear();\n\n                _context5.next = 4;\n                return this._q.onIdle();\n\n              case 4:\n                // Reset internal caches\n                this._logs = [];\n                this._fetching = {};\n                this._fetched = {};\n\n              case 7:\n              case \"end\":\n                return _context5.stop();\n            }\n          }\n        }, _callee5, this);\n      }));\n\n      function stop() {\n        return _stop.apply(this, arguments);\n      }\n\n      return stop;\n    }()\n  }, {\n    key: \"_replicateLog\",\n    value: function () {\n      var _replicateLog2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee6(entry) {\n        var _this3 = this;\n\n        var hash, onProgressCallback, shouldExclude, log, nexts;\n        return _regeneratorRuntime().wrap(function _callee6$(_context6) {\n          while (1) {\n            switch (_context6.prev = _context6.next) {\n              case 0:\n                hash = entry.hash || entry; // Notify the Store that we made progress\n\n                onProgressCallback = function onProgressCallback(entry) {\n                  _this3._fetched[entry.hash] = true;\n\n                  if (_this3.onReplicationProgress) {\n                    _this3.onReplicationProgress(entry);\n                  }\n                };\n\n                shouldExclude = function shouldExclude(h) {\n                  return h && h !== hash && _this3._store._oplog && (_this3._store._oplog.has(h) || _this3._fetching[h] !== undefined || _this3._fetched[h] !== undefined);\n                }; // Fetch and load a log from the entry hash\n\n\n                _context6.next = 5;\n                return Log.fromEntryHash(this._store._ipfs, this._store.identity, hash, {\n                  logId: this._store.id,\n                  access: this._store.access,\n                  length: -1,\n                  exclude: [],\n                  shouldExclude: shouldExclude,\n                  concurrency: this._concurrency,\n                  onProgressCallback: onProgressCallback\n                });\n\n              case 5:\n                log = _context6.sent;\n                // Return all next pointers\n                nexts = log.values.map(getNextAndRefsUnion).reduce(flatMap, []);\n                _context6.prev = 7;\n\n                // Add the next (hashes) to the processing queue\n                this._addToQueue(nexts);\n\n                _context6.next = 15;\n                break;\n\n              case 11:\n                _context6.prev = 11;\n                _context6.t0 = _context6[\"catch\"](7);\n                console.error(_context6.t0);\n                throw _context6.t0;\n\n              case 15:\n                return _context6.abrupt(\"return\", log);\n\n              case 16:\n              case \"end\":\n                return _context6.stop();\n            }\n          }\n        }, _callee6, this, [[7, 11]]);\n      }));\n\n      function _replicateLog(_x3) {\n        return _replicateLog2.apply(this, arguments);\n      }\n\n      return _replicateLog;\n    }()\n  }]);\n\n  return Replicator;\n}();\n\nmodule.exports = Replicator;","map":{"version":3,"names":["PQueue","require","default","Log","getNextAndRefsUnion","e","Set","next","refs","flatMap","res","val","concat","defaultConcurrency","Replicator","store","concurrency","_store","_concurrency","_q","_logs","_fetching","_fetched","on","logs","slice","onReplicationComplete","length","_oplog","forEach","log","values","hash","console","error","pending","size","Object","keys","entries","_addToQueue","shouldExclude","h","has","undefined","createReplicationTask","onReplicationQueued","_replicateLog","push","tasks","filter","map","addAll","pause","clear","onIdle","entry","onProgressCallback","onReplicationProgress","fromEntryHash","_ipfs","identity","logId","id","access","exclude","nexts","reduce","module","exports"],"sources":["C:/Users/zajan/GitHub/chatApplication/node_modules/orbit-db-store/src/Replicator.js"],"sourcesContent":["const PQueue = require('p-queue').default\nconst Log = require('ipfs-log')\n\nconst getNextAndRefsUnion = e => [...new Set([...e.next, ...e.refs])]\nconst flatMap = (res, val) => res.concat(val)\n\nconst defaultConcurrency = 32\n\nclass Replicator {\n  constructor (store, concurrency) {\n    this._store = store\n    this._concurrency = concurrency || defaultConcurrency\n\n    // Tasks processing queue where each log sync request is\n    // added as a task that fetches the log\n    this._q = new PQueue({ concurrency: this._concurrency })\n\n    /* Internal caches */\n\n    // For storing fetched logs before \"load is complete\".\n    // Cleared when processing is complete.\n    this._logs = []\n    // Index of hashes (CIDs) for checking which entries are currently being fetched.\n    // Hashes are added to this cache before fetching a log starts and removed after\n    // the log was fetched.\n    this._fetching = {}\n    // Index of hashes (CIDs) for checking which entries have been fetched.\n    // Cleared when processing is complete.\n    this._fetched = {}\n\n    // Listen for an event when the task queue has emptied\n    // and all tasks have been processed. We call the\n    // onReplicationComplete callback which then updates the Store's\n    // state (eg. index, replication state, etc)\n    this._q.on('idle', async () => {\n      const logs = this._logs.slice()\n      this._logs = []\n      if (this.onReplicationComplete && logs.length > 0 && this._store._oplog) {\n        try {\n          await this.onReplicationComplete(logs)\n          // Remove from internal cache\n          logs.forEach(log => log.values.forEach(e => delete this._fetched[e.hash]))\n        } catch (e) {\n          console.error(e)\n        }\n      }\n    })\n  }\n\n  /**\n   * Returns the number of replication tasks running currently\n   * @return {[Integer]} [Number of replication tasks running]\n   */\n  get tasksRunning () {\n    return this._q.pending\n  }\n\n  /**\n   * Returns the number of replication tasks currently queued\n   * @return {[Integer]} [Number of replication tasks queued]\n   */\n  get tasksQueued () {\n    return this._q.size\n  }\n\n  /**\n   * Returns the hashes currently queued or being processed\n   * @return {[Array]} [Strings of hashes of entries currently queued or being processed]\n   */\n  get unfinished () {\n    return Object.keys(this._fetching)\n  }\n\n  /*\n    Process new heads.\n    Param 'entries' is an Array of Entry instances or strings (of CIDs).\n   */\n  async load (entries) {\n    try {\n      // Add entries to the replication queue\n      this._addToQueue(entries)\n    } catch (e) {\n      console.error(e)\n    }\n  }\n\n  async _addToQueue (entries) {\n    // Function to determine if an entry should be fetched (ie. do we have it somewhere already?)\n    const shouldExclude = (h) => h && this._store._oplog && (this._store._oplog.has(h) || this._fetching[h] !== undefined || this._fetched[h])\n\n    // A task to process a given entries\n    const createReplicationTask = (e) => {\n      // Add to internal \"currently fetching\" cache\n      this._fetching[e.hash || e] = true\n      // The returned function is the processing function / task\n      // to run concurrently\n      return async () => {\n        // Call onReplicationProgress only for entries that have .hash field,\n        // if it is a string don't call it (added internally from .next)\n        if (e.hash && this.onReplicationQueued) {\n          this.onReplicationQueued(e)\n        }\n        try {\n          // Replicate the log starting from the entry's hash (CID)\n          const log = await this._replicateLog(e)\n          // Add the fetched log to the internal cache to wait\n          // for \"onReplicationComplete\"\n          this._logs.push(log)\n        } catch (e) {\n          console.error(e)\n          throw e\n        }\n        // Remove from internal cache\n        delete this._fetching[e.hash || e]\n      }\n    }\n\n    if (entries.length > 0) {\n      // Create a processing tasks from each entry/hash that we\n      // should include based on the exclusion filter function\n      const tasks = entries\n        .filter((e) => !shouldExclude(e.hash || e))\n        .map((e) => createReplicationTask(e))\n      // Add the tasks to the processing queue\n      if (tasks.length > 0) {\n        this._q.addAll(tasks)\n      }\n    }\n  }\n\n  async stop () {\n    // Clear the task queue\n    this._q.pause()\n    this._q.clear()\n    await this._q.onIdle()\n    // Reset internal caches\n    this._logs = []\n    this._fetching = {}\n    this._fetched = {}\n  }\n\n  async _replicateLog (entry) {\n    const hash = entry.hash || entry\n\n    // Notify the Store that we made progress\n    const onProgressCallback = (entry) => {\n      this._fetched[entry.hash] = true\n      if (this.onReplicationProgress) {\n        this.onReplicationProgress(entry)\n      }\n    }\n\n    const shouldExclude = (h) => h && h !== hash && this._store._oplog && (this._store._oplog.has(h) || this._fetching[h] !== undefined || this._fetched[h] !== undefined)\n\n    // Fetch and load a log from the entry hash\n    const log = await Log.fromEntryHash(\n      this._store._ipfs,\n      this._store.identity,\n      hash,\n      {\n        logId: this._store.id,\n        access: this._store.access,\n        length: -1,\n        exclude: [],\n        shouldExclude,\n        concurrency: this._concurrency,\n        onProgressCallback\n      }\n    )\n\n    // Return all next pointers\n    const nexts = log.values.map(getNextAndRefsUnion).reduce(flatMap, [])\n    try {\n      // Add the next (hashes) to the processing queue\n      this._addToQueue(nexts)\n    } catch (e) {\n      console.error(e)\n      throw e\n    }\n    // Return the log\n    return log\n  }\n}\n\nmodule.exports = Replicator\n"],"mappings":";;;;;;;;;;AAAA,IAAMA,MAAM,GAAGC,OAAO,CAAC,SAAD,CAAP,CAAmBC,OAAlC;;AACA,IAAMC,GAAG,GAAGF,OAAO,CAAC,UAAD,CAAnB;;AAEA,IAAMG,mBAAmB,GAAG,SAAtBA,mBAAsB,CAAAC,CAAC;EAAA,0BAAQ,IAAIC,GAAJ,8BAAYD,CAAC,CAACE,IAAd,sBAAuBF,CAAC,CAACG,IAAzB,GAAR;AAAA,CAA7B;;AACA,IAAMC,OAAO,GAAG,SAAVA,OAAU,CAACC,GAAD,EAAMC,GAAN;EAAA,OAAcD,GAAG,CAACE,MAAJ,CAAWD,GAAX,CAAd;AAAA,CAAhB;;AAEA,IAAME,kBAAkB,GAAG,EAA3B;;IAEMC,U;;;EACJ,oBAAaC,KAAb,EAAoBC,WAApB,EAAiC;IAAA;;IAAA;;IAC/B,KAAKC,MAAL,GAAcF,KAAd;IACA,KAAKG,YAAL,GAAoBF,WAAW,IAAIH,kBAAnC,CAF+B,CAI/B;IACA;;IACA,KAAKM,EAAL,GAAU,IAAInB,MAAJ,CAAW;MAAEgB,WAAW,EAAE,KAAKE;IAApB,CAAX,CAAV;IAEA;IAEA;IACA;;IACA,KAAKE,KAAL,GAAa,EAAb,CAZ+B,CAa/B;IACA;IACA;;IACA,KAAKC,SAAL,GAAiB,EAAjB,CAhB+B,CAiB/B;IACA;;IACA,KAAKC,QAAL,GAAgB,EAAhB,CAnB+B,CAqB/B;IACA;IACA;IACA;;IACA,KAAKH,EAAL,CAAQI,EAAR,CAAW,MAAX,0EAAmB;MAAA;MAAA;QAAA;UAAA;YAAA;cACXC,IADW,GACJ,KAAI,CAACJ,KAAL,CAAWK,KAAX,EADI;cAEjB,KAAI,CAACL,KAAL,GAAa,EAAb;;cAFiB,MAGb,KAAI,CAACM,qBAAL,IAA8BF,IAAI,CAACG,MAAL,GAAc,CAA5C,IAAiD,KAAI,CAACV,MAAL,CAAYW,MAHhD;gBAAA;gBAAA;cAAA;;cAAA;cAAA;cAAA,OAKP,KAAI,CAACF,qBAAL,CAA2BF,IAA3B,CALO;;YAAA;cAMb;cACAA,IAAI,CAACK,OAAL,CAAa,UAAAC,GAAG;gBAAA,OAAIA,GAAG,CAACC,MAAJ,CAAWF,OAAX,CAAmB,UAAAxB,CAAC;kBAAA,OAAI,OAAO,KAAI,CAACiB,QAAL,CAAcjB,CAAC,CAAC2B,IAAhB,CAAX;gBAAA,CAApB,CAAJ;cAAA,CAAhB;cAPa;cAAA;;YAAA;cAAA;cAAA;cASbC,OAAO,CAACC,KAAR;;YATa;YAAA;cAAA;UAAA;QAAA;MAAA;IAAA,CAAnB;EAaD;EAED;AACF;AACA;AACA;;;;;SACE,eAAoB;MAClB,OAAO,KAAKf,EAAL,CAAQgB,OAAf;IACD;IAED;AACF;AACA;AACA;;;;SACE,eAAmB;MACjB,OAAO,KAAKhB,EAAL,CAAQiB,IAAf;IACD;IAED;AACF;AACA;AACA;;;;SACE,eAAkB;MAChB,OAAOC,MAAM,CAACC,IAAP,CAAY,KAAKjB,SAAjB,CAAP;IACD;IAED;AACF;AACA;AACA;;;;;6EACE,kBAAYkB,OAAZ;QAAA;UAAA;YAAA;cAAA;gBACE,IAAI;kBACF;kBACA,KAAKC,WAAL,CAAiBD,OAAjB;gBACD,CAHD,CAGE,OAAOlC,CAAP,EAAU;kBACV4B,OAAO,CAACC,KAAR,CAAc7B,CAAd;gBACD;;cANH;cAAA;gBAAA;YAAA;UAAA;QAAA;MAAA,C;;;;;;;;;;;oFASA,kBAAmBkC,OAAnB;QAAA;;QAAA;QAAA;UAAA;YAAA;cAAA;gBACE;gBACME,aAFR,GAEwB,SAAhBA,aAAgB,CAACC,CAAD;kBAAA,OAAOA,CAAC,IAAI,MAAI,CAACzB,MAAL,CAAYW,MAAjB,KAA4B,MAAI,CAACX,MAAL,CAAYW,MAAZ,CAAmBe,GAAnB,CAAuBD,CAAvB,KAA6B,MAAI,CAACrB,SAAL,CAAeqB,CAAf,MAAsBE,SAAnD,IAAgE,MAAI,CAACtB,QAAL,CAAcoB,CAAd,CAA5F,CAAP;gBAAA,CAFxB,EAIE;;;gBACMG,qBALR,GAKgC,SAAxBA,qBAAwB,CAACxC,CAAD,EAAO;kBACnC;kBACA,MAAI,CAACgB,SAAL,CAAehB,CAAC,CAAC2B,IAAF,IAAU3B,CAAzB,IAA8B,IAA9B,CAFmC,CAGnC;kBACA;;kBACA,+EAAO;oBAAA;oBAAA;sBAAA;wBAAA;0BAAA;4BACL;4BACA;4BACA,IAAIA,CAAC,CAAC2B,IAAF,IAAU,MAAI,CAACc,mBAAnB,EAAwC;8BACtC,MAAI,CAACA,mBAAL,CAAyBzC,CAAzB;4BACD;;4BALI;4BAAA;4BAAA,OAQe,MAAI,CAAC0C,aAAL,CAAmB1C,CAAnB,CARf;;0BAAA;4BAQGyB,GARH;;4BASH;4BACA;4BACA,MAAI,CAACV,KAAL,CAAW4B,IAAX,CAAgBlB,GAAhB;;4BAXG;4BAAA;;0BAAA;4BAAA;4BAAA;4BAaHG,OAAO,CAACC,KAAR;4BAbG;;0BAAA;4BAgBL;4BACA,OAAO,MAAI,CAACb,SAAL,CAAehB,CAAC,CAAC2B,IAAF,IAAU3B,CAAzB,CAAP;;0BAjBK;0BAAA;4BAAA;wBAAA;sBAAA;oBAAA;kBAAA,CAAP;gBAmBD,CA7BH;;gBA+BE,IAAIkC,OAAO,CAACZ,MAAR,GAAiB,CAArB,EAAwB;kBACtB;kBACA;kBACMsB,KAHgB,GAGRV,OAAO,CAClBW,MADW,CACJ,UAAC7C,CAAD;oBAAA,OAAO,CAACoC,aAAa,CAACpC,CAAC,CAAC2B,IAAF,IAAU3B,CAAX,CAArB;kBAAA,CADI,EAEX8C,GAFW,CAEP,UAAC9C,CAAD;oBAAA,OAAOwC,qBAAqB,CAACxC,CAAD,CAA5B;kBAAA,CAFO,CAHQ,EAMtB;;kBACA,IAAI4C,KAAK,CAACtB,MAAN,GAAe,CAAnB,EAAsB;oBACpB,KAAKR,EAAL,CAAQiC,MAAR,CAAeH,KAAf;kBACD;gBACF;;cAzCH;cAAA;gBAAA;YAAA;UAAA;QAAA;MAAA,C;;;;;;;;;;;6EA4CA;QAAA;UAAA;YAAA;cAAA;gBACE;gBACA,KAAK9B,EAAL,CAAQkC,KAAR;;gBACA,KAAKlC,EAAL,CAAQmC,KAAR;;gBAHF;gBAAA,OAIQ,KAAKnC,EAAL,CAAQoC,MAAR,EAJR;;cAAA;gBAKE;gBACA,KAAKnC,KAAL,GAAa,EAAb;gBACA,KAAKC,SAAL,GAAiB,EAAjB;gBACA,KAAKC,QAAL,GAAgB,EAAhB;;cARF;cAAA;gBAAA;YAAA;UAAA;QAAA;MAAA,C;;;;;;;;;;;sFAWA,kBAAqBkC,KAArB;QAAA;;QAAA;QAAA;UAAA;YAAA;cAAA;gBACQxB,IADR,GACewB,KAAK,CAACxB,IAAN,IAAcwB,KAD7B,EAGE;;gBACMC,kBAJR,GAI6B,SAArBA,kBAAqB,CAACD,KAAD,EAAW;kBACpC,MAAI,CAAClC,QAAL,CAAckC,KAAK,CAACxB,IAApB,IAA4B,IAA5B;;kBACA,IAAI,MAAI,CAAC0B,qBAAT,EAAgC;oBAC9B,MAAI,CAACA,qBAAL,CAA2BF,KAA3B;kBACD;gBACF,CATH;;gBAWQf,aAXR,GAWwB,SAAhBA,aAAgB,CAACC,CAAD;kBAAA,OAAOA,CAAC,IAAIA,CAAC,KAAKV,IAAX,IAAmB,MAAI,CAACf,MAAL,CAAYW,MAA/B,KAA0C,MAAI,CAACX,MAAL,CAAYW,MAAZ,CAAmBe,GAAnB,CAAuBD,CAAvB,KAA6B,MAAI,CAACrB,SAAL,CAAeqB,CAAf,MAAsBE,SAAnD,IAAgE,MAAI,CAACtB,QAAL,CAAcoB,CAAd,MAAqBE,SAA/H,CAAP;gBAAA,CAXxB,EAaE;;;gBAbF;gBAAA,OAcoBzC,GAAG,CAACwD,aAAJ,CAChB,KAAK1C,MAAL,CAAY2C,KADI,EAEhB,KAAK3C,MAAL,CAAY4C,QAFI,EAGhB7B,IAHgB,EAIhB;kBACE8B,KAAK,EAAE,KAAK7C,MAAL,CAAY8C,EADrB;kBAEEC,MAAM,EAAE,KAAK/C,MAAL,CAAY+C,MAFtB;kBAGErC,MAAM,EAAE,CAAC,CAHX;kBAIEsC,OAAO,EAAE,EAJX;kBAKExB,aAAa,EAAbA,aALF;kBAMEzB,WAAW,EAAE,KAAKE,YANpB;kBAOEuC,kBAAkB,EAAlBA;gBAPF,CAJgB,CAdpB;;cAAA;gBAcQ3B,GAdR;gBA6BE;gBACMoC,KA9BR,GA8BgBpC,GAAG,CAACC,MAAJ,CAAWoB,GAAX,CAAe/C,mBAAf,EAAoC+D,MAApC,CAA2C1D,OAA3C,EAAoD,EAApD,CA9BhB;gBAAA;;gBAgCI;gBACA,KAAK+B,WAAL,CAAiB0B,KAAjB;;gBAjCJ;gBAAA;;cAAA;gBAAA;gBAAA;gBAmCIjC,OAAO,CAACC,KAAR;gBAnCJ;;cAAA;gBAAA,kCAuCSJ,GAvCT;;cAAA;cAAA;gBAAA;YAAA;UAAA;QAAA;MAAA,C;;;;;;;;;;;;;AA2CFsC,MAAM,CAACC,OAAP,GAAiBvD,UAAjB"},"metadata":{},"sourceType":"script"}